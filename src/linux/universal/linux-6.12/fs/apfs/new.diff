diff --git a/.gitignore b/.gitignore
index b8be41b..c3e3df8 100644
--- a/.gitignore
+++ b/.gitignore
@@ -9,3 +9,4 @@
 *.a
 *.mod
 tags
+version.h
diff --git a/Makefile b/Makefile
index 8fa509c..ab4c49d 100644
--- a/Makefile
+++ b/Makefile
@@ -14,8 +14,10 @@ apfs-y := btree.o compress.o dir.o extents.o file.o inode.o key.o libzbitmap.o \
 	  spaceman.o super.o symlink.o transaction.o unicode.o xattr.o xfield.o
 
 default:
+	./genver.sh
 	make -C $(KERNEL_DIR) M=$(PWD)
 install:
 	make -C $(KERNEL_DIR) M=$(PWD) modules_install
 clean:
+	rm -f version.h
 	make -C $(KERNEL_DIR) M=$(PWD) clean
diff --git a/README.rst b/README.rst
index be99914..93ab2c6 100644
--- a/README.rst
+++ b/README.rst
@@ -22,7 +22,8 @@ This module is the result of reverse engineering and testing has been limited.
 If you make use of the write support, expect data corruption. Please report any
 issues that you find, but I can't promise a quick resolution at this stage.
 
-Encryption is not yet implemented even in read-only mode.
+Encryption is not yet implemented even in read-only mode, and neither are
+fusion drives.
 
 Build
 =====
diff --git a/apfs.h b/apfs.h
index f57709a..b6d135c 100644
--- a/apfs.h
+++ b/apfs.h
@@ -13,8 +13,6 @@
 #include <linux/version.h>
 #include "apfs_raw.h"
 
-#define APFS_MODULE_ID_STRING	"linux-apfs by EA FernÃ¡ndez"
-
 #define EFSBADCRC	EBADMSG		/* Bad CRC detected */
 #define EFSCORRUPTED	EUCLEAN		/* Filesystem is corrupted */
 
@@ -66,6 +64,7 @@ struct apfs_object {
 	 */
 	struct buffer_head *o_bh;
 	char *data; /* The raw object */
+	bool ephemeral; /* Is this an ephemeral object? */
 };
 
 /* Constants used in managing the size of a node's table of contents */
@@ -123,8 +122,8 @@ static inline bool apfs_node_has_fixed_kv_size(struct apfs_node *node)
  */
 struct apfs_spaceman {
 	struct apfs_spaceman_phys *sm_raw; /* On-disk spaceman structure */
-	struct buffer_head	  *sm_bh;  /* Buffer head for @sm_raw */
-	struct buffer_head	  *sm_ip;  /* Current internal pool */
+	struct apfs_nxsb_info	  *sm_nxi; /* Container superblock */
+	u32			  sm_size; /* Size of @sm_raw in bytes */
 
 	u32 sm_blocks_per_chunk;	/* Blocks covered by a bitmap block */
 	u32 sm_chunks_per_cib;		/* Chunk count in a chunk-info block */
@@ -140,6 +139,15 @@ struct apfs_spaceman {
 	 */
 	u64 sm_free_cache_base;
 	u64 sm_free_cache_blkcnt;
+
+	/* Shift to match an ip block with its bitmap in the array */
+	int sm_ip_bmaps_shift;
+	/* Mask to find an ip block's offset inside its ip bitmap */
+	u32 sm_ip_bmaps_mask;
+	/* Number of ip bitmaps */
+	u32 sm_ip_bmaps_count;
+	/* List of ip bitmaps, in order */
+	struct buffer_head *sm_ip_bmaps[];
 };
 
 #define TRANSACTION_MAIN_QUEUE_MAX	4096
@@ -156,7 +164,6 @@ struct apfs_spaceman {
  * Structure that keeps track of a container transaction.
  */
 struct apfs_nx_transaction {
-	struct buffer_head *t_old_msb;  /* Main superblock being replaced */
 	unsigned int t_state;
 
 	struct list_head t_inodes;	/* List of inodes in the transaction */
@@ -197,6 +204,23 @@ struct apfs_max_ops {
 	int blks;	/* Maximum extent blocks that may need changing */
 };
 
+/*
+ * List entry for an in-memory ephemeral object
+ */
+struct apfs_ephemeral_object_info {
+	u64	oid;		/* Ephemeral object id */
+	u32	size;		/* Size of the object in bytes */
+	void	*object;	/* In-memory address of the object */
+};
+
+/*
+ * We allocate a fixed space for the list of ephemeral objects. I don't
+ * actually know how big this should be allowed to get, but all the objects
+ * must be written down with each transaction commit, so probably not too big.
+ */
+#define APFS_EPHEMERAL_LIST_SIZE	32768
+#define APFS_EPHEMERAL_LIST_LIMIT	(APFS_EPHEMERAL_LIST_SIZE / sizeof(struct apfs_ephemeral_object_info))
+
 /* Mount option flags for a container */
 #define APFS_CHECK_NODES	1
 #define APFS_READWRITE		2
@@ -206,10 +230,19 @@ struct apfs_max_ops {
  */
 struct apfs_nxsb_info {
 	struct block_device *nx_bdev; /* Device for the container */
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(6, 9, 0)
+	struct file *nx_bdev_file;
+#elif LINUX_VERSION_CODE >= KERNEL_VERSION(6, 8, 0)
+	struct bdev_handle *nx_bdev_handle;
+#endif
 	struct apfs_nx_superblock *nx_raw; /* On-disk main sb */
-	struct apfs_object nx_object; /* Main superblock object */
+	u64 nx_bno; /* Current block number for the checkpoint superblock */
 	u64 nx_xid; /* Latest transaction id */
 
+	/* List of ephemeral objects in memory (except the superblock) */
+	struct apfs_ephemeral_object_info *nx_eph_list;
+	int nx_eph_count;
+
 	struct list_head vol_list;	/* List of mounted volumes in container */
 
 	unsigned int nx_flags;	/* Mount options shared by all volumes */
@@ -219,7 +252,7 @@ struct apfs_nxsb_info {
 	unsigned long nx_blocksize;
 	unsigned char nx_blocksize_bits;
 
-	struct apfs_spaceman nx_spaceman;
+	struct apfs_spaceman *nx_spaceman;
 	struct apfs_nx_transaction nx_transaction;
 
 	/* For now, a single semaphore for every operation */
@@ -283,6 +316,8 @@ struct apfs_sb_info {
 	struct list_head list;		/* List of mounted volumes in container */
 	struct apfs_superblock *s_vsb_raw; /* On-disk volume sb */
 
+	dev_t s_anon_dev; /* Anonymous device for this volume-snapshot */
+
 	char *s_snap_name; /* Label for the mounted snapshot */
 	u64 s_snap_xid; /* Transaction id for mounted snapshot */
 
@@ -302,6 +337,7 @@ struct apfs_sb_info {
 	int s_trans_buffers_max;
 
 	struct inode *s_private_dir;	/* Inode for the private directory */
+	struct work_struct s_orphan_cleanup_work;
 };
 
 static inline struct apfs_sb_info *APFS_SB(struct super_block *sb)
@@ -342,7 +378,7 @@ static inline struct apfs_nxsb_info *APFS_NXI(struct super_block *sb)
  */
 static inline struct apfs_spaceman *APFS_SM(struct super_block *sb)
 {
-	return &APFS_NXI(sb)->nx_spaceman;
+	return APFS_NXI(sb)->nx_spaceman;
 }
 
 static inline bool apfs_is_case_insensitive(struct super_block *sb)
@@ -593,20 +629,21 @@ static inline u64 apfs_cat_cnid(struct apfs_key_header *key)
 }
 
 /* Flags for the query structure */
-#define APFS_QUERY_TREE_MASK	00177	/* Which b-tree we query */
-#define APFS_QUERY_OMAP		00001	/* This is a b-tree object map query */
-#define APFS_QUERY_CAT		00002	/* This is a catalog tree query */
-#define APFS_QUERY_FREE_QUEUE	00004	/* This is a free queue query */
-#define APFS_QUERY_EXTENTREF	00010	/* This is an extent reference query */
-#define APFS_QUERY_FEXT		00020	/* This is a fext tree query */
-#define APFS_QUERY_SNAP_META	00040	/* This is a snapshot meta query */
-#define APFS_QUERY_OMAP_SNAP	00100	/* This is an omap snapshots query */
-#define APFS_QUERY_NEXT		00200	/* Find next of multiple matches */
-#define APFS_QUERY_EXACT	00400	/* Search for an exact match */
-#define APFS_QUERY_DONE		01000	/* The search at this level is over */
-#define APFS_QUERY_ANY_NAME	02000	/* Multiple search for any name */
-#define APFS_QUERY_ANY_NUMBER	04000	/* Multiple search for any number */
+#define APFS_QUERY_TREE_MASK	000177	/* Which b-tree we query */
+#define APFS_QUERY_OMAP		000001	/* This is a b-tree object map query */
+#define APFS_QUERY_CAT		000002	/* This is a catalog tree query */
+#define APFS_QUERY_FREE_QUEUE	000004	/* This is a free queue query */
+#define APFS_QUERY_EXTENTREF	000010	/* This is an extent reference query */
+#define APFS_QUERY_FEXT		000020	/* This is a fext tree query */
+#define APFS_QUERY_SNAP_META	000040	/* This is a snapshot meta query */
+#define APFS_QUERY_OMAP_SNAP	000100	/* This is an omap snapshots query */
+#define APFS_QUERY_NEXT		000200	/* Find next of multiple matches */
+#define APFS_QUERY_EXACT	000400	/* Search for an exact match */
+#define APFS_QUERY_DONE		001000	/* The search at this level is over */
+#define APFS_QUERY_ANY_NAME	002000	/* Multiple search for any name */
+#define APFS_QUERY_ANY_NUMBER	004000	/* Multiple search for any number */
 #define APFS_QUERY_MULTIPLE	(APFS_QUERY_ANY_NAME | APFS_QUERY_ANY_NUMBER)
+#define APFS_QUERY_PREV		010000	/* Find previous record */
 
 /*
  * Structure used to retrieve data from an APFS B-Tree. For now only used
@@ -614,7 +651,7 @@ static inline u64 apfs_cat_cnid(struct apfs_key_header *key)
  */
 struct apfs_query {
 	struct apfs_node *node;		/* Node being searched */
-	struct apfs_key *key;		/* What the query is looking for */
+	struct apfs_key key;		/* What the query is looking for */
 
 	struct apfs_query *parent;	/* Query for parent node */
 	unsigned int flags;
@@ -722,6 +759,8 @@ struct apfs_inode_info {
 	bool			 i_has_dstream;	 /* Is there a dstream record? */
 	struct apfs_dstream_info i_dstream;	 /* Dstream data, if any */
 
+	bool			i_cleaned;	 /* Orphan data already deleted */
+
 	struct inode vfs_inode;
 };
 
@@ -822,21 +861,24 @@ do {									\
 } while (0)
 
 /* btree.c */
+extern struct apfs_node *apfs_query_root(const struct apfs_query *query);
 extern struct apfs_query *apfs_alloc_query(struct apfs_node *node,
 					   struct apfs_query *parent);
 extern void apfs_free_query(struct apfs_query *query);
 extern int apfs_btree_query(struct super_block *sb, struct apfs_query **query);
-extern int apfs_omap_lookup_block(struct super_block *sb, struct apfs_omap *omap,
-				  u64 id, u64 *block, bool write);
+extern int apfs_omap_lookup_block(struct super_block *sb, struct apfs_omap *omap, u64 id, u64 *block, bool write);
+extern int apfs_omap_lookup_newest_block(struct super_block *sb, struct apfs_omap *omap, u64 id, u64 *block, bool write);
 extern int apfs_create_omap_rec(struct super_block *sb, u64 oid, u64 bno);
 extern int apfs_delete_omap_rec(struct super_block *sb, u64 oid);
 extern int apfs_query_join_transaction(struct apfs_query *query);
+extern int __apfs_btree_insert(struct apfs_query *query, void *key, int key_len, void *val, int val_len);
 extern int apfs_btree_insert(struct apfs_query *query, void *key, int key_len,
 			     void *val, int val_len);
 extern int apfs_btree_remove(struct apfs_query *query);
 extern void apfs_btree_change_node_count(struct apfs_query *query, int change);
 extern int apfs_btree_replace(struct apfs_query *query, void *key, int key_len,
 			      void *val, int val_len);
+extern void apfs_query_direct_forward(struct apfs_query *query);
 
 /* compress.c */
 extern int apfs_compress_get_size(struct inode *inode, loff_t *size);
@@ -884,6 +926,7 @@ extern int apfs_unlink(struct inode *dir, struct dentry *dentry);
 extern int apfs_rmdir(struct inode *dir, struct dentry *dentry);
 extern int apfs_delete_orphan_link(struct inode *inode);
 extern int APFS_DELETE_ORPHAN_LINK_MAXOPS(void);
+extern u64 apfs_any_orphan_ino(struct super_block *sb, u64 *ino_p);
 
 /* extents.c */
 extern int apfs_extent_from_query(struct apfs_query *query,
@@ -899,6 +942,7 @@ extern int apfs_get_new_block(struct inode *inode, sector_t iblock,
 			      struct buffer_head *bh_result, int create);
 extern int APFS_GET_NEW_BLOCK_MAXOPS(void);
 extern int apfs_truncate(struct apfs_dstream_info *dstream, loff_t new_size);
+extern int apfs_inode_delete_front(struct inode *inode);
 #if LINUX_VERSION_CODE >= KERNEL_VERSION(4, 20, 0)
 extern loff_t apfs_remap_file_range(struct file *src_file, loff_t off, struct file *dst_file, loff_t destoff, loff_t len, unsigned int remap_flags);
 #else
@@ -916,6 +960,7 @@ extern int apfs_fsync(struct file *file, loff_t start, loff_t end, int datasync)
 extern struct inode *apfs_iget(struct super_block *sb, u64 cnid);
 extern int apfs_update_inode(struct inode *inode, char *new_name);
 extern int APFS_UPDATE_INODE_MAXOPS(void);
+extern void apfs_orphan_cleanup_work(struct work_struct *work);
 extern void apfs_evict_inode(struct inode *inode);
 extern struct inode *apfs_new_inode(struct inode *dir, umode_t mode,
 				    dev_t rdev);
@@ -990,7 +1035,7 @@ extern __printf(5, 6) void apfs_msg(struct super_block *sb, const char *prefix,
 extern struct apfs_node *apfs_read_node(struct super_block *sb, u64 oid,
 					u32 storage, bool write);
 extern void apfs_update_node(struct apfs_node *node);
-extern int apfs_delete_node(struct apfs_query *query);
+extern int apfs_delete_node(struct apfs_node *node, int type);
 extern int apfs_node_query(struct super_block *sb, struct apfs_query *query);
 extern void apfs_node_query_first(struct apfs_query *query);
 extern int apfs_omap_map_from_query(struct apfs_query *query, struct apfs_omap_map *map);
@@ -998,6 +1043,7 @@ extern int apfs_node_split(struct apfs_query *query);
 extern int apfs_node_locate_key(struct apfs_node *node, int index, int *off);
 extern void apfs_node_free(struct apfs_node *node);
 extern void apfs_node_free_range(struct apfs_node *node, u16 off, u16 len);
+extern bool apfs_node_has_room(struct apfs_node *node, int length, bool replace);
 extern int apfs_node_replace(struct apfs_query *query, void *key, int key_len, void *val, int val_len);
 extern int apfs_node_insert(struct apfs_query *query, void *key, int key_len, void *val, int val_len);
 extern int apfs_create_single_rec_node(struct apfs_query *query, void *key, int key_len, void *val, int val_len);
@@ -1005,12 +1051,12 @@ extern int apfs_make_empty_btree_root(struct super_block *sb, u32 subtype, u64 *
 
 /* object.c */
 extern int apfs_obj_verify_csum(struct super_block *sb, struct buffer_head *bh);
-extern void apfs_obj_set_csum(struct super_block *sb,
-			      struct apfs_obj_phys *obj);
-extern int apfs_create_cpoint_map(struct super_block *sb, u64 oid, u64 bno);
-extern int apfs_remove_cpoint_map(struct super_block *sb, u64 bno);
-extern struct buffer_head *apfs_read_ephemeral_object(struct super_block *sb,
-						      u64 oid);
+extern void apfs_obj_set_csum(struct super_block *sb, struct apfs_obj_phys *obj);
+extern int apfs_multiblock_verify_csum(char *object, u32 size);
+extern void apfs_multiblock_set_csum(char *object, u32 size);
+extern int apfs_create_cpm_block(struct super_block *sb, u64 bno, struct buffer_head **bh_p);
+extern int apfs_create_cpoint_map(struct super_block *sb, struct apfs_checkpoint_map_phys *cpm, struct apfs_obj_phys *obj, u64 bno, u32 size);
+extern struct apfs_ephemeral_object_info *apfs_ephemeral_object_lookup(struct super_block *sb, u64 oid);
 extern struct buffer_head *apfs_read_object_block(struct super_block *sb, u64 bno, bool write, bool preserve);
 extern u32 apfs_index_in_data_area(struct super_block *sb, u64 bno);
 extern u64 apfs_data_index_to_bno(struct super_block *sb, u32 index);
@@ -1034,7 +1080,6 @@ extern int apfs_read_catalog(struct super_block *sb, bool write);
 extern int apfs_sync_fs(struct super_block *sb, int wait);
 
 /* transaction.c */
-extern void apfs_cpoint_data_allocate(struct super_block *sb, u64 *bno);
 extern int apfs_cpoint_data_free(struct super_block *sb, u64 bno);
 extern int apfs_transaction_start(struct super_block *sb, struct apfs_max_ops maxops);
 extern int apfs_transaction_commit(struct super_block *sb);
@@ -1091,6 +1136,18 @@ extern const struct inode_operations apfs_symlink_inode_operations;
 /* xattr.c */
 extern const struct xattr_handler *apfs_xattr_handlers[];
 
+/**
+ * apfs_assert_query_is_valid - Assert that all of a query's ancestors are set
+ * @query: the query to check
+ *
+ * A query may lose some of its ancestors during a node split, but nothing
+ * should be done to such a query until it gets refreshed.
+ */
+static inline void apfs_assert_query_is_valid(const struct apfs_query *query)
+{
+	ASSERT(apfs_node_is_root(apfs_query_root(query)));
+}
+
 /*
  * TODO: the following are modified variants of buffer head functions that will
  * work with the shared block device for the container. The correct approach
@@ -1118,7 +1175,11 @@ apfs_getblk(struct super_block *sb, sector_t block)
 {
 	struct buffer_head *bh;
 
+#if LINUX_VERSION_CODE < KERNEL_VERSION(6, 7, 0)
 	bh = __getblk_gfp(APFS_NXI(sb)->nx_bdev, block, sb->s_blocksize, __GFP_MOVABLE);
+#else
+	bh = bdev_getblk(APFS_NXI(sb)->nx_bdev, block, sb->s_blocksize, __GFP_MOVABLE);
+#endif
 	if (bh)
 		set_buffer_uptodate(bh);
 	return bh;
diff --git a/btree.c b/btree.c
index f2d3d4a..c5af110 100644
--- a/btree.c
+++ b/btree.c
@@ -7,6 +7,14 @@
 #include <linux/slab.h>
 #include "apfs.h"
 
+struct apfs_node *apfs_query_root(const struct apfs_query *query)
+{
+	while (query->parent)
+		query = query->parent;
+	ASSERT(apfs_node_is_root(query->node));
+	return query->node;
+}
+
 static u64 apfs_catalog_base_oid(struct apfs_query *query)
 {
 	struct apfs_query *root_query = NULL;
@@ -162,21 +170,21 @@ static inline bool apfs_xid_in_snapshot(struct apfs_omap *omap, u64 xid)
 }
 
 /**
- * apfs_omap_lookup_block - Find the block number of a b-tree node from its id
+ * apfs_omap_lookup_block_with_xid - Find bno of a virtual object from oid/xid
  * @sb:		filesystem superblock
  * @omap:	object map to be searched
  * @id:		id of the node
+ * @xid:	transaction id
  * @block:	on return, the found block number
  * @write:	get write access to the object?
  *
- * Returns 0 on success or a negative error code in case of failure.
+ * Searches @omap for the most recent matching object with a transaction id
+ * below @xid. Returns 0 on success or a negative error code in case of failure.
  */
-int apfs_omap_lookup_block(struct super_block *sb, struct apfs_omap *omap,
-			   u64 id, u64 *block, bool write)
+static int apfs_omap_lookup_block_with_xid(struct super_block *sb, struct apfs_omap *omap, u64 id, u64 xid, u64 *block, bool write)
 {
 	struct apfs_nxsb_info *nxi = APFS_NXI(sb);
 	struct apfs_query *query;
-	struct apfs_key key;
 	struct apfs_omap_map map = {0};
 	int ret = 0;
 
@@ -188,15 +196,13 @@ int apfs_omap_lookup_block(struct super_block *sb, struct apfs_omap *omap,
 	query = apfs_alloc_query(omap->omap_root, NULL /* parent */);
 	if (!query)
 		return -ENOMEM;
-
-	apfs_init_omap_key(id, apfs_mounted_xid(sb), &key);
-	query->key = &key;
+	apfs_init_omap_key(id, xid, &query->key);
 	query->flags |= APFS_QUERY_OMAP;
 
 	ret = apfs_btree_query(sb, &query);
 	if (ret) {
 		if (ret != -ENODATA)
-			apfs_err(sb, "query failed for oid 0x%llx, xid 0x%llx", id, apfs_mounted_xid(sb));
+			apfs_err(sb, "query failed for oid 0x%llx, xid 0x%llx", id, xid);
 		goto fail;
 	}
 
@@ -218,7 +224,7 @@ int apfs_omap_lookup_block(struct super_block *sb, struct apfs_omap *omap,
 
 		new_bh = apfs_read_object_block(sb, *block, write, preserve);
 		if (IS_ERR(new_bh)) {
-			apfs_err(sb, "CoW failed for oid 0x%llx, xid 0x%llx", id, apfs_mounted_xid(sb));
+			apfs_err(sb, "CoW failed for oid 0x%llx, xid 0x%llx", id, xid);
 			ret = PTR_ERR(new_bh);
 			goto fail;
 		}
@@ -234,7 +240,7 @@ int apfs_omap_lookup_block(struct super_block *sb, struct apfs_omap *omap,
 		else
 			ret = apfs_btree_replace(query, &key, sizeof(key), &val, sizeof(val));
 		if (ret)
-			apfs_err(sb, "CoW omap update failed (oid 0x%llx, xid 0x%llx)", id, apfs_mounted_xid(sb));
+			apfs_err(sb, "CoW omap update failed (oid 0x%llx, xid 0x%llx)", id, xid);
 
 		*block = new_bh->b_blocknr;
 		brelse(new_bh);
@@ -247,6 +253,36 @@ fail:
 	return ret;
 }
 
+/**
+ * apfs_omap_lookup_block - Find the block number of a b-tree node from its id
+ * @sb:		filesystem superblock
+ * @omap:	object map to be searched
+ * @id:		id of the node
+ * @block:	on return, the found block number
+ * @write:	get write access to the object?
+ *
+ * Returns 0 on success or a negative error code in case of failure.
+ */
+int apfs_omap_lookup_block(struct super_block *sb, struct apfs_omap *omap, u64 id, u64 *block, bool write)
+{
+	return apfs_omap_lookup_block_with_xid(sb, omap, id, apfs_mounted_xid(sb), block, write);
+}
+
+/**
+ * apfs_omap_lookup_newest_block - Find newest bno for a virtual object's oid
+ * @sb:		filesystem superblock
+ * @omap:	object map to be searched
+ * @id:		id of the object
+ * @block:	on return, the found block number
+ * @write:	get write access to the object?
+ *
+ * Returns 0 on success or a negative error code in case of failure.
+ */
+int apfs_omap_lookup_newest_block(struct super_block *sb, struct apfs_omap *omap, u64 id, u64 *block, bool write)
+{
+	return apfs_omap_lookup_block_with_xid(sb, omap, id, -1, block, write);
+}
+
 /**
  * apfs_create_omap_rec - Create a record in the volume's omap tree
  * @sb:		filesystem superblock
@@ -261,7 +297,6 @@ int apfs_create_omap_rec(struct super_block *sb, u64 oid, u64 bno)
 	struct apfs_nxsb_info *nxi = APFS_NXI(sb);
 	struct apfs_omap *omap = sbi->s_omap;
 	struct apfs_query *query;
-	struct apfs_key key;
 	struct apfs_omap_key raw_key;
 	struct apfs_omap_val raw_val;
 	int ret;
@@ -269,9 +304,7 @@ int apfs_create_omap_rec(struct super_block *sb, u64 oid, u64 bno)
 	query = apfs_alloc_query(omap->omap_root, NULL /* parent */);
 	if (!query)
 		return -ENOMEM;
-
-	apfs_init_omap_key(oid, nxi->nx_xid, &key);
-	query->key = &key;
+	apfs_init_omap_key(oid, nxi->nx_xid, &query->key);
 	query->flags |= APFS_QUERY_OMAP;
 
 	ret = apfs_btree_query(sb, &query);
@@ -313,15 +346,12 @@ int apfs_delete_omap_rec(struct super_block *sb, u64 oid)
 	struct apfs_nxsb_info *nxi = APFS_NXI(sb);
 	struct apfs_omap *omap = sbi->s_omap;
 	struct apfs_query *query;
-	struct apfs_key key;
 	int ret;
 
 	query = apfs_alloc_query(omap->omap_root, NULL /* parent */);
 	if (!query)
 		return -ENOMEM;
-
-	apfs_init_omap_key(oid, nxi->nx_xid, &key);
-	query->key = &key;
+	apfs_init_omap_key(oid, nxi->nx_xid, &query->key);
 	query->flags |= APFS_QUERY_OMAP;
 
 	ret = apfs_btree_query(sb, &query);
@@ -362,19 +392,28 @@ struct apfs_query *apfs_alloc_query(struct apfs_node *node,
 {
 	struct apfs_query *query;
 
-	query = kmalloc(sizeof(*query), GFP_KERNEL);
+	query = kzalloc(sizeof(*query), GFP_KERNEL);
 	if (!query)
 		return NULL;
 
 	/* To be released by free_query. */
 	query->node = node;
-	query->key = parent ? parent->key : NULL;
-	query->flags = parent ?
-		parent->flags & ~(APFS_QUERY_DONE | APFS_QUERY_NEXT) : 0;
-	query->parent = parent;
-	/* Start the search with the last record and go backwards */
-	query->index = node->records;
-	query->depth = parent ? parent->depth + 1 : 0;
+
+	if (parent) {
+		query->key = parent->key;
+		query->flags = parent->flags & ~(APFS_QUERY_DONE | APFS_QUERY_NEXT);
+		query->parent = parent;
+		query->depth = parent->depth + 1;
+	}
+
+	/*
+	 * We start the search with the last record and go backwards, but
+	 * some queries later use the PREV flag later to list them in order.
+	 */
+	if (query->flags & APFS_QUERY_PREV)
+		query->index = -1;
+	else
+		query->index = node->records;
 
 	return query;
 }
@@ -482,7 +521,8 @@ next_node:
 		 * than enough to map every block.
 		 */
 		apfs_err(sb, "btree is too high");
-		return -EFSCORRUPTED;
+		err = -EFSCORRUPTED;
+		goto fail;
 	}
 
 	err = apfs_node_query(sb, *query);
@@ -494,12 +534,16 @@ next_node:
 		err = apfs_query_set_before_first(sb, query);
 		if (err) {
 			apfs_err(sb, "failed to set before the first record");
-			return err;
+			goto fail;
 		}
-		return -ENODATA;
+		err = -ENODATA;
+		goto fail;
 	} else if (err == -EAGAIN) {
-		if (!(*query)->parent) /* We are at the root of the tree */
-			return -ENODATA;
+		if (!(*query)->parent) {
+			/* We are at the root of the tree */
+			err = -ENODATA;
+			goto fail;
+		}
 
 		/* Move back up one level and continue the query */
 		parent = (*query)->parent;
@@ -508,7 +552,7 @@ next_node:
 		*query = parent;
 		goto next_node;
 	} else if (err) {
-		return err;
+		goto fail;
 	}
 	if (apfs_node_is_leaf((*query)->node)) /* All done */
 		return 0;
@@ -517,14 +561,15 @@ next_node:
 	if (err) {
 		apfs_alert(sb, "bad index block: 0x%llx",
 			   (*query)->node->object.block_nr);
-		return err;
+		goto fail;
 	}
 
 	/* Now go a level deeper and search the child */
 	node = apfs_read_node(sb, child_id, storage, false /* write */);
 	if (IS_ERR(node)) {
 		apfs_err(sb, "failed to read node 0x%llx", child_id);
-		return PTR_ERR(node);
+		err = PTR_ERR(node);
+		goto fail;
 	}
 
 	if (node->object.oid != child_id)
@@ -539,12 +584,20 @@ next_node:
 	if (!*query) {
 		apfs_node_free(node);
 		*query = parent;
-		return -ENOMEM;
+		err = -ENOMEM;
+		goto fail;
 	}
 	node = NULL;
 	goto next_node;
+
+fail:
+	/* Don't leave stale record info here or some callers will use it */
+	(*query)->key_len = (*query)->len = 0;
+	return err;
 }
 
+static int __apfs_btree_replace(struct apfs_query *query, void *key, int key_len, void *val, int val_len);
+
 /**
  * apfs_query_join_transaction - Add the found node to the current transaction
  * @query: query that found the node
@@ -555,11 +608,22 @@ int apfs_query_join_transaction(struct apfs_query *query)
 	struct super_block *sb = node->object.sb;
 	u64 oid = node->object.oid;
 	u32 storage = apfs_query_storage(query);
+	struct apfs_obj_phys *raw = NULL;
+
+	/*
+	 * Ephemeral objects are checkpoint data, and all of their xids get
+	 * updated on commit. There is no real need to do it here as well, but
+	 * it's better for consistency with the other object types.
+	 */
+	if (storage == APFS_OBJ_EPHEMERAL) {
+		ASSERT(node->object.ephemeral);
+		raw = (void *)node->object.data;
+		raw->o_xid = cpu_to_le64(APFS_NXI(sb)->nx_xid);
+		return 0;
+	}
 
 	if (buffer_trans(node->object.o_bh)) /* Already in the transaction */
 		return 0;
-	/* Ephemeral objects are always checkpoint data */
-	ASSERT(storage != APFS_OBJ_EPHEMERAL);
 	/* Root nodes should join the transaction before the query is created */
 	ASSERT(!apfs_node_is_root(node));
 
@@ -575,9 +639,7 @@ int apfs_query_join_transaction(struct apfs_query *query)
 		__le64 bno = cpu_to_le64(node->object.block_nr);
 
 		/* The parent node needs to report the new location */
-		return apfs_btree_replace(query->parent,
-					  NULL /* key */, 0 /* key_len */,
-					  &bno, sizeof(bno));
+		return __apfs_btree_replace(query->parent, NULL /* key */, 0 /* key_len */, &bno, sizeof(bno));
 	}
 	return 0;
 }
@@ -604,9 +666,7 @@ static void apfs_btree_change_rec_count(struct apfs_query *query, int change,
 		ASSERT(!key_len && !val_len);
 	ASSERT(apfs_node_is_leaf(query->node));
 
-	while (query->parent)
-		query = query->parent;
-	root = query->node;
+	root = apfs_query_root(query);
 	ASSERT(apfs_node_is_root(root));
 
 	sb = root->object.sb;
@@ -637,11 +697,7 @@ void apfs_btree_change_node_count(struct apfs_query *query, int change)
 	struct apfs_btree_node_phys *root_raw;
 	struct apfs_btree_info *info;
 
-	ASSERT(!apfs_node_is_leaf(query->node));
-
-	while (query->parent)
-		query = query->parent;
-	root = query->node;
+	root = apfs_query_root(query);
 	ASSERT(apfs_node_is_root(root));
 
 	sb = root->object.sb;
@@ -654,91 +710,73 @@ void apfs_btree_change_node_count(struct apfs_query *query, int change)
 
 /**
  * apfs_query_refresh - Recreate a catalog query invalidated by node splits
- * @old_query: the catalog query to refresh
+ * @old_query:	query chain to refresh
+ * @root:	root node of the query chain
+ * @nodata:	is the query expected to find nothing?
  *
  * On success, @old_query is left pointing to the same leaf record, but with
  * valid ancestor queries as well. Returns a negative error code in case of
  * failure, or 0 on success.
  */
-static int apfs_query_refresh(struct apfs_query *old_query)
+static int apfs_query_refresh(struct apfs_query *old_query, struct apfs_node *root, bool nodata)
 {
-	struct apfs_node *node = old_query->node;
-	struct super_block *sb = node->object.sb;
-	char *raw = node->object.data;
-	struct apfs_query *new_query, *ancestor;
-	struct apfs_key new_key;
-	bool hashed = apfs_is_normalization_insensitive(sb);
+	struct super_block *sb = NULL;
+	struct apfs_query *new_query = NULL;
 	int err = 0;
 
-	/*
-	 * This function is for handling multiple splits of the same node,
-	 * which are only expected when large inline xattr values are involved.
-	 */
-	if ((old_query->flags & APFS_QUERY_TREE_MASK) != APFS_QUERY_CAT) {
-		apfs_err(sb, "non-catalog query");
+	sb = root->object.sb;
+
+	if (!apfs_node_is_leaf(old_query->node)) {
+		apfs_alert(sb, "attempting refresh of non-leaf query");
 		return -EFSCORRUPTED;
 	}
-	if (!apfs_node_is_leaf(node)) {
-		apfs_err(sb, "non-leaf query");
+	if (apfs_node_is_root(old_query->node)) {
+		apfs_alert(sb, "attempting refresh of root query");
 		return -EFSCORRUPTED;
 	}
 
-	/* Build a new query that points exactly to the same key */
-	err = apfs_read_cat_key(raw + old_query->key_off, old_query->key_len, &new_key, hashed);
-	if (err) {
-		apfs_err(sb, "failed to read the key");
-		return err;
-	}
-	new_query = apfs_alloc_query(APFS_SB(sb)->s_cat_root, NULL /* parent */);
+	new_query = apfs_alloc_query(root, NULL /* parent */);
 	if (!new_query)
 		return -ENOMEM;
-	new_query->key = &new_key;
-	new_query->flags = APFS_QUERY_CAT | APFS_QUERY_EXACT;
+	new_query->key = old_query->key;
+	new_query->flags = old_query->flags & ~(APFS_QUERY_DONE | APFS_QUERY_NEXT);
 
 	err = apfs_btree_query(sb, &new_query);
-	if (err) {
-		apfs_err(sb, "failed to rerun");
+	if (!nodata && err == -ENODATA) {
+		apfs_err(sb, "record should exist");
+		err = -EFSCORRUPTED;
 		goto fail;
 	}
-
-	/* Set the original query flags and key on the new query */
-	for (ancestor = new_query; ancestor; ancestor = ancestor->parent) {
-		ancestor->flags = old_query->flags;
-		ancestor->key = old_query->key;
+	if (err && err != -ENODATA) {
+		apfs_err(sb, "failed to rerun");
+		goto fail;
 	}
+	err = 0;
 
 	/* Replace the parent of the original query with the new valid one */
 	apfs_free_query(old_query->parent);
 	old_query->parent = new_query->parent;
 	new_query->parent = NULL;
 
+	/*
+	 * The records may have moved around so update this too. TODO: rework
+	 * the query struct so this stuff is not needed.
+	 */
+	ASSERT(old_query->node->object.oid == new_query->node->object.oid);
+	old_query->index = new_query->index;
+	old_query->key_off = new_query->key_off;
+	old_query->key_len = new_query->key_len;
+	old_query->off = new_query->off;
+	old_query->len = new_query->len;
+	old_query->depth = new_query->depth;
+
 fail:
 	apfs_free_query(new_query);
 	return err;
 }
 
 /**
- * apfs_query_is_orphan - Check if all of a query's ancestors are set
- * @query: the query to check
- *
- * A query may lose some of its ancestors during a node split. This can be
- * used to check if that has happened.
- *
- * TODO: running this check early on the insert, remove and replace functions
- * could be used to simplify several callers that do their own query refresh.
- */
-static bool apfs_query_is_orphan(const struct apfs_query *query)
-{
-	while (query) {
-		if (apfs_node_is_root(query->node))
-			return false;
-		query = query->parent;
-	}
-	return true;
-}
-
-/**
- * apfs_btree_insert - Insert a new record into a b-tree
+ * __apfs_btree_insert - Insert a new record into a b-tree (at any level)
  * @query:	query run to search for the record
  * @key:	on-disk record key
  * @key_len:	length of @key
@@ -747,20 +785,18 @@ static bool apfs_query_is_orphan(const struct apfs_query *query)
  *
  * The new record is placed right after the one found by @query.  On success,
  * returns 0 and sets @query to the new record; returns a negative error code
- * in case of failure.
+ * in case of failure, which may be -EAGAIN if a split happened and the caller
+ * must retry.
  */
-int apfs_btree_insert(struct apfs_query *query, void *key, int key_len,
-		      void *val, int val_len)
+int __apfs_btree_insert(struct apfs_query *query, void *key, int key_len, void *val, int val_len)
 {
 	struct apfs_node *node = query->node;
 	struct super_block *sb = node->object.sb;
 	struct apfs_btree_node_phys *node_raw;
+	int needed_room;
 	int err;
 
-	/* Do this first, or node splits may cause @query->parent to be gone */
-	if (apfs_node_is_leaf(node))
-		apfs_btree_change_rec_count(query, 1 /* change */,
-					    key_len, val_len);
+	apfs_assert_query_is_valid(query);
 
 	err = apfs_query_join_transaction(query);
 	if (err) {
@@ -768,52 +804,100 @@ int apfs_btree_insert(struct apfs_query *query, void *key, int key_len,
 		return err;
 	}
 
-again:
 	node = query->node;
 	node_raw = (void *)node->object.data;
 	apfs_assert_in_transaction(node->object.sb, &node_raw->btn_o);
 
-	err = apfs_node_insert(query, key, key_len, val, val_len);
-	if (err == -ENOSPC) {
-		if (!query->parent && !apfs_node_is_root(node)) {
-			err = apfs_query_refresh(query);
-			if (err) {
-				apfs_err(sb, "query refresh failed");
-				return err;
-			}
-			if (node->records == 1) {
-				/* The new record just won't fit in the node */
-				return apfs_create_single_rec_node(query, key, key_len, val, val_len);
-			}
+	needed_room = key_len + val_len;
+	if (!apfs_node_has_room(node, needed_room, false /* replace */)) {
+		if (node->records == 1) {
+			/* The new record just won't fit in the node */
+			err = apfs_create_single_rec_node(query, key, key_len, val, val_len);
+			if (err && err != -EAGAIN)
+				apfs_err(sb, "failed to create single-record node");
+			return err;
 		}
 		err = apfs_node_split(query);
-		if (err) {
+		if (err && err != -EAGAIN) {
 			apfs_err(sb, "node split failed");
 			return err;
 		}
-		goto again;
-	} else if (err) {
+		return -EAGAIN;
+	}
+
+	apfs_assert_query_is_valid(query);
+
+	if (query->parent && query->index == -1) {
+		/* We are about to insert a record before all others */
+		err = __apfs_btree_replace(query->parent, key, key_len, NULL /* val */, 0 /* val_len */);
+		if (err) {
+			if (err != -EAGAIN)
+				apfs_err(sb, "parent update failed");
+			return err;
+		}
+	}
+
+	apfs_assert_query_is_valid(query);
+
+	err = apfs_node_insert(query, key, key_len, val, val_len);
+	if (err) {
 		apfs_err(sb, "node record insertion failed");
 		return err;
 	}
+	return 0;
+}
 
-	/* This can only happen when we insert a record before all others */
-	if (query->parent && query->index == 0) {
-		err = apfs_btree_replace(query->parent, key, key_len,
-					 NULL /* val */, 0 /* val_len */);
-		if (err)
-			apfs_err(sb, "parent update failed");
+/**
+ * apfs_btree_insert - Insert a new record into a b-tree leaf
+ * @query:	query run to search for the record
+ * @key:	on-disk record key
+ * @key_len:	length of @key
+ * @val:	on-disk record value (NULL for ghost records)
+ * @val_len:	length of @val (0 for ghost records)
+ *
+ * The new record is placed right after the one found by @query.  On success,
+ * returns 0 and sets @query to the new record; returns a negative error code
+ * in case of failure.
+ */
+int apfs_btree_insert(struct apfs_query *query, void *key, int key_len, void *val, int val_len)
+{
+	struct super_block *sb = NULL;
+	struct apfs_node *root = NULL, *leaf = NULL;
+	int err;
+
+	root = apfs_query_root(query);
+	ASSERT(apfs_node_is_root(root));
+	leaf = query->node;
+	ASSERT(apfs_node_is_leaf(leaf));
+	sb = root->object.sb;
+
+	while (true) {
+		err = __apfs_btree_insert(query, key, key_len, val, val_len);
+		if (err != -EAGAIN) {
+			if (err)
+				return err;
+			break;
+		}
+		err = apfs_query_refresh(query, root, true /* nodata */);
+		if (err) {
+			apfs_err(sb, "query refresh failed");
+			return err;
+		}
 	}
-	return err;
+
+	apfs_assert_query_is_valid(query);
+	apfs_btree_change_rec_count(query, 1 /* change */, key_len, val_len);
+	return 0;
 }
 
 /**
- * apfs_btree_remove - Remove a record from a b-tree
+ * __apfs_btree_remove - Remove a record from a b-tree (at any level)
  * @query:	exact query that found the record
  *
- * Returns 0 on success, or a negative error code in case of failure.
+ * Returns 0 on success, or a negative error code in case of failure, which may
+ * be -EAGAIN if a split happened and the caller must retry.
  */
-int apfs_btree_remove(struct apfs_query *query)
+static int __apfs_btree_remove(struct apfs_query *query)
 {
 	struct apfs_node *node = query->node;
 	struct super_block *sb = node->object.sb;
@@ -821,12 +905,7 @@ int apfs_btree_remove(struct apfs_query *query)
 	int later_entries = node->records - query->index - 1;
 	int err;
 
-	/* Do this first, or node splits may cause @query->parent to be gone */
-	if (apfs_node_is_leaf(node))
-		apfs_btree_change_rec_count(query, -1 /* change */,
-					    0 /* key_len */, 0 /* val_len */);
-	else
-		apfs_btree_change_node_count(query, -1 /* change */);
+	apfs_assert_query_is_valid(query);
 
 	err = apfs_query_join_transaction(query);
 	if (err) {
@@ -838,16 +917,26 @@ int apfs_btree_remove(struct apfs_query *query)
 	node_raw = (void *)query->node->object.data;
 	apfs_assert_in_transaction(node->object.sb, &node_raw->btn_o);
 
-	if (node->records == 1) {
-		if (query->parent) {
-			/* Just get rid of the node */
-			return apfs_delete_node(query);
+	if (query->parent && node->records == 1) {
+		/* Just get rid of the node */
+		err = __apfs_btree_remove(query->parent);
+		if (err == -EAGAIN)
+			return -EAGAIN;
+		if (err) {
+			apfs_err(sb, "parent index removal failed");
+			return err;
 		}
-		/* All descendants are gone, root is the whole tree */
-		node_raw->btn_level = 0;
-		node->flags |= APFS_BTNODE_LEAF;
+		apfs_btree_change_node_count(query, -1 /* change */);
+		err = apfs_delete_node(node, query->flags & APFS_QUERY_TREE_MASK);
+		if (err) {
+			apfs_err(sb, "node deletion failed");
+			return err;
+		}
+		return 0;
 	}
 
+	apfs_assert_query_is_valid(query);
+
 	/* The first key in a node must match the parent record's */
 	if (query->parent && query->index == 0) {
 		int first_key_len, first_key_off;
@@ -858,14 +947,17 @@ int apfs_btree_remove(struct apfs_query *query)
 			return -EFSCORRUPTED;
 		key = (void *)node_raw + first_key_off;
 
-		err = apfs_btree_replace(query->parent, key, first_key_len,
-					 NULL /* val */, 0 /* val_len */);
+		err = __apfs_btree_replace(query->parent, key, first_key_len, NULL /* val */, 0 /* val_len */);
+		if (err == -EAGAIN)
+			return -EAGAIN;
 		if (err) {
 			apfs_err(sb, "parent update failed");
 			return err;
 		}
 	}
 
+	apfs_assert_query_is_valid(query);
+
 	/* Remove the entry from the table of contents */
 	if (apfs_node_has_fixed_kv_size(node)) {
 		struct apfs_kvoff *toc_entry;
@@ -887,6 +979,11 @@ int apfs_btree_remove(struct apfs_query *query)
 	apfs_node_free_range(node, query->off, query->len);
 
 	--node->records;
+	if (node->records == 0) {
+		/* All descendants are gone, root is the whole tree */
+		node_raw->btn_level = 0;
+		node->flags |= APFS_BTNODE_LEAF;
+	}
 	apfs_update_node(node);
 
 	--query->index;
@@ -894,7 +991,44 @@ int apfs_btree_remove(struct apfs_query *query)
 }
 
 /**
- * apfs_btree_replace - Replace a record in a b-tree
+ * apfs_btree_remove - Remove a record from a b-tree leaf
+ * @query:	exact query that found the record
+ *
+ * Returns 0 on success, or a negative error code in case of failure.
+ */
+int apfs_btree_remove(struct apfs_query *query)
+{
+	struct super_block *sb = NULL;
+	struct apfs_node *root = NULL, *leaf = NULL;
+	int err;
+
+	root = apfs_query_root(query);
+	ASSERT(apfs_node_is_root(root));
+	leaf = query->node;
+	ASSERT(apfs_node_is_leaf(leaf));
+	sb = root->object.sb;
+
+	while (true) {
+		err = __apfs_btree_remove(query);
+		if (err != -EAGAIN) {
+			if (err)
+				return err;
+			break;
+		}
+		err = apfs_query_refresh(query, root, false /* nodata */);
+		if (err) {
+			apfs_err(sb, "query refresh failed");
+			return err;
+		}
+	}
+
+	apfs_assert_query_is_valid(query);
+	apfs_btree_change_rec_count(query, -1 /* change */, 0 /* key_len */, 0 /* val_len */);
+	return 0;
+}
+
+/**
+ * __apfs_btree_replace - Replace a record in a b-tree (at any level)
  * @query:	exact query that found the record
  * @key:	new on-disk record key (NULL if unchanged)
  * @key_len:	length of @key
@@ -906,28 +1040,19 @@ int apfs_btree_remove(struct apfs_query *query)
  * same length: it can just be overwritten in place.
  *
  * Returns 0 on success, and @query is left pointing to the same record; returns
- * a negative error code in case of failure.
+ * a negative error code in case of failure, which may be -EAGAIN if a split
+ * happened and the caller must retry.
  */
-int apfs_btree_replace(struct apfs_query *query, void *key, int key_len,
-		       void *val, int val_len)
+static int __apfs_btree_replace(struct apfs_query *query, void *key, int key_len, void *val, int val_len)
 {
 	struct apfs_node *node = query->node;
 	struct super_block *sb = node->object.sb;
 	struct apfs_btree_node_phys *node_raw;
+	int needed_room;
 	int err;
 
 	ASSERT(key || val);
-
-	/* Do this first, or node splits may cause @query->parent to be gone */
-	if (apfs_node_is_leaf(node)) {
-		if (apfs_query_is_orphan(query)) {
-			err = apfs_query_refresh(query);
-			if (err)
-				return err;
-		}
-		apfs_btree_change_rec_count(query, 0 /* change */,
-					    key_len, val_len);
-	}
+	apfs_assert_query_is_valid(query);
 
 	err = apfs_query_join_transaction(query);
 	if (err) {
@@ -935,41 +1060,115 @@ int apfs_btree_replace(struct apfs_query *query, void *key, int key_len,
 		return err;
 	}
 
-again:
 	node = query->node;
 	node_raw = (void *)node->object.data;
 	apfs_assert_in_transaction(sb, &node_raw->btn_o);
 
+	needed_room = key_len + val_len;
+	/* We can reuse the space of the replaced key/value */
+	if (key)
+		needed_room -= query->key_len;
+	if (val)
+		needed_room -= query->len;
+
+	if (!apfs_node_has_room(node, needed_room, true /* replace */)) {
+		if (node->records == 1) {
+			apfs_alert(sb, "no room in empty node?");
+			return -EFSCORRUPTED;
+		}
+		err = apfs_node_split(query);
+		if (err && err != -EAGAIN) {
+			apfs_err(sb, "node split failed");
+			return err;
+		}
+		return -EAGAIN;
+	}
+
+	apfs_assert_query_is_valid(query);
+
 	/* The first key in a node must match the parent record's */
 	if (key && query->parent && query->index == 0) {
-		err = apfs_btree_replace(query->parent, key, key_len,
-					 NULL /* val */, 0 /* val_len */);
+		err = __apfs_btree_replace(query->parent, key, key_len, NULL /* val */, 0 /* val_len */);
 		if (err) {
-			apfs_err(sb, "parent update failed");
+			if (err != -EAGAIN)
+				apfs_err(sb, "parent update failed");
 			return err;
 		}
 	}
 
+	apfs_assert_query_is_valid(query);
+
 	err = apfs_node_replace(query, key, key_len, val, val_len);
-	if (err == -ENOSPC) {
-		if (!query->parent && !apfs_node_is_root(node)) {
-			if (node->records == 1) {
-				/* Node is defragmented, ENOSPC is absurd */
-				apfs_alert(sb, "absurd ENOSPC in empty node");
-				return -EFSCORRUPTED;
-			}
-			err = apfs_query_refresh(query);
-			if (err) {
-				apfs_err(sb, "query refresh failed");
+	if (err) {
+		apfs_err(sb, "node record replacement failed");
+		return err;
+	}
+	return 0;
+}
+
+/**
+ * apfs_btree_replace - Replace a record in a b-tree leaf
+ * @query:	exact query that found the record
+ * @key:	new on-disk record key (NULL if unchanged)
+ * @key_len:	length of @key
+ * @val:	new on-disk record value (NULL if unchanged)
+ * @val_len:	length of @val
+ *
+ * It's important that the order of the records is not changed by the new @key.
+ * This function is not needed to replace an old value with a new one of the
+ * same length: it can just be overwritten in place.
+ *
+ * Returns 0 on success, and @query is left pointing to the same record; returns
+ * a negative error code in case of failure.
+ */
+int apfs_btree_replace(struct apfs_query *query, void *key, int key_len, void *val, int val_len)
+{
+	struct super_block *sb = NULL;
+	struct apfs_node *root = NULL, *leaf = NULL;
+	int err;
+
+	root = apfs_query_root(query);
+	ASSERT(apfs_node_is_root(root));
+	leaf = query->node;
+	ASSERT(apfs_node_is_leaf(leaf));
+	sb = root->object.sb;
+
+	while (true) {
+		err = __apfs_btree_replace(query, key, key_len, val, val_len);
+		if (err != -EAGAIN) {
+			if (err)
 				return err;
-			}
+			break;
 		}
-		err = apfs_node_split(query);
+		err = apfs_query_refresh(query, root, false /* nodata */);
 		if (err) {
-			apfs_err(sb, "node split failed");
+			apfs_err(sb, "query refresh failed");
 			return err;
 		}
-		goto again;
 	}
-	return err;
+
+	apfs_assert_query_is_valid(query);
+	apfs_btree_change_rec_count(query, 0 /* change */, key_len, val_len);
+	return 0;
+}
+
+/**
+ * apfs_query_direct_forward - Set a query to start listing records forwards
+ * @query: a successfully executed query
+ *
+ * Multiple queries list records backwards, but queries marked with this
+ * function after execution will go in the opposite direction.
+ */
+void apfs_query_direct_forward(struct apfs_query *query)
+{
+	if (query->flags & APFS_QUERY_PREV)
+		return;
+
+	apfs_assert_query_is_valid(query);
+	ASSERT(apfs_node_is_leaf(query->node));
+
+	while (query) {
+		query->flags |= APFS_QUERY_PREV;
+		query = query->parent;
+	}
 }
diff --git a/compress.c b/compress.c
index 7f73398..a360506 100644
--- a/compress.c
+++ b/compress.c
@@ -417,16 +417,16 @@ static int apfs_compress_read_folio(struct file *filp, struct folio *folio)
 static int apfs_compress_readpage(struct file *filp, struct page *page)
 {
 #endif
-	void *addr = NULL;
+	char *addr = NULL;
 	ssize_t ret;
 	loff_t off;
 
 	/* Mostly copied from ext4_read_inline_page() */
 	off = page->index << PAGE_SHIFT;
-	addr = kmap_atomic(page);
+	addr = kmap(page);
 	ret = apfs_compress_file_read_page(filp, addr, off);
 	flush_dcache_page(page);
-	kunmap_atomic(addr);
+	kunmap(page);
 	if (ret >= 0) {
 		zero_user_segment(page, ret, PAGE_SIZE);
 		SetPageUptodate(page);
diff --git a/dir.c b/dir.c
index fbaed30..416f42f 100644
--- a/dir.c
+++ b/dir.c
@@ -99,24 +99,25 @@ static struct apfs_query *apfs_dentry_lookup(struct inode *dir,
 {
 	struct super_block *sb = dir->i_sb;
 	struct apfs_sb_info *sbi = APFS_SB(sb);
-	struct apfs_key key;
 	struct apfs_query *query;
 	u64 cnid = apfs_ino(dir);
 	bool hashed = apfs_is_normalization_insensitive(sb);
 	int err;
 
-	apfs_init_drec_key(sb, cnid, child->name, child->len, &key);
-
 	query = apfs_alloc_query(sbi->s_cat_root, NULL /* parent */);
 	if (!query)
 		return ERR_PTR(-ENOMEM);
-	query->key = &key;
+	apfs_init_drec_key(sb, cnid, child->name, child->len, &query->key);
 
 	/*
 	 * Distinct filenames in the same directory may (rarely) share the same
-	 * hash.  The query code cannot handle that because their order in the
-	 * b-tree would	depend on their unnormalized original names.  Just get
+	 * hash. The query code cannot handle that because their order in the
+	 * b-tree would	depend on their unnormalized original names. Just get
 	 * all the candidates and check them one by one.
+	 *
+	 * This is very wasteful for normalization-sensitive filesystems: there
+	 * are no hashes so we just check every single file in the directory for
+	 * no reason. This would be easy to avoid but does it matter? (TODO)
 	 */
 	query->flags |= APFS_QUERY_CAT | APFS_QUERY_ANY_NAME | APFS_QUERY_EXACT;
 	do {
@@ -128,6 +129,14 @@ static struct apfs_query *apfs_dentry_lookup(struct inode *dir,
 			goto fail;
 	} while (unlikely(apfs_filename_cmp(sb, child->name, child->len, drec->name, drec->name_len)));
 
+	/*
+	 * We may need to refresh the query later, but the refresh code doesn't
+	 * know how to deal with hash collisions. Instead set the key to the
+	 * unnormalized name and pretend that this was never a multiple query
+	 * in the first place.
+	 */
+	query->key.name = drec->name;
+	query->flags &= ~(APFS_QUERY_MULTIPLE | APFS_QUERY_DONE | APFS_QUERY_NEXT);
 	return query;
 
 fail:
@@ -173,7 +182,6 @@ static int apfs_readdir(struct file *file, struct dir_context *ctx)
 	struct super_block *sb = inode->i_sb;
 	struct apfs_sb_info *sbi = APFS_SB(sb);
 	struct apfs_nxsb_info *nxi = APFS_NXI(sb);
-	struct apfs_key key;
 	struct apfs_query *query;
 	u64 cnid = apfs_ino(inode);
 	loff_t pos;
@@ -193,8 +201,7 @@ static int apfs_readdir(struct file *file, struct dir_context *ctx)
 	}
 
 	/* We want all the children for the cnid, regardless of the name */
-	apfs_init_drec_key(sb, cnid, NULL /* name */, 0 /* name_len */, &key);
-	query->key = &key;
+	apfs_init_drec_key(sb, cnid, NULL /* name */, 0 /* name_len */, &query->key);
 	query->flags = APFS_QUERY_CAT | APFS_QUERY_MULTIPLE | APFS_QUERY_EXACT;
 
 	pos = ctx->pos - 2;
@@ -361,7 +368,6 @@ static int apfs_create_dentry_rec(struct inode *inode, struct qstr *qname,
 {
 	struct super_block *sb = inode->i_sb;
 	struct apfs_sb_info *sbi = APFS_SB(sb);
-	struct apfs_key key;
 	struct apfs_query *query;
 	void *raw_key = NULL;
 	struct apfs_drec_val *raw_val = NULL;
@@ -369,21 +375,20 @@ static int apfs_create_dentry_rec(struct inode *inode, struct qstr *qname,
 	bool hashed = apfs_is_normalization_insensitive(sb);
 	int ret;
 
-	apfs_init_drec_key(sb, parent_id, qname->name, qname->len, &key);
 	query = apfs_alloc_query(sbi->s_cat_root, NULL /* parent */);
 	if (!query)
 		return -ENOMEM;
-	query->key = &key;
+	apfs_init_drec_key(sb, parent_id, qname->name, qname->len, &query->key);
 	query->flags |= APFS_QUERY_CAT;
 
 	ret = apfs_btree_query(sb, &query);
 	if (ret && ret != -ENODATA) {
-		apfs_err(sb, "query failed in dir 0x%llx (hash 0x%llx)", parent_id, key.number);
+		apfs_err(sb, "query failed in dir 0x%llx (hash 0x%llx)", parent_id, query->key.number);
 		goto fail;
 	}
 
 	if (hashed)
-		key_len = apfs_build_dentry_hashed_key(qname, key.number, parent_id,
+		key_len = apfs_build_dentry_hashed_key(qname, query->key.number, parent_id,
 						       (struct apfs_drec_hashed_key **)&raw_key);
 	else
 		key_len = apfs_build_dentry_unhashed_key(qname, parent_id,
@@ -401,7 +406,7 @@ static int apfs_create_dentry_rec(struct inode *inode, struct qstr *qname,
 	/* TODO: deal with hash collisions */
 	ret = apfs_btree_insert(query, raw_key, key_len, raw_val, val_len);
 	if (ret)
-		apfs_err(sb, "insertion failed in dir 0x%llx (hash 0x%llx)", parent_id, key.number);
+		apfs_err(sb, "insertion failed in dir 0x%llx (hash 0x%llx)", parent_id, query->key.number);
 
 fail:
 	kfree(raw_val);
@@ -453,18 +458,16 @@ static int apfs_create_sibling_link_rec(struct dentry *dentry,
 {
 	struct super_block *sb = dentry->d_sb;
 	struct apfs_sb_info *sbi = APFS_SB(sb);
-	struct apfs_key key;
 	struct apfs_query *query = NULL;
 	struct apfs_sibling_link_key raw_key;
 	struct apfs_sibling_val *raw_val;
 	int val_len;
 	int ret;
 
-	apfs_init_sibling_link_key(apfs_ino(inode), sibling_id, &key);
 	query = apfs_alloc_query(sbi->s_cat_root, NULL /* parent */);
 	if (!query)
 		return -ENOMEM;
-	query->key = &key;
+	apfs_init_sibling_link_key(apfs_ino(inode), sibling_id, &query->key);
 	query->flags |= APFS_QUERY_CAT;
 
 	ret = apfs_btree_query(sb, &query);
@@ -503,17 +506,15 @@ static int apfs_create_sibling_map_rec(struct dentry *dentry,
 {
 	struct super_block *sb = dentry->d_sb;
 	struct apfs_sb_info *sbi = APFS_SB(sb);
-	struct apfs_key key;
 	struct apfs_query *query = NULL;
 	struct apfs_sibling_map_key raw_key;
 	struct apfs_sibling_map_val raw_val;
 	int ret;
 
-	apfs_init_sibling_map_key(sibling_id, &key);
 	query = apfs_alloc_query(sbi->s_cat_root, NULL /* parent */);
 	if (!query)
 		return -ENOMEM;
-	query->key = &key;
+	apfs_init_sibling_map_key(sibling_id, &query->key);
 	query->flags |= APFS_QUERY_CAT;
 
 	ret = apfs_btree_query(sb, &query);
@@ -603,8 +604,10 @@ static int apfs_create_dentry(struct dentry *dentry, struct inode *inode)
 	/* Now update the parent inode */
 #if LINUX_VERSION_CODE < KERNEL_VERSION(6, 6, 0)
 	parent->i_mtime = parent->i_ctime = current_time(inode);
-#else
+#elif LINUX_VERSION_CODE < KERNEL_VERSION(6, 7, 0)
 	parent->i_mtime = inode_set_ctime_current(parent);
+#else
+	inode_set_mtime_to_ts(parent, inode_set_ctime_current(parent));
 #endif
 	++APFS_I(parent)->i_nchildren;
 	apfs_inode_join_transaction(parent->i_sb, parent);
@@ -923,17 +926,15 @@ static int apfs_delete_sibling_link_rec(struct dentry *dentry, u64 sibling_id)
 	struct super_block *sb = dentry->d_sb;
 	struct apfs_sb_info *sbi = APFS_SB(sb);
 	struct inode *inode = d_inode(dentry);
-	struct apfs_key key;
 	struct apfs_query *query = NULL;
 	int ret;
 
 	ASSERT(sibling_id);
 
-	apfs_init_sibling_link_key(apfs_ino(inode), sibling_id, &key);
 	query = apfs_alloc_query(sbi->s_cat_root, NULL /* parent */);
 	if (!query)
 		return -ENOMEM;
-	query->key = &key;
+	apfs_init_sibling_link_key(apfs_ino(inode), sibling_id, &query->key);
 	query->flags |= APFS_QUERY_CAT | APFS_QUERY_EXACT;
 
 	ret = apfs_btree_query(sb, &query);
@@ -966,17 +967,15 @@ static int apfs_delete_sibling_map_rec(struct dentry *dentry, u64 sibling_id)
 {
 	struct super_block *sb = dentry->d_sb;
 	struct apfs_sb_info *sbi = APFS_SB(sb);
-	struct apfs_key key;
 	struct apfs_query *query = NULL;
 	int ret;
 
 	ASSERT(sibling_id);
 
-	apfs_init_sibling_map_key(sibling_id, &key);
 	query = apfs_alloc_query(sbi->s_cat_root, NULL /* parent */);
 	if (!query)
 		return -ENOMEM;
-	query->key = &key;
+	apfs_init_sibling_map_key(sibling_id, &query->key);
 	query->flags |= APFS_QUERY_CAT | APFS_QUERY_EXACT;
 
 	ret = apfs_btree_query(sb, &query);
@@ -1040,8 +1039,10 @@ static int apfs_delete_dentry(struct dentry *dentry)
 	/* Now update the parent inode */
 #if LINUX_VERSION_CODE < KERNEL_VERSION(6, 6, 0)
 	parent->i_mtime = parent->i_ctime = current_time(parent);
-#else
+#elif LINUX_VERSION_CODE < KERNEL_VERSION(6, 7, 0)
 	parent->i_mtime = inode_set_ctime_current(parent);
+#else
+	inode_set_mtime_to_ts(parent, inode_set_ctime_current(parent));
 #endif
 	--APFS_I(parent)->i_nchildren;
 	apfs_inode_join_transaction(sb, parent);
@@ -1119,18 +1120,14 @@ static int apfs_find_primary_link(struct inode *inode, char **name, u64 *parent)
 {
 	struct super_block *sb = inode->i_sb;
 	struct apfs_sb_info *sbi = APFS_SB(sb);
-	struct apfs_key key;
 	struct apfs_query *query;
 	int err;
 
 	query = apfs_alloc_query(sbi->s_cat_root, NULL /* parent */);
 	if (!query)
 		return -ENOMEM;
-
-	apfs_init_sibling_link_key(apfs_ino(inode), 0 /* sibling_id */, &key);
-	query->key = &key;
-	query->flags |= APFS_QUERY_CAT | APFS_QUERY_ANY_NUMBER |
-			APFS_QUERY_EXACT;
+	apfs_init_sibling_link_key(apfs_ino(inode), 0 /* sibling_id */, &query->key);
+	query->flags |= APFS_QUERY_CAT | APFS_QUERY_ANY_NUMBER | APFS_QUERY_EXACT;
 
 	/* The primary link is the one with the lowest sibling id */
 	*name = NULL;
@@ -1161,13 +1158,13 @@ fail:
 
 /**
  * apfs_orphan_name - Get the name for an orphan inode's invisible link
- * @inode: the vfs inode
- * @qname: on return, the name assigned to the link
+ * @ino:	the inode number
+ * @qname:	on return, the name assigned to the link
  *
  * Returns 0 on success; the caller must remember to free @qname->name after
  * use.  Returns a negative error code in case of failure.
  */
-static int apfs_orphan_name(struct inode *inode, struct qstr *qname)
+static int apfs_orphan_name(u64 ino, struct qstr *qname)
 {
 	int max_len;
 	char *name;
@@ -1177,7 +1174,7 @@ static int apfs_orphan_name(struct inode *inode, struct qstr *qname)
 	name = kmalloc(max_len, GFP_KERNEL);
 	if (!name)
 		return -ENOMEM;
-	qname->len = snprintf(name, max_len, "0x%llx-dead", apfs_ino(inode));
+	qname->len = snprintf(name, max_len, "0x%llx-dead", ino);
 	qname->name = name;
 	return 0;
 }
@@ -1196,7 +1193,7 @@ static int apfs_create_orphan_link(struct inode *inode)
 	struct qstr qname;
 	int err = 0;
 
-	err = apfs_orphan_name(inode, &qname);
+	err = apfs_orphan_name(apfs_ino(inode), &qname);
 	if (err)
 		return err;
 	err = apfs_create_dentry_rec(inode, &qname, apfs_ino(priv_dir), 0 /* sibling_id */);
@@ -1208,8 +1205,10 @@ static int apfs_create_orphan_link(struct inode *inode)
 	/* Now update the child count for private-dir */
 #if LINUX_VERSION_CODE < KERNEL_VERSION(6, 6, 0)
 	priv_dir->i_mtime = priv_dir->i_ctime = current_time(priv_dir);
-#else
+#elif LINUX_VERSION_CODE < KERNEL_VERSION(6, 7, 0)
 	priv_dir->i_mtime = inode_set_ctime_current(priv_dir);
+#else
+	inode_set_mtime_to_ts(priv_dir, inode_set_ctime_current(priv_dir));
 #endif
 	++APFS_I(priv_dir)->i_nchildren;
 	apfs_inode_join_transaction(sb, priv_dir);
@@ -1237,7 +1236,7 @@ int apfs_delete_orphan_link(struct inode *inode)
 	struct apfs_drec drec;
 	int err;
 
-	err = apfs_orphan_name(inode, &qname);
+	err = apfs_orphan_name(apfs_ino(inode), &qname);
 	if (err)
 		return err;
 
@@ -1257,8 +1256,10 @@ int apfs_delete_orphan_link(struct inode *inode)
 	/* Now update the child count for private-dir */
 #if LINUX_VERSION_CODE < KERNEL_VERSION(6, 6, 0)
 	priv_dir->i_mtime = priv_dir->i_ctime = current_time(priv_dir);
-#else
+#elif LINUX_VERSION_CODE < KERNEL_VERSION(6, 7, 0)
 	priv_dir->i_mtime = inode_set_ctime_current(priv_dir);
+#else
+	inode_set_mtime_to_ts(priv_dir, inode_set_ctime_current(priv_dir));
 #endif
 	--APFS_I(priv_dir)->i_nchildren;
 	apfs_inode_join_transaction(sb, priv_dir);
@@ -1480,3 +1481,64 @@ out_abort:
 	apfs_transaction_abort(sb);
 	return err;
 }
+
+/**
+ * apfs_any_orphan_ino - Find the inode number for any orphaned regular file
+ * @sb:		filesytem superblock
+ * @ino_p:	on return, the inode number found
+ *
+ * Returns 0 on success, or a negative error code in case of failure, which may
+ * be -ENODATA if there are no orphan files.
+ */
+u64 apfs_any_orphan_ino(struct super_block *sb, u64 *ino_p)
+{
+	struct apfs_sb_info *sbi = APFS_SB(sb);
+	struct apfs_query *query = NULL;
+	struct apfs_drec drec = {0};
+	struct qstr qname = {0};
+	bool hashed = apfs_is_normalization_insensitive(sb);
+	bool found = false;
+	int err;
+
+	query = apfs_alloc_query(sbi->s_cat_root, NULL /* parent */);
+	if (!query)
+		return -ENOMEM;
+	apfs_init_drec_key(sb, APFS_PRIV_DIR_INO_NUM, NULL /* name */, 0 /* name_len */, &query->key);
+	query->flags = APFS_QUERY_CAT | APFS_QUERY_MULTIPLE | APFS_QUERY_EXACT;
+
+	while (!found) {
+		err = apfs_btree_query(sb, &query);
+		if (err) {
+			if (err == -ENODATA)
+				goto out;
+			apfs_err(sb, "drec query failed for private dir");
+			goto out;
+		}
+		err = apfs_drec_from_query(query, &drec, hashed);
+		if (err) {
+			apfs_alert(sb, "bad dentry record in private dir");
+			goto out;
+		}
+
+		/* These files are deleted immediately by ->evict_inode() */
+		if (drec.type != DT_REG)
+			continue;
+
+		/*
+		 * Confirm that this is an orphan file, because the official
+		 * reference allows other uses for the private directory.
+		 */
+		err = apfs_orphan_name(drec.ino, &qname);
+		if (err)
+			goto out;
+		found = strcmp(drec.name, qname.name) == 0;
+		kfree(qname.name);
+		qname.name = NULL;
+	}
+	*ino_p = drec.ino;
+
+out:
+	apfs_free_query(query);
+	query = NULL;
+	return err;
+}
diff --git a/dkms.conf b/dkms.conf
index ec0d726..a03f8c9 100644
--- a/dkms.conf
+++ b/dkms.conf
@@ -1,7 +1,8 @@
 PACKAGE_NAME="linux-apfs-rw"
-PACKAGE_VERSION="0.3.4"
+PACKAGE_VERSION="0.3.8"
 
 BUILT_MODULE_NAME[0]="apfs"
 DEST_MODULE_LOCATION[0]="/extra"
 
 AUTOINSTALL="yes"
+PRE_BUILD="genver.sh"
diff --git a/extents.c b/extents.c
index 1fb4c54..3ebcd29 100644
--- a/extents.c
+++ b/extents.c
@@ -139,7 +139,7 @@ static int apfs_extent_read(struct apfs_dstream_info *dstream, sector_t dsblock,
 		ret = -ENOMEM;
 		goto done;
 	}
-	query->key = &key;
+	query->key = key;
 	query->flags = apfs_is_sealed(sb) ? APFS_QUERY_FEXT : APFS_QUERY_CAT;
 
 	ret = apfs_btree_query(sb, &query);
@@ -387,7 +387,7 @@ static int apfs_shrink_extent_tail(struct apfs_query *query, struct apfs_dstream
 }
 
 /**
- * apfs_query_found_extent - Is this query pointing to an extent record?
+ * apfs_query_found_extent - Did this query find an extent with the right id?
  * @query: the (successful) query that found the record
  */
 static inline bool apfs_query_found_extent(struct apfs_query *query)
@@ -398,7 +398,12 @@ static inline bool apfs_query_found_extent(struct apfs_query *query)
 	if (query->key_len < sizeof(*hdr))
 		return false;
 	hdr = raw + query->key_off;
-	return apfs_cat_type(hdr) == APFS_TYPE_FILE_EXTENT;
+
+	if (apfs_cat_type(hdr) != APFS_TYPE_FILE_EXTENT)
+		return false;
+	if (apfs_cat_cnid(hdr) != query->key.id)
+		return false;
+	return true;
 }
 
 /**
@@ -413,7 +418,6 @@ static int apfs_update_tail_extent(struct apfs_dstream_info *dstream, const stru
 {
 	struct super_block *sb = dstream->ds_sb;
 	struct apfs_sb_info *sbi = APFS_SB(sb);
-	struct apfs_key key;
 	struct apfs_query *query;
 	struct apfs_file_extent_key raw_key;
 	struct apfs_file_extent_val raw_val;
@@ -431,13 +435,11 @@ static int apfs_update_tail_extent(struct apfs_dstream_info *dstream, const stru
 		new_crypto = 0;
 	raw_val.crypto_id = cpu_to_le64(new_crypto);
 
-	/* We want the last extent record */
-	apfs_init_file_extent_key(extent_id, -1, &key);
-
 	query = apfs_alloc_query(sbi->s_cat_root, NULL /* parent */);
 	if (!query)
 		return -ENOMEM;
-	query->key = &key;
+	/* We want the last extent record */
+	apfs_init_file_extent_key(extent_id, -1, &query->key);
 	query->flags = APFS_QUERY_CAT;
 
 	ret = apfs_btree_query(sb, &query);
@@ -614,7 +616,7 @@ search_and_insert:
 	query = apfs_alloc_query(sbi->s_cat_root, NULL /* parent */);
 	if (!query)
 		return -ENOMEM;
-	query->key = &key;
+	query->key = key;
 	query->flags = APFS_QUERY_CAT;
 
 	ret = apfs_btree_query(sb, &query);
@@ -801,7 +803,6 @@ static int apfs_insert_phys_extent(struct apfs_dstream_info *dstream, const stru
 	struct super_block *sb = dstream->ds_sb;
 	struct apfs_superblock *vsb_raw = APFS_SB(sb)->s_vsb_raw;
 	struct apfs_node *extref_root;
-	struct apfs_key key;
 	struct apfs_query *query = NULL;
 	struct apfs_phys_extent pext;
 	u64 blkcnt = extent->len >> sb->s_blocksize_bits;
@@ -830,8 +831,7 @@ static int apfs_insert_phys_extent(struct apfs_dstream_info *dstream, const stru
 	 * one.
 	 */
 	last_bno = extent->phys_block_num + blkcnt - 1;
-	apfs_init_extent_key(last_bno, &key);
-	query->key = &key;
+	apfs_init_extent_key(last_bno, &query->key);
 	query->flags = APFS_QUERY_EXTENTREF;
 
 	ret = apfs_btree_query(sb, &query);
@@ -1153,7 +1153,6 @@ static int apfs_create_hole(struct apfs_dstream_info *dstream, u64 start, u64 en
 {
 	struct super_block *sb = dstream->ds_sb;
 	struct apfs_sb_info *sbi = APFS_SB(sb);
-	struct apfs_key key;
 	struct apfs_query *query;
 	struct apfs_file_extent_key raw_key;
 	struct apfs_file_extent_val raw_val;
@@ -1173,11 +1172,10 @@ static int apfs_create_hole(struct apfs_dstream_info *dstream, u64 start, u64 en
 	raw_val.phys_block_num = cpu_to_le64(0); /* It's a hole... */
 	raw_val.crypto_id = cpu_to_le64(apfs_vol_is_encrypted(sb) ? extent_id : 0);
 
-	apfs_init_file_extent_key(extent_id, start, &key);
 	query = apfs_alloc_query(sbi->s_cat_root, NULL /* parent */);
 	if (!query)
 		return -ENOMEM;
-	query->key = &key;
+	apfs_init_file_extent_key(extent_id, start, &query->key);
 	query->flags = APFS_QUERY_CAT;
 
 	ret = apfs_btree_query(sb, &query);
@@ -1260,7 +1258,6 @@ static int apfs_range_in_snap(struct super_block *sb, u64 bno, u64 blkcnt, bool
 {
 	struct apfs_superblock *vsb_raw = APFS_SB(sb)->s_vsb_raw;
 	struct apfs_node *extref_root = NULL;
-	struct apfs_key key;
 	struct apfs_query *query = NULL;
 	struct apfs_phys_extent pext = {0};
 	int ret;
@@ -1287,8 +1284,7 @@ static int apfs_range_in_snap(struct super_block *sb, u64 bno, u64 blkcnt, bool
 		goto out;
 	}
 
-	apfs_init_extent_key(bno, &key);
-	query->key = &key;
+	apfs_init_extent_key(bno, &query->key);
 	query->flags = APFS_QUERY_EXTENTREF;
 
 	ret = apfs_btree_query(sb, &query);
@@ -1500,18 +1496,15 @@ static int apfs_shrink_dstream_last_extent(struct apfs_dstream_info *dstream, lo
 {
 	struct super_block *sb = dstream->ds_sb;
 	struct apfs_sb_info *sbi = APFS_SB(sb);
-	struct apfs_key key;
 	struct apfs_query *query;
 	struct apfs_file_extent tail;
 	u64 extent_id = dstream->ds_id;
 	int ret = 0;
 
-	apfs_init_file_extent_key(extent_id, -1, &key);
-
 	query = apfs_alloc_query(sbi->s_cat_root, NULL /* parent */);
 	if (!query)
 		return -ENOMEM;
-	query->key = &key;
+	apfs_init_file_extent_key(extent_id, -1, &query->key);
 	query->flags = APFS_QUERY_CAT;
 
 	ret = apfs_btree_query(sb, &query);
@@ -1637,6 +1630,125 @@ int apfs_truncate(struct apfs_dstream_info *dstream, loff_t new_size)
 	return apfs_create_hole(dstream, old_blks, new_blks);
 }
 
+/**
+ * apfs_dstream_delete_front - Deletes as many leading extents as possible
+ * @sb:		filesystem superblock
+ * @ds_id:	id for the dstream to delete
+ *
+ * Returns 0 on success, or a negative error code in case of failure, which may
+ * be -ENODATA if there are no more extents, or -EAGAIN if the free queue is
+ * getting too full.
+ */
+static int apfs_dstream_delete_front(struct super_block *sb, u64 ds_id)
+{
+	struct apfs_sb_info *sbi = APFS_SB(sb);
+	struct apfs_spaceman *sm = APFS_SM(sb);
+	struct apfs_spaceman_phys *sm_raw = sm->sm_raw;
+	struct apfs_spaceman_free_queue *fq = NULL;
+	struct apfs_query *query = NULL;
+	struct apfs_file_extent head;
+	bool first_match = true;
+	int ret;
+
+	fq = &sm_raw->sm_fq[APFS_SFQ_MAIN];
+	if (le64_to_cpu(fq->sfq_count) > TRANSACTION_MAIN_QUEUE_MAX)
+		return -EAGAIN;
+
+	query = apfs_alloc_query(sbi->s_cat_root, NULL /* parent */);
+	if (!query)
+		return -ENOMEM;
+	apfs_init_file_extent_key(ds_id, 0, &query->key);
+	query->flags = APFS_QUERY_CAT;
+
+next_extent:
+	ret = apfs_btree_query(sb, &query);
+	if (ret && ret != -ENODATA) {
+		apfs_err(sb, "query failed for first extent of id 0x%llx", ds_id);
+		goto out;
+	}
+	apfs_query_direct_forward(query);
+	if (!apfs_query_found_extent(query)) {
+		/*
+		 * After the original lookup, the query may not be set to the
+		 * first extent, but instead to the record that comes right
+		 * before.
+		 */
+		if (first_match) {
+			first_match = false;
+			goto next_extent;
+		}
+		ret = -ENODATA;
+		goto out;
+	}
+	first_match = false;
+
+	ret = apfs_extent_from_query(query, &head);
+	if (ret) {
+		apfs_err(sb, "bad head extent record on dstream 0x%llx", ds_id);
+		goto out;
+	}
+	ret = apfs_btree_remove(query);
+	if (ret) {
+		apfs_err(sb, "removal failed for id 0x%llx, addr 0x%llx", ds_id, head.logical_addr);
+		goto out;
+	}
+
+	/*
+	 * The official fsck doesn't complain about wrong sparse byte counts
+	 * for orphans, so I guess we don't need to update them here
+	 */
+	if (!apfs_ext_is_hole(&head)) {
+		ret = apfs_range_put_reference(sb, head.phys_block_num, head.len);
+		if (ret) {
+			apfs_err(sb, "failed to put range 0x%llx-0x%llx", head.phys_block_num, head.len);
+			goto out;
+		}
+		ret = apfs_crypto_adj_refcnt(sb, head.crypto_id, -1);
+		if (ret) {
+			apfs_err(sb, "failed to take crypto id 0x%llx", head.crypto_id);
+			goto out;
+		}
+	}
+
+	if (le64_to_cpu(fq->sfq_count) <= TRANSACTION_MAIN_QUEUE_MAX)
+		goto next_extent;
+	ret = -EAGAIN;
+out:
+	apfs_free_query(query);
+	return ret;
+}
+
+/**
+ * apfs_inode_delete_front - Deletes as many leading extents as possible
+ * @inode:	inode to delete
+ *
+ * Tries to delete all extents for @inode, in which case it returns 0. If the
+ * free queue is getting too full, deletes as much as is reasonable and returns
+ * -EAGAIN. May return other negative error codes as well.
+ */
+int apfs_inode_delete_front(struct inode *inode)
+{
+	struct super_block *sb = inode->i_sb;
+	struct apfs_dstream_info *dstream = NULL;
+	struct apfs_inode_info *ai = APFS_I(inode);
+	int ret;
+
+	if (!ai->i_has_dstream)
+		return 0;
+
+	dstream = &ai->i_dstream;
+	ret = apfs_flush_extent_cache(dstream);
+	if (ret) {
+		apfs_err(sb, "extent cache flush failed for dstream 0x%llx", dstream->ds_id);
+		return ret;
+	}
+
+	ret = apfs_dstream_delete_front(sb, dstream->ds_id);
+	if (ret == -ENODATA)
+		return 0;
+	return ret;
+}
+
 #if LINUX_VERSION_CODE >= KERNEL_VERSION(4, 20, 0)
 loff_t apfs_remap_file_range(struct file *src_file, loff_t off, struct file *dst_file, loff_t destoff, loff_t len, unsigned int remap_flags)
 #else
@@ -1706,8 +1818,10 @@ int apfs_clone_file_range(struct file *src_file, loff_t off, struct file *dst_fi
 
 #if LINUX_VERSION_CODE < KERNEL_VERSION(6, 6, 0)
 	dst_inode->i_mtime = dst_inode->i_ctime = current_time(dst_inode);
-#else
+#elif LINUX_VERSION_CODE < KERNEL_VERSION(6, 7, 0)
 	dst_inode->i_mtime = inode_set_ctime_current(dst_inode);
+#else
+	inode_set_mtime_to_ts(dst_inode, inode_set_ctime_current(dst_inode));
 #endif
 	dst_inode->i_size = src_inode->i_size;
 	dst_ai->i_key_class = src_ai->i_key_class;
@@ -1760,18 +1874,15 @@ fail:
 static int apfs_extent_create_record(struct super_block *sb, u64 dstream_id, struct apfs_file_extent *extent)
 {
 	struct apfs_sb_info *sbi = APFS_SB(sb);
-	struct apfs_key key;
 	struct apfs_query *query = NULL;
 	struct apfs_file_extent_val raw_val;
 	struct apfs_file_extent_key raw_key;
 	int ret = 0;
 
-	apfs_init_file_extent_key(dstream_id, extent->logical_addr, &key);
-
 	query = apfs_alloc_query(sbi->s_cat_root, NULL /* parent */);
 	if (!query)
 		return -ENOMEM;
-	query->key = &key;
+	apfs_init_file_extent_key(dstream_id, extent->logical_addr, &query->key);
 	query->flags = APFS_QUERY_CAT | APFS_QUERY_EXACT;
 
 	ret = apfs_btree_query(sb, &query);
@@ -1835,7 +1946,7 @@ restart:
 		ret = -ENOMEM;
 		goto out;
 	}
-	query->key = &key;
+	query->key = key;
 	query->flags = APFS_QUERY_EXTENTREF;
 
 	ret = apfs_btree_query(sb, &query);
@@ -1975,7 +2086,7 @@ restart:
 		ret = -ENOMEM;
 		goto out;
 	}
-	query->key = &key;
+	query->key = key;
 	query->flags = APFS_QUERY_EXTENTREF;
 
 	ret = apfs_btree_query(sb, &query);
@@ -2186,7 +2297,11 @@ int apfs_nonsparse_dstream_read(struct apfs_dstream_info *dstream, void *buf, si
 			goto out;
 		}
 
+#if LINUX_VERSION_CODE < KERNEL_VERSION(6, 7, 0)
 		bhs[idx] = __getblk_gfp(APFS_NXI(sb)->nx_bdev, bno, sb->s_blocksize, __GFP_MOVABLE);
+#else
+		bhs[idx] = bdev_getblk(APFS_NXI(sb)->nx_bdev, bno, sb->s_blocksize, __GFP_MOVABLE);
+#endif
 		if (!bhs[idx]) {
 			apfs_err(sb, "failed to map block 0x%llx", bno);
 			ret = -EIO;
@@ -2258,7 +2373,11 @@ void apfs_nonsparse_dstream_preread(struct apfs_dstream_info *dstream)
 		if (ret || bno == 0)
 			return;
 
+#if LINUX_VERSION_CODE < KERNEL_VERSION(6, 7, 0)
 		bh = __getblk_gfp(APFS_NXI(sb)->nx_bdev, bno, sb->s_blocksize, __GFP_MOVABLE);
+#else
+		bh = bdev_getblk(APFS_NXI(sb)->nx_bdev, bno, sb->s_blocksize, __GFP_MOVABLE);
+#endif
 		if (!bh)
 			return;
 		if (!buffer_uptodate(bh)) {
diff --git a/file.c b/file.c
index 0abedbc..c37d59a 100644
--- a/file.c
+++ b/file.c
@@ -5,6 +5,9 @@
 
 #include "apfs.h"
 
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(6, 8, 0)
+#include <linux/splice.h>
+#endif
 #if LINUX_VERSION_CODE < KERNEL_VERSION(4, 17, 0)
 typedef int vm_fault_t;
 #endif
@@ -18,6 +21,9 @@ static vm_fault_t apfs_page_mkwrite(struct vm_fault *vmf)
 	struct vm_area_struct *vma = vmf->vma;
 #endif
 	struct page *page = vmf->page;
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(6, 7, 0)
+	struct folio *folio;
+#endif
 	struct inode *inode = file_inode(vma->vm_file);
 	struct super_block *sb = inode->i_sb;
 	struct buffer_head *bh, *head;
@@ -54,8 +60,16 @@ static vm_fault_t apfs_page_mkwrite(struct vm_fault *vmf)
 		goto out_unlock;
 	}
 
-	if (!page_has_buffers(page))
+	if (!page_has_buffers(page)) {
+#if LINUX_VERSION_CODE < KERNEL_VERSION(6, 7, 0)
 		create_empty_buffers(page, sb->s_blocksize, 0);
+#else
+		folio = page_folio(page);
+		bh = folio_buffers(folio);
+		if (!bh)
+			bh = create_empty_buffers(folio, sb->s_blocksize, 0);
+#endif
+	}
 
 	size = i_size_read(inode);
 	if (page->index == size >> PAGE_SHIFT)
@@ -141,6 +155,16 @@ int apfs_fsync(struct file *file, loff_t start, loff_t end, int datasync)
 	return apfs_sync_fs(sb, true /* wait */);
 }
 
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(6, 8, 0)
+static ssize_t apfs_copy_file_range(struct file *src_file, loff_t src_off,
+				    struct file *dst_file, loff_t dst_off,
+				    size_t len, unsigned int flags)
+{
+	return (splice_copy_file_range(src_file, src_off,
+		dst_file, dst_off, len));
+}
+#endif
+
 const struct file_operations apfs_file_operations = {
 	.llseek			= generic_file_llseek,
 	.read_iter		= generic_file_read_iter,
@@ -150,7 +174,9 @@ const struct file_operations apfs_file_operations = {
 	.fsync			= apfs_fsync,
 	.unlocked_ioctl		= apfs_file_ioctl,
 
-#if LINUX_VERSION_CODE >= KERNEL_VERSION(5, 3, 0)
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(6, 8, 0)
+	.copy_file_range	= apfs_copy_file_range,
+#elif LINUX_VERSION_CODE >= KERNEL_VERSION(5, 3, 0)
 	.copy_file_range	= generic_copy_file_range,
 #endif
 
@@ -159,6 +185,13 @@ const struct file_operations apfs_file_operations = {
 #else
 	.clone_file_range	= apfs_clone_file_range,
 #endif
+
+#if LINUX_VERSION_CODE < KERNEL_VERSION(6, 5, 0)
+	.splice_read		= generic_file_splice_read,
+#else
+	.splice_read		= filemap_splice_read,
+#endif
+	.splice_write		= iter_file_splice_write,
 };
 
 #if LINUX_VERSION_CODE == KERNEL_VERSION(5, 3, 0)
diff --git a/genver.sh b/genver.sh
new file mode 100755
index 0000000..c8e0bd3
--- /dev/null
+++ b/genver.sh
@@ -0,0 +1,13 @@
+#!/bin/sh
+# SPDX-License-Identifier: GPL-2.0-only
+#
+# Script to generate the module version header
+#
+
+if command -v git >/dev/null 2>&1 && [ -d .git ]; then
+	GIT_COMMIT=$(git describe HEAD | tail -c 9)
+else
+	GIT_COMMIT="$(grep PACKAGE_VERSION dkms.conf | cut -d '"' -f2)?"
+fi
+
+printf '#define GIT_COMMIT\t"%s"\n' "$GIT_COMMIT" > version.h
diff --git a/inode.c b/inode.c
index ab42c06..71a1dca 100644
--- a/inode.c
+++ b/inode.c
@@ -64,17 +64,15 @@ static int apfs_create_dstream_rec(struct apfs_dstream_info *dstream)
 {
 	struct super_block *sb = dstream->ds_sb;
 	struct apfs_sb_info *sbi = APFS_SB(sb);
-	struct apfs_key key;
 	struct apfs_query *query;
 	struct apfs_dstream_id_key raw_key;
 	struct apfs_dstream_id_val raw_val;
 	int ret;
 
-	apfs_init_dstream_id_key(dstream->ds_id, &key);
 	query = apfs_alloc_query(sbi->s_cat_root, NULL /* parent */);
 	if (!query)
 		return -ENOMEM;
-	query->key = &key;
+	apfs_init_dstream_id_key(dstream->ds_id, &query->key);
 	query->flags |= APFS_QUERY_CAT | APFS_QUERY_EXACT;
 
 	ret = apfs_btree_query(sb, &query);
@@ -190,7 +188,6 @@ int apfs_dstream_adj_refcnt(struct apfs_dstream_info *dstream, u32 delta)
 {
 	struct super_block *sb = dstream->ds_sb;
 	struct apfs_sb_info *sbi = APFS_SB(sb);
-	struct apfs_key key;
 	struct apfs_query *query;
 	struct apfs_dstream_id_val raw_val;
 	void *raw = NULL;
@@ -199,11 +196,10 @@ int apfs_dstream_adj_refcnt(struct apfs_dstream_info *dstream, u32 delta)
 
 	ASSERT(APFS_I(dstream->ds_inode)->i_has_dstream);
 
-	apfs_init_dstream_id_key(dstream->ds_id, &key);
 	query = apfs_alloc_query(sbi->s_cat_root, NULL /* parent */);
 	if (!query)
 		return -ENOMEM;
-	query->key = &key;
+	apfs_init_dstream_id_key(dstream->ds_id, &query->key);
 	query->flags |= APFS_QUERY_CAT | APFS_QUERY_EXACT;
 
 	ret = apfs_btree_query(sb, &query);
@@ -268,7 +264,6 @@ static int apfs_create_crypto_rec(struct inode *inode)
 	struct super_block *sb = inode->i_sb;
 	struct apfs_sb_info *sbi = APFS_SB(sb);
 	struct apfs_dstream_info *dstream = &APFS_I(inode)->i_dstream;
-	struct apfs_key key;
 	struct apfs_query *query;
 	struct apfs_crypto_state_key raw_key;
 	int ret;
@@ -276,11 +271,10 @@ static int apfs_create_crypto_rec(struct inode *inode)
 	if (inode->i_size || inode->i_blocks) /* Already has a dstream */
 		return 0;
 
-	apfs_init_crypto_state_key(dstream->ds_id, &key);
 	query = apfs_alloc_query(sbi->s_cat_root, NULL /* parent */);
 	if (!query)
 		return -ENOMEM;
-	query->key = &key;
+	apfs_init_crypto_state_key(dstream->ds_id, &query->key);
 	query->flags |= APFS_QUERY_CAT | APFS_QUERY_EXACT;
 
 	ret = apfs_btree_query(sb, &query);
@@ -343,7 +337,6 @@ static unsigned int apfs_dflt_key_class(struct super_block *sb)
 int apfs_crypto_adj_refcnt(struct super_block *sb, u64 crypto_id, int delta)
 {
 	struct apfs_sb_info *sbi = APFS_SB(sb);
-	struct apfs_key key;
 	struct apfs_query *query;
 	struct apfs_crypto_state_val *raw_val;
 	char *raw;
@@ -352,11 +345,10 @@ int apfs_crypto_adj_refcnt(struct super_block *sb, u64 crypto_id, int delta)
 	if (!crypto_id)
 		return 0;
 
-	apfs_init_crypto_state_key(crypto_id, &key);
 	query = apfs_alloc_query(sbi->s_cat_root, NULL /* parent */);
 	if (!query)
 		return -ENOMEM;
-	query->key = &key;
+	apfs_init_crypto_state_key(crypto_id, &query->key);
 	query->flags |= APFS_QUERY_CAT | APFS_QUERY_EXACT;
 
 	ret = apfs_btree_query(sb, &query);
@@ -396,7 +388,6 @@ int APFS_CRYPTO_ADJ_REFCNT_MAXOPS(void)
 static int apfs_crypto_set_key(struct super_block *sb, u64 crypto_id, struct apfs_crypto_state_val *new_val)
 {
 	struct apfs_sb_info *sbi = APFS_SB(sb);
-	struct apfs_key key;
 	struct apfs_query *query;
 	struct apfs_crypto_state_val *raw_val;
 	char *raw;
@@ -408,11 +399,10 @@ static int apfs_crypto_set_key(struct super_block *sb, u64 crypto_id, struct apf
 
 	pfk_len = le16_to_cpu(new_val->state.key_len);
 
-	apfs_init_crypto_state_key(crypto_id, &key);
 	query = apfs_alloc_query(sbi->s_cat_root, NULL /* parent */);
 	if (!query)
 		return -ENOMEM;
-	query->key = &key;
+	apfs_init_crypto_state_key(crypto_id, &query->key);
 	query->flags |= APFS_QUERY_CAT | APFS_QUERY_EXACT;
 
 	ret = apfs_btree_query(sb, &query);
@@ -446,7 +436,6 @@ static int apfs_crypto_get_key(struct super_block *sb, u64 crypto_id, struct apf
 			       unsigned int max_len)
 {
 	struct apfs_sb_info *sbi = APFS_SB(sb);
-	struct apfs_key key;
 	struct apfs_query *query;
 	struct apfs_crypto_state_val *raw_val;
 	char *raw;
@@ -456,11 +445,10 @@ static int apfs_crypto_get_key(struct super_block *sb, u64 crypto_id, struct apf
 	if (!crypto_id)
 		return -ENOENT;
 
-	apfs_init_crypto_state_key(crypto_id, &key);
 	query = apfs_alloc_query(sbi->s_cat_root, NULL /* parent */);
 	if (!query)
 		return -ENOMEM;
-	query->key = &key;
+	apfs_init_crypto_state_key(crypto_id, &query->key);
 	query->flags |= APFS_QUERY_CAT | APFS_QUERY_EXACT;
 
 	ret = apfs_btree_query(sb, &query);
@@ -488,6 +476,9 @@ int __apfs_write_begin(struct file *file, struct address_space *mapping, loff_t
 	struct apfs_dstream_info *dstream = &APFS_I(inode)->i_dstream;
 	struct super_block *sb = inode->i_sb;
 	struct page *page;
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(6, 7, 0)
+	struct folio *folio;
+#endif
 	struct buffer_head *bh, *head;
 	unsigned int blocksize, block_start, block_end, from, to;
 	pgoff_t index = pos >> PAGE_SHIFT;
@@ -520,8 +511,16 @@ int __apfs_write_begin(struct file *file, struct address_space *mapping, loff_t
 #endif
 	if (!page)
 		return -ENOMEM;
-	if (!page_has_buffers(page))
+	if (!page_has_buffers(page)) {
+#if LINUX_VERSION_CODE < KERNEL_VERSION(6, 7, 0)
 		create_empty_buffers(page, sb->s_blocksize, 0);
+#else
+		folio = page_folio(page);
+		bh = folio_buffers(folio);
+		if (!bh)
+			bh = create_empty_buffers(folio, sb->s_blocksize, 0);
+#endif
+	}
 
 	/* CoW moves existing blocks, so read them but mark them as unmapped */
 	head = page_buffers(page);
@@ -799,13 +798,19 @@ static int apfs_inode_from_query(struct apfs_query *query, struct inode *inode)
 		ai->i_nchildren = le32_to_cpu(inode_val->nchildren);
 	}
 
-	inode->i_atime = ns_to_timespec64(le64_to_cpu(inode_val->access_time));
 #if LINUX_VERSION_CODE < KERNEL_VERSION(6, 6, 0)
 	inode->i_ctime = ns_to_timespec64(le64_to_cpu(inode_val->change_time));
 #else
 	inode_set_ctime_to_ts(inode, ns_to_timespec64(le64_to_cpu(inode_val->change_time)));
 #endif
+
+#if LINUX_VERSION_CODE < KERNEL_VERSION(6, 7, 0)
+	inode->i_atime = ns_to_timespec64(le64_to_cpu(inode_val->access_time));
 	inode->i_mtime = ns_to_timespec64(le64_to_cpu(inode_val->mod_time));
+#else
+	inode_set_atime_to_ts(inode, ns_to_timespec64(le64_to_cpu(inode_val->access_time)));
+	inode_set_mtime_to_ts(inode, ns_to_timespec64(le64_to_cpu(inode_val->mod_time)));
+#endif
 	ai->i_crtime = ns_to_timespec64(le64_to_cpu(inode_val->create_time));
 
 	dstream->ds_size = inode->i_size = inode->i_blocks = 0;
@@ -868,23 +873,22 @@ static struct apfs_query *apfs_inode_lookup(const struct inode *inode)
 {
 	struct super_block *sb = inode->i_sb;
 	struct apfs_sb_info *sbi = APFS_SB(sb);
-	struct apfs_key key;
 	struct apfs_query *query;
 	int ret;
 
-	apfs_init_inode_key(apfs_ino(inode), &key);
-
 	query = apfs_alloc_query(sbi->s_cat_root, NULL /* parent */);
 	if (!query)
 		return ERR_PTR(-ENOMEM);
-	query->key = &key;
+	apfs_init_inode_key(apfs_ino(inode), &query->key);
 	query->flags |= APFS_QUERY_CAT | APFS_QUERY_EXACT;
 
 	ret = apfs_btree_query(sb, &query);
 	if (!ret)
 		return query;
 
-	apfs_err(sb, "query failed for id 0x%llx", apfs_ino(inode));
+	/* Don't complain if an orphan is already gone */
+	if (!current_work() || ret != -ENODATA)
+		apfs_err(sb, "query failed for id 0x%llx", apfs_ino(inode));
 	apfs_free_query(query);
 	return ERR_PTR(ret);
 }
@@ -938,7 +942,6 @@ static int apfs_check_dstream_refcnt(struct inode *inode)
 	struct apfs_dstream_info *dstream = &ai->i_dstream;
 	struct super_block *sb = inode->i_sb;
 	struct apfs_sb_info *sbi = APFS_SB(sb);
-	struct apfs_key key;
 	struct apfs_query *query = NULL;
 	struct apfs_dstream_id_val raw_val;
 	void *raw = NULL;
@@ -950,11 +953,10 @@ static int apfs_check_dstream_refcnt(struct inode *inode)
 		return 0;
 	}
 
-	apfs_init_dstream_id_key(dstream->ds_id, &key);
 	query = apfs_alloc_query(sbi->s_cat_root, NULL /* parent */);
 	if (!query)
 		return -ENOMEM;
-	query->key = &key;
+	apfs_init_dstream_id_key(dstream->ds_id, &query->key);
 	query->flags |= APFS_QUERY_CAT | APFS_QUERY_EXACT;
 
 	ret = apfs_btree_query(sb, &query);
@@ -1005,8 +1007,10 @@ struct inode *apfs_iget(struct super_block *sb, u64 cnid)
 	down_read(&nxi->nx_big_sem);
 	query = apfs_inode_lookup(inode);
 	if (IS_ERR(query)) {
-		apfs_err(sb, "lookup failed for ino 0x%llx", cnid);
 		err = PTR_ERR(query);
+		/* Don't complain if an orphan is already gone */
+		if (!current_work() || err != -ENODATA)
+			apfs_err(sb, "lookup failed for ino 0x%llx", cnid);
 		goto fail;
 	}
 	err = apfs_inode_from_query(query, inode);
@@ -1044,6 +1048,7 @@ int apfs_getattr(struct vfsmount *mnt, struct dentry *dentry,
 	struct inode *inode = d_inode(dentry);
 
 	generic_fillattr(inode, stat);
+	stat->dev = APFS_SB(inode->i_sb)->s_anon_dev;
 	stat->ino = apfs_ino(inode);
 	return 0;
 }
@@ -1093,6 +1098,7 @@ int apfs_getattr(struct mnt_idmap *idmap,
 	generic_fillattr(idmap, request_mask, inode, stat);
 #endif
 
+	stat->dev = APFS_SB(inode->i_sb)->s_anon_dev;
 	stat->ino = apfs_ino(inode);
 	return 0;
 }
@@ -1112,6 +1118,9 @@ static int apfs_build_inode_val(struct inode *inode, struct qstr *qname,
 {
 	struct apfs_inode_val *val;
 	struct apfs_x_field xkey;
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(6, 7, 0)
+	struct timespec64 ts;
+#endif
 	int total_xlen, val_len;
 	bool is_device = S_ISCHR(inode->i_mode) || S_ISBLK(inode->i_mode);
 	__le32 rdev;
@@ -1130,7 +1139,12 @@ static int apfs_build_inode_val(struct inode *inode, struct qstr *qname,
 	val->parent_id = cpu_to_le64(APFS_I(inode)->i_parent_id);
 	val->private_id = cpu_to_le64(apfs_ino(inode));
 
+#if LINUX_VERSION_CODE < KERNEL_VERSION(6, 7, 0)
 	val->mod_time = cpu_to_le64(timespec64_to_ns(&inode->i_mtime));
+#else
+	ts = inode_get_mtime(inode);
+	val->mod_time = cpu_to_le64(timespec64_to_ns(&ts));
+#endif
 	val->create_time = val->change_time = val->access_time = val->mod_time;
 
 	if (S_ISDIR(inode->i_mode))
@@ -1492,14 +1506,22 @@ int apfs_update_inode(struct inode *inode, char *new_name)
 	if (gid_valid(sbi->s_gid))
 		inode_raw->group = cpu_to_le32(ai->i_saved_gid);
 
-	inode_raw->access_time = cpu_to_le64(timespec64_to_ns(&inode->i_atime));
 #if LINUX_VERSION_CODE < KERNEL_VERSION(6, 6, 0)
 	inode_raw->change_time = cpu_to_le64(timespec64_to_ns(&inode->i_ctime));
 #else
 	struct timespec64 ictime = inode_get_ctime(inode);
 	inode_raw->change_time = cpu_to_le64(timespec64_to_ns(&ictime));
 #endif
+
+#if LINUX_VERSION_CODE < KERNEL_VERSION(6, 7, 0)
+	inode_raw->access_time = cpu_to_le64(timespec64_to_ns(&inode->i_atime));
 	inode_raw->mod_time = cpu_to_le64(timespec64_to_ns(&inode->i_mtime));
+#else
+	struct timespec64 ts = inode_get_mtime(inode);
+	inode_raw->mod_time = cpu_to_le64(timespec64_to_ns(&ts));
+	ts = inode_get_atime(inode);
+	inode_raw->access_time = cpu_to_le64(timespec64_to_ns(&ts));
+#endif
 	inode_raw->create_time = cpu_to_le64(timespec64_to_ns(&ai->i_crtime));
 
 	if (S_ISDIR(inode->i_mode)) {
@@ -1522,13 +1544,16 @@ int APFS_UPDATE_INODE_MAXOPS(void)
  * apfs_delete_inode - Delete an inode record
  * @inode: the vfs inode to delete
  *
- * Returns 0 on success or a negative error code in case of failure.
+ * Returns 0 on success or a negative error code in case of failure, which may
+ * be -EAGAIN if the inode was not deleted in full.
  */
 static int apfs_delete_inode(struct inode *inode)
 {
 	struct super_block *sb = inode->i_sb;
+	struct apfs_inode_info *ai = APFS_I(inode);
 	struct apfs_dstream_info *dstream = NULL;
 	struct apfs_query *query;
+	u64 old_dstream_id;
 	int ret;
 
 	ret = apfs_delete_all_xattrs(inode);
@@ -1537,6 +1562,9 @@ static int apfs_delete_inode(struct inode *inode)
 		return ret;
 	}
 
+	dstream = &ai->i_dstream;
+	old_dstream_id = dstream->ds_id;
+
 	/*
 	 * This is very wasteful since all the new extents and references will
 	 * get deleted right away, but it only affects clones, so I don't see a
@@ -1548,12 +1576,27 @@ static int apfs_delete_inode(struct inode *inode)
 		return ret;
 	}
 
-	/* TODO: truncate an orphan inode in multiple transactions */
-	dstream = &APFS_I(inode)->i_dstream;
-	ret = apfs_truncate(dstream, 0 /* new_size */);
+	/* TODO: what about partial deletion of xattrs? Is that allowed? */
+	ret = apfs_inode_delete_front(inode);
 	if (ret) {
-		apfs_err(sb, "truncation failed for ino 0x%llx", apfs_ino(inode));
-		return ret;
+		/*
+		 * If the inode had too many extents, only the first few get
+		 * deleted and the inode remains in the orphan list for now.
+		 * I don't know why the deletion starts at the front, but it
+		 * seems to be what the official driver does.
+		 */
+		if (ret != -EAGAIN) {
+			apfs_err(sb, "head deletion failed for ino 0x%llx", apfs_ino(inode));
+			return ret;
+		}
+		if (dstream->ds_id != old_dstream_id) {
+			ret = apfs_update_inode(inode, NULL /* new_name */);
+			if (ret) {
+				apfs_err(sb, "dstream id update failed for orphan 0x%llx", apfs_ino(inode));
+				return ret;
+			}
+		}
+		return -EAGAIN;
 	}
 
 	ret = apfs_put_dstream_rec(dstream);
@@ -1561,6 +1604,8 @@ static int apfs_delete_inode(struct inode *inode)
 		apfs_err(sb, "failed to put dstream for ino 0x%llx", apfs_ino(inode));
 		return ret;
 	}
+	dstream = NULL;
+	ai->i_has_dstream = false;
 
 	query = apfs_inode_lookup(inode);
 	if (IS_ERR(query)) {
@@ -1569,42 +1614,191 @@ static int apfs_delete_inode(struct inode *inode)
 	}
 	ret = apfs_btree_remove(query);
 	apfs_free_query(query);
-	if (ret)
+	if (ret) {
 		apfs_err(sb, "removal failed for ino 0x%llx", apfs_ino(inode));
+		return ret;
+	}
+
+	ai->i_cleaned = true;
 	return ret;
 }
 #define APFS_DELETE_INODE_MAXOPS	1
 
+/**
+ * apfs_clean_single_orphan - Clean the given orphan file
+ * @inode:	inode for the file to clean
+ *
+ * Returns 0 on success or a negative error code in case of failure, which may
+ * be -EAGAIN if the file could not be deleted in full.
+ */
+static int apfs_clean_single_orphan(struct inode *inode)
+{
+	struct super_block *sb = inode->i_sb;
+	struct apfs_max_ops maxops = {0}; /* TODO: rethink this stuff */
+	u64 ino = apfs_ino(inode);
+	bool eagain = false;
+	int err;
+
+	err = apfs_transaction_start(sb, maxops);
+	if (err)
+		return err;
+	err = apfs_delete_inode(inode);
+	if (err) {
+		if (err != -EAGAIN) {
+			apfs_err(sb, "failed to delete orphan 0x%llx", ino);
+			goto fail;
+		}
+		eagain = true;
+	} else {
+		err = apfs_delete_orphan_link(inode);
+		if (err) {
+			apfs_err(sb, "failed to unlink orphan 0x%llx", ino);
+			goto fail;
+		}
+	}
+	err = apfs_transaction_commit(sb);
+	if (err)
+		goto fail;
+	return eagain ? -EAGAIN : 0;
+
+fail:
+	apfs_transaction_abort(sb);
+	return err;
+}
+
+/**
+ * apfs_clean_any_orphan - Pick an orphan and delete as much as reasonable
+ * @sb:		filesystem superblock
+ *
+ * Returns 0 on success, or a negative error code in case of failure, which may
+ * be -ENODATA if there are no more orphan files or -EAGAIN if a file could not
+ * be deleted in full.
+ */
+static int apfs_clean_any_orphan(struct super_block *sb)
+{
+	struct apfs_nxsb_info *nxi = APFS_NXI(sb);
+	struct inode *inode = NULL;
+	int err;
+	u64 ino;
+
+	down_read(&nxi->nx_big_sem);
+	err = apfs_any_orphan_ino(sb, &ino);
+	up_read(&nxi->nx_big_sem);
+	if (err) {
+		if (err == -ENODATA)
+			return -ENODATA;
+		apfs_err(sb, "failed to find orphan inode numbers");
+		return err;
+	}
+
+	inode = apfs_iget(sb, ino);
+	if (IS_ERR(inode)) {
+		err = PTR_ERR(inode);
+		if (err != -ENODATA) {
+			apfs_err(sb, "iget failed for orphan 0x%llx", ino);
+			return err;
+		}
+		/*
+		 * This happens rarely for files with no extents, if we hit a
+		 * race with ->evict_inode(). Not a problem: the file is gone.
+		 */
+		apfs_notice(sb, "orphan 0x%llx not found", ino);
+		return 0;
+	}
+
+	if (atomic_read(&inode->i_count) > 1)
+		goto out;
+	err = apfs_clean_single_orphan(inode);
+	if (err && err != -EAGAIN) {
+		apfs_err(sb, "failed to clean orphan 0x%llx", ino);
+		goto out;
+	}
+out:
+	iput(inode);
+	return err;
+}
+
+/**
+ * apfs_clean_orphans - Delete as many orphan files as is reasonable
+ * @sb: filesystem superblock
+ *
+ * Returns 0 on success or a negative error code in case of failure.
+ */
+static int apfs_clean_orphans(struct super_block *sb)
+{
+	int ret, i;
+
+	for (i = 0; i < 100; ++i) {
+		ret = apfs_clean_any_orphan(sb);
+		if (ret) {
+			if (ret == -ENODATA)
+				return 0;
+			if (ret == -EAGAIN)
+				break;
+			apfs_err(sb, "failed to delete an orphan file");
+			return ret;
+		}
+	}
+
+	/*
+	 * If a file is too big, or if there are too many files, take a break
+	 * and continue later.
+	 */
+	if (atomic_read(&sb->s_active) != 0)
+		schedule_work(&APFS_SB(sb)->s_orphan_cleanup_work);
+	return 0;
+}
+
 void apfs_evict_inode(struct inode *inode)
 {
 	struct super_block *sb = inode->i_sb;
-	struct apfs_max_ops maxops;
+	struct apfs_inode_info *ai = APFS_I(inode);
+	int err;
 
-	if (is_bad_inode(inode) || inode->i_nlink)
-		goto out_clear;
+	if (is_bad_inode(inode) || inode->i_nlink || ai->i_cleaned)
+		goto out;
 
-	maxops.cat = APFS_DELETE_INODE_MAXOPS + APFS_DELETE_ORPHAN_LINK_MAXOPS();
-	maxops.blks = 0;
+	if (!ai->i_has_dstream || ai->i_dstream.ds_size == 0) {
+		/* For files with no extents, scheduled cleanup wastes time */
+		err = apfs_clean_single_orphan(inode);
+		if (err)
+			apfs_err(sb, "failed to clean orphan 0x%llx (err:%d)", apfs_ino(inode), err);
+		goto out;
+	}
 
-	if (apfs_transaction_start(sb, maxops))
-		goto out_report;
-	if (apfs_delete_inode(inode))
-		goto out_abort;
-	if (apfs_delete_orphan_link(inode))
-		goto out_abort;
-	if (apfs_transaction_commit(sb))
-		goto out_abort;
-	goto out_clear;
-
-out_abort:
-	apfs_transaction_abort(sb);
-out_report:
-	apfs_err(sb, "failed to delete orphan inode 0x%llx", apfs_ino(inode));
-out_clear:
+	/*
+	 * If the inode still has extents then schedule cleanup for the rest
+	 * of it. Not during unmount though: completing all cleanup could take
+	 * a while so just leave future mounts to handle the orphans.
+	 */
+	if (atomic_read(&sb->s_active))
+		schedule_work(&APFS_SB(sb)->s_orphan_cleanup_work);
+out:
 	truncate_inode_pages_final(&inode->i_data);
 	clear_inode(inode);
 }
 
+void apfs_orphan_cleanup_work(struct work_struct *work)
+{
+	struct super_block *sb = NULL;
+	struct apfs_sb_info *sbi = NULL;
+	struct inode *priv = NULL;
+	int err;
+
+	sbi = container_of(work, struct apfs_sb_info, s_orphan_cleanup_work);
+	priv = sbi->s_private_dir;
+	sb = priv->i_sb;
+
+	if (sb->s_flags & SB_RDONLY) {
+		apfs_alert(sb, "attempt to flush orphans in read-only mount");
+		return;
+	}
+
+	err = apfs_clean_orphans(sb);
+	if (err)
+		apfs_err(sb, "orphan cleanup failed (err:%d)", err);
+}
+
 /**
  * apfs_insert_inode_locked - Wrapper for insert_inode_locked4()
  * @inode: vfs inode to insert in cache
@@ -1680,9 +1874,11 @@ struct inode *apfs_new_inode(struct inode *dir, umode_t mode, dev_t rdev)
 	now = current_time(inode);
 #if LINUX_VERSION_CODE < KERNEL_VERSION(6, 6, 0)
 	inode->i_atime = inode->i_mtime = inode->i_ctime = ai->i_crtime = now;
-#else
+#elif LINUX_VERSION_CODE < KERNEL_VERSION(6, 7, 0)
 	inode_set_ctime_to_ts(inode, now);
 	inode->i_atime = inode->i_mtime = ai->i_crtime = now;
+#else
+	ai->i_crtime = simple_inode_init_ts(inode);
 #endif
 	vsb_raw->apfs_last_mod_time = cpu_to_le64(timespec64_to_ns(&now));
 
@@ -1720,18 +1916,16 @@ int apfs_create_inode_rec(struct super_block *sb, struct inode *inode,
 			  struct dentry *dentry)
 {
 	struct apfs_sb_info *sbi = APFS_SB(sb);
-	struct apfs_key key;
 	struct apfs_query *query;
 	struct apfs_inode_key raw_key;
 	struct apfs_inode_val *raw_val;
 	int val_len;
 	int ret;
 
-	apfs_init_inode_key(apfs_ino(inode), &key);
 	query = apfs_alloc_query(sbi->s_cat_root, NULL /* parent */);
 	if (!query)
 		return -ENOMEM;
-	query->key = &key;
+	apfs_init_inode_key(apfs_ino(inode), &query->key);
 	query->flags |= APFS_QUERY_CAT;
 
 	ret = apfs_btree_query(sb, &query);
@@ -1779,8 +1973,10 @@ static int apfs_setsize(struct inode *inode, loff_t new_size)
 		return 0;
 #if LINUX_VERSION_CODE < KERNEL_VERSION(6, 6, 0)
 	inode->i_mtime = inode->i_ctime = current_time(inode);
-#else
+#elif LINUX_VERSION_CODE < KERNEL_VERSION(6, 7, 0)
 	inode->i_mtime = inode_set_ctime_current(inode);
+#else
+	inode_set_mtime_to_ts(inode, inode_set_ctime_current(inode));
 #endif
 
 	err = apfs_inode_create_dstream_rec(inode);
diff --git a/node.c b/node.c
index 184602a..2104177 100644
--- a/node.c
+++ b/node.c
@@ -39,16 +39,20 @@ static bool apfs_node_is_valid(struct super_block *sb,
 
 void apfs_node_free(struct apfs_node *node)
 {
-	struct apfs_object *obj = &node->object;
+	struct apfs_object *obj = NULL;
+
+	if (!node)
+		return;
+	obj = &node->object;
 
 	if (obj->o_bh) {
-		obj->data = NULL;
 		brelse(obj->o_bh);
 		obj->o_bh = NULL;
-	} else {
+	} else if (!obj->ephemeral) {
+		/* Ephemeral data always remains in memory */
 		kfree(obj->data);
-		obj->data = NULL;
 	}
+	obj->data = NULL;
 
 	kfree(node);
 }
@@ -71,9 +75,10 @@ struct apfs_node *apfs_read_node(struct super_block *sb, u64 oid, u32 storage,
 	struct apfs_sb_info *sbi = APFS_SB(sb);
 	struct apfs_nxsb_info *nxi = APFS_NXI(sb);
 	struct buffer_head *bh = NULL;
-	struct apfs_btree_node_phys *raw;
-	struct apfs_node *node;
-	struct apfs_nloc *free_head;
+	struct apfs_ephemeral_object_info *eph_info = NULL;
+	struct apfs_btree_node_phys *raw = NULL;
+	struct apfs_node *node = NULL;
+	struct apfs_nloc *free_head = NULL;
 	u64 bno;
 	int err;
 
@@ -91,6 +96,8 @@ struct apfs_node *apfs_read_node(struct super_block *sb, u64 oid, u32 storage,
 			apfs_err(sb, "object read failed for bno 0x%llx", bno);
 			return (void *)bh;
 		}
+		bno = bh->b_blocknr;
+		raw = (struct apfs_btree_node_phys *)bh->b_data;
 		break;
 	case APFS_OBJ_PHYSICAL:
 		bh = apfs_read_object_block(sb, oid, write, false /* preserve */);
@@ -98,21 +105,30 @@ struct apfs_node *apfs_read_node(struct super_block *sb, u64 oid, u32 storage,
 			apfs_err(sb, "object read failed for bno 0x%llx", oid);
 			return (void *)bh;
 		}
-		oid = bh->b_blocknr;
+		bno = oid = bh->b_blocknr;
+		raw = (struct apfs_btree_node_phys *)bh->b_data;
 		break;
 	case APFS_OBJ_EPHEMERAL:
-		/* Ephemeral objects are checkpoint data, so ignore 'write' */
-		bh = apfs_read_ephemeral_object(sb, oid);
-		if (IS_ERR(bh)) {
-			apfs_err(sb, "ephemeral read failed for oid 0x%llx", oid);
-			return (void *)bh;
+		/* Ephemeral objects are already in memory */
+		eph_info = apfs_ephemeral_object_lookup(sb, oid);
+		if (IS_ERR(eph_info)) {
+			apfs_err(sb, "no ephemeral node for oid 0x%llx", oid);
+			return (void *)eph_info;
+		}
+		if (eph_info->size != sb->s_blocksize) {
+			apfs_err(sb, "unsupported size for ephemeral node (%u)", eph_info->size);
+			return ERR_PTR(-EOPNOTSUPP);
 		}
+		bno = 0; /* In memory, so meaningless */
+		raw = eph_info->object;
+		/* Only for consistency, will happen again on commit */
+		if (write)
+			raw->btn_o.o_xid = cpu_to_le64(nxi->nx_xid);
 		break;
 	default:
 		apfs_alert(sb, "invalid storage type %u - bug!", storage);
 		return ERR_PTR(-EINVAL);
 	}
-	raw = (struct apfs_btree_node_phys *) bh->b_data;
 
 	node = kmalloc(sizeof(*node), GFP_KERNEL);
 	if (!node) {
@@ -134,19 +150,21 @@ struct apfs_node *apfs_read_node(struct super_block *sb, u64 oid, u32 storage,
 	node->val_free_list_len = le16_to_cpu(free_head->len);
 
 	node->object.sb = sb;
-	node->object.block_nr = bh->b_blocknr;
+	node->object.block_nr = bno;
 	node->object.oid = oid;
 	node->object.o_bh = bh;
-	node->object.data = bh->b_data;
+	node->object.data = (char *)raw;
+	node->object.ephemeral = !bh;
 
-	if (nxi->nx_flags & APFS_CHECK_NODES && !apfs_obj_verify_csum(sb, bh)) {
+	/* Ephemeral objects already got checked on mount */
+	if (!node->object.ephemeral && nxi->nx_flags & APFS_CHECK_NODES && !apfs_obj_verify_csum(sb, bh)) {
 		/* TODO: don't check this twice for virtual/physical objects */
-		apfs_err(sb, "bad checksum for node in block 0x%llx", (unsigned long long)bh->b_blocknr);
+		apfs_err(sb, "bad checksum for node in block 0x%llx", (unsigned long long)bno);
 		apfs_node_free(node);
 		return ERR_PTR(-EFSBADCRC);
 	}
 	if (!apfs_node_is_valid(sb, node)) {
-		apfs_err(sb, "bad node in block 0x%llx", (unsigned long long)bh->b_blocknr);
+		apfs_err(sb, "bad node in block 0x%llx", (unsigned long long)bno);
 		apfs_node_free(node);
 		return ERR_PTR(-EFSCORRUPTED);
 	}
@@ -328,9 +346,10 @@ static struct apfs_node *apfs_create_node(struct super_block *sb, u32 storage)
 	struct apfs_nxsb_info *nxi = APFS_NXI(sb);
 	struct apfs_nx_superblock *msb_raw = nxi->nx_raw;
 	struct apfs_superblock *vsb_raw = sbi->s_vsb_raw;
-	struct apfs_node *node;
-	struct buffer_head *bh;
-	struct apfs_btree_node_phys *raw;
+	struct apfs_ephemeral_object_info *eph_info = NULL;
+	struct apfs_node *node = NULL;
+	struct buffer_head *bh = NULL;
+	struct apfs_btree_node_phys *raw = NULL;
 	u64 bno, oid;
 	int err;
 
@@ -366,29 +385,38 @@ static struct apfs_node *apfs_create_node(struct super_block *sb, u32 storage)
 		oid = bno;
 		break;
 	case APFS_OBJ_EPHEMERAL:
-		apfs_cpoint_data_allocate(sb, &bno);
-		oid = le64_to_cpu(msb_raw->nx_next_oid);
-		le64_add_cpu(&msb_raw->nx_next_oid, 1);
-
-		err = apfs_create_cpoint_map(sb, oid, bno);
-		if (err) {
-			apfs_err(sb, "checkpoint map creation failed (0x%llx-0x%llx)", oid, bno);
-			return ERR_PTR(err);
+		if (nxi->nx_eph_count >= APFS_EPHEMERAL_LIST_LIMIT) {
+			apfs_err(sb, "creating too many ephemeral objects?");
+			return ERR_PTR(-EOPNOTSUPP);
 		}
+		eph_info = &nxi->nx_eph_list[nxi->nx_eph_count++];
+		eph_info->object = kzalloc(sb->s_blocksize, GFP_KERNEL);
+		if (!eph_info->object)
+			return ERR_PTR(-ENOMEM);
+		eph_info->size = sb->s_blocksize;
+		oid = eph_info->oid = le64_to_cpu(msb_raw->nx_next_oid);
+		le64_add_cpu(&msb_raw->nx_next_oid, 1);
 		break;
 	default:
 		apfs_alert(sb, "invalid storage type %u - bug!", storage);
 		return ERR_PTR(-EINVAL);
 	}
 
-	bh = apfs_getblk(sb, bno);
-	if (!bh)
-		return ERR_PTR(-EIO);
-	raw = (void *)bh->b_data;
-	err = apfs_transaction_join(sb, bh);
-	if (err)
-		goto fail;
-	set_buffer_csum(bh);
+	if (storage == APFS_OBJ_EPHEMERAL) {
+		bh = NULL;
+		bno = 0;
+		raw = eph_info->object;
+	} else {
+		bh = apfs_getblk(sb, bno);
+		if (!bh)
+			return ERR_PTR(-EIO);
+		bno = bh->b_blocknr;
+		raw = (void *)bh->b_data;
+		err = apfs_transaction_join(sb, bh);
+		if (err)
+			goto fail;
+		set_buffer_csum(bh);
+	}
 
 	/* Set most of the object header, but the subtype is up to the caller */
 	raw->btn_o.o_oid = cpu_to_le64(oid);
@@ -416,46 +444,42 @@ static struct apfs_node *apfs_create_node(struct super_block *sb, u32 storage)
 	}
 
 	node->object.sb = sb;
-	node->object.block_nr = bh->b_blocknr;
+	node->object.block_nr = bno;
 	node->object.oid = oid;
 	node->object.o_bh = bh;
-	node->object.data = bh->b_data;
+	node->object.data = (char *)raw;
+	node->object.ephemeral = !bh;
 	return node;
 
 fail:
-	brelse(bh);
+	if (storage == APFS_OBJ_EPHEMERAL)
+		kfree(raw);
+	else
+		brelse(bh);
+	raw = NULL;
+	bh = NULL;
 	return ERR_PTR(err);
 }
 
 /**
  * apfs_delete_node - Deletes a nonroot node from disk
- * @query: query pointing to the node
+ * @node: node to delete
+ * @type: tree type for the query that found the node
  *
  * Does nothing to the in-memory node structure.  Returns 0 on success, or a
  * negative error code in case of failure.
  */
-int apfs_delete_node(struct apfs_query *query)
+int apfs_delete_node(struct apfs_node *node, int type)
 {
-	struct super_block *sb = query->node->object.sb;
+	struct super_block *sb = node->object.sb;
+	struct apfs_nxsb_info *nxi = APFS_NXI(sb);
 	struct apfs_superblock *vsb_raw;
-	struct apfs_node *node = query->node;
 	u64 oid = node->object.oid;
 	u64 bno = node->object.block_nr;
+	struct apfs_ephemeral_object_info *eph_info = NULL, *eph_info_end = NULL;
 	int err;
 
-	ASSERT(query->parent);
-
-	/*
-	 * For ephemeral nodes, it's important to do this before actually
-	 * deleting the node, because that involves moving blocks around.
-	 */
-	err = apfs_btree_remove(query->parent);
-	if (err) {
-		apfs_err(sb, "parent index removal failed for oid x%llx", oid);
-		return err;
-	}
-
-	switch (query->flags & APFS_QUERY_TREE_MASK) {
+	switch (type) {
 	case APFS_QUERY_CAT:
 		err = apfs_free_queue_insert(sb, bno, 1);
 		if (err) {
@@ -487,19 +511,20 @@ int apfs_delete_node(struct apfs_query *query)
 		le64_add_cpu(&vsb_raw->apfs_total_blocks_freed, 1);
 		return 0;
 	case APFS_QUERY_FREE_QUEUE:
-		err = apfs_cpoint_data_free(sb, bno);
-		if (err) {
-			apfs_err(sb, "failed to free checkpoint block 0x%llx", bno);
-			return err;
-		}
-		err = apfs_remove_cpoint_map(sb, bno);
-		if (err) {
-			apfs_err(sb, "checkpoint map removal failed (0x%llx)", bno);
-			return err;
+		eph_info_end = &nxi->nx_eph_list[nxi->nx_eph_count];
+		eph_info = apfs_ephemeral_object_lookup(sb, node->object.oid);
+		if (IS_ERR(eph_info)) {
+			apfs_alert(sb, "can't find ephemeral object to delete");
+			return PTR_ERR(eph_info);
 		}
+		kfree(eph_info->object);
+		eph_info->object = NULL;
+		memmove(eph_info, eph_info + 1, (char *)eph_info_end - (char *)(eph_info + 1));
+		eph_info_end->object = NULL;
+		--nxi->nx_eph_count;
 		return 0;
 	default:
-		apfs_alert(sb, "new query type must implement node deletion (%d)", query->flags & APFS_QUERY_TREE_MASK);
+		apfs_alert(sb, "new query type must implement node deletion (%d)", type);
 		return -EOPNOTSUPP;
 	}
 }
@@ -546,9 +571,10 @@ void apfs_update_node(struct apfs_node *node)
 	if (!free_head->len)
 		free_head->off = cpu_to_le16(APFS_BTOFF_INVALID);
 
-	(void)bh;
-	ASSERT(buffer_trans(bh));
-	ASSERT(buffer_csum(bh));
+	if (bh) {
+		ASSERT(buffer_trans(bh));
+		ASSERT(buffer_csum(bh));
+	}
 }
 
 /**
@@ -633,8 +659,10 @@ static int apfs_node_locate_data(struct apfs_node *node, int index, int *off)
 		entry = (struct apfs_kvoff *)raw->btn_data + index;
 		if (node->tree_type == APFS_OBJECT_TYPE_SPACEMAN_FREE_QUEUE) {
 			/* A free-space queue record may have no value */
-			if (le16_to_cpu(entry->v) == APFS_BTOFF_INVALID)
+			if (le16_to_cpu(entry->v) == APFS_BTOFF_INVALID) {
+				*off = 0;
 				return 0;
+			}
 			len = 8;
 		} else {
 			/* This is an omap or omap snapshots node */
@@ -775,6 +803,42 @@ static int apfs_key_from_query(struct apfs_query *query, struct apfs_key *key)
 	return err;
 }
 
+/**
+ * apfs_node_prev - Find the previous record in the current node
+ * @sb:		filesystem superblock
+ * @query:	query in execution
+ *
+ * Returns 0 on success, -EAGAIN if the previous record is in another node,
+ * -ENODATA if no more records exist, or another negative error code in case
+ * of failure.
+ *
+ * The meaning of "next" and "previous" is reverted here, because regular
+ * multiple always start with the final record, and then they go backwards.
+ * TODO: consider renaming this for clarity.
+ */
+static int apfs_node_prev(struct super_block *sb, struct apfs_query *query)
+{
+	struct apfs_node *node = query->node;
+
+	if (query->index + 1 == node->records) {
+		/* The next record may be in another node */
+		return -EAGAIN;
+	}
+	++query->index;
+
+	query->key_len = apfs_node_locate_key(node, query->index, &query->key_off);
+	if (query->key_len == 0) {
+		apfs_err(sb, "bad key for index %d", query->index);
+		return -EFSCORRUPTED;
+	}
+	query->len = apfs_node_locate_data(node, query->index, &query->off);
+	if (query->len == 0) {
+		apfs_err(sb, "bad value for index %d", query->index);
+		return -EFSCORRUPTED;
+	}
+	return 0;
+}
+
 /**
  * apfs_node_next - Find the next matching record in the current node
  * @sb:		filesystem superblock
@@ -806,7 +870,7 @@ static int apfs_node_next(struct super_block *sb, struct apfs_query *query)
 		return err;
 	}
 
-	cmp = apfs_keycmp(&curr_key, query->key);
+	cmp = apfs_keycmp(&curr_key, &query->key);
 
 	if (cmp > 0) {
 		apfs_err(sb, "records are out of order");
@@ -864,6 +928,8 @@ int apfs_node_query(struct super_block *sb, struct apfs_query *query)
 	int cmp;
 	int err;
 
+	if (query->flags & APFS_QUERY_PREV)
+		return apfs_node_prev(sb, query);
 	if (query->flags & APFS_QUERY_NEXT)
 		return apfs_node_next(sb, query);
 
@@ -893,7 +959,7 @@ int apfs_node_query(struct super_block *sb, struct apfs_query *query)
 			return err;
 		}
 
-		cmp = apfs_keycmp(&curr_key, query->key);
+		cmp = apfs_keycmp(&curr_key, &query->key);
 		if (cmp == 0 && !(query->flags & APFS_QUERY_MULTIPLE))
 			break;
 	} while (left != right);
@@ -1159,8 +1225,9 @@ fail:
  * @query:	query pointing to the previous record in the parent
  * @child:	the new child node to attach
  *
- * Returns 0 on success or a negative error code in case of failure; @query is
- * rendered invalid either way and must be freed by the caller.
+ * Returns 0 on success or a negative error code in case of failure (which may
+ * be -EAGAIN if a node split has happened and the caller must refresh and
+ * retry).
  */
 static int apfs_attach_child(struct apfs_query *query, struct apfs_node *child)
 {
@@ -1176,8 +1243,7 @@ static int apfs_attach_child(struct apfs_query *query, struct apfs_node *child)
 		return -EFSCORRUPTED;
 	}
 
-	return apfs_btree_insert(query, (void *)raw + key_off, key_len,
-				 &raw_oid, sizeof(raw_oid));
+	return __apfs_btree_insert(query, (void *)raw + key_off, key_len, &raw_oid, sizeof(raw_oid));
 }
 
 /**
@@ -1199,6 +1265,7 @@ static int apfs_node_temp_dup(const struct apfs_node *original, struct apfs_node
 	*dup = *original;
 	dup->object.o_bh = NULL;
 	dup->object.data = NULL;
+	dup->object.ephemeral = false;
 
 	buffer = kmalloc(sb->s_blocksize, GFP_KERNEL);
 	if (!buffer) {
@@ -1217,19 +1284,21 @@ static int apfs_node_temp_dup(const struct apfs_node *original, struct apfs_node
  * @query: query pointing to the node
  *
  * On success returns 0, and @query is left pointing to the same record on the
- * leaf; to simplify the implementation, @query->parent is set to NULL.  Returns
- * a negative error code in case of failure.
+ * tip; to simplify the implementation, @query->parent is set to NULL. Returns
+ * a negative error code in case of failure, which may be -EAGAIN if a node
+ * split has happened and the caller must refresh and retry.
  */
 int apfs_node_split(struct apfs_query *query)
 {
 	struct super_block *sb = query->node->object.sb;
-	struct apfs_node *old_node;
-	struct apfs_btree_node_phys *old_raw;
-	struct apfs_node *tmp_node = NULL;
+	struct apfs_node *old_node = NULL, *new_node = NULL, *tmp_node = NULL;
+	struct apfs_btree_node_phys *new_raw = NULL, *old_raw = NULL;
 	u32 storage = apfs_query_storage(query);
 	int record_count, new_rec_count, old_rec_count;
 	int err;
 
+	apfs_assert_query_is_valid(query);
+
 	if (apfs_node_is_root(query->node)) {
 		err = apfs_btree_inc_height(query);
 		if (err) {
@@ -1253,79 +1322,95 @@ int apfs_node_split(struct apfs_query *query)
 	if (err)
 		return err;
 
-	/*
-	 * The first half of the records go in the original node. If there's
-	 * only one record, just defragment the node and don't split anything.
-	 */
 	record_count = old_node->records;
+	if (record_count == 1) {
+		apfs_alert(sb, "splitting node with a single record");
+		err = -EFSCORRUPTED;
+		goto out;
+	}
 	new_rec_count = record_count / 2;
 	old_rec_count = record_count - new_rec_count;
-	old_node->records = 0;
-	old_node->key_free_list_len = 0;
-	old_node->val_free_list_len = 0;
-	err = apfs_copy_record_range(old_node, tmp_node, 0, old_rec_count);
+
+	/*
+	 * The second half of the records go into a new node. This is done
+	 * before the first half to avoid committing to any actual changes
+	 * until we know for sure that no ancestor splits are expected.
+	 */
+
+	new_node = apfs_create_node(sb, storage);
+	if (IS_ERR(new_node)) {
+		apfs_err(sb, "node creation failed");
+		err = PTR_ERR(new_node);
+		new_node = NULL;
+		goto out;
+	}
+	new_node->tree_type = old_node->tree_type;
+	new_node->flags = old_node->flags;
+	new_node->records = 0;
+	new_node->key_free_list_len = 0;
+	new_node->val_free_list_len = 0;
+	err = apfs_copy_record_range(new_node, tmp_node, old_rec_count, record_count);
 	if (err) {
 		apfs_err(sb, "record copy failed");
 		goto out;
 	}
-	apfs_update_node(old_node);
-
-	/* The second half is copied to a new node */
-	if (new_rec_count != 0) {
-		struct apfs_node *new_node;
-		struct apfs_btree_node_phys *new_raw;
-
-		apfs_btree_change_node_count(query->parent, 1 /* change */);
+	new_raw = (void *)new_node->object.data;
+	apfs_assert_in_transaction(sb, &new_raw->btn_o);
+	new_raw->btn_level = old_raw->btn_level;
+	apfs_update_node(new_node);
 
-		new_node = apfs_create_node(sb, storage);
-		if (IS_ERR(new_node)) {
-			apfs_err(sb, "node creation failed");
-			err = PTR_ERR(new_node);
+	err = apfs_attach_child(query->parent, new_node);
+	if (err) {
+		if (err != -EAGAIN) {
+			apfs_err(sb, "child attachment failed");
 			goto out;
 		}
-		new_node->tree_type = old_node->tree_type;
-		new_node->flags = old_node->flags;
-		new_node->records = 0;
-		new_node->key_free_list_len = 0;
-		new_node->val_free_list_len = 0;
-		err = apfs_copy_record_range(new_node, tmp_node, old_rec_count, record_count);
+		err = apfs_delete_node(new_node, query->flags & APFS_QUERY_TREE_MASK);
 		if (err) {
-			apfs_err(sb, "record copy failed");
-			apfs_node_free(new_node);
+			apfs_err(sb, "node cleanup failed for query retry");
 			goto out;
 		}
-		new_raw = (void *)new_node->object.data;
-		apfs_assert_in_transaction(sb, &new_raw->btn_o);
-		new_raw->btn_level = old_raw->btn_level;
-		apfs_update_node(new_node);
+		err = -EAGAIN;
+		goto out;
+	}
+	apfs_assert_query_is_valid(query->parent);
+	apfs_btree_change_node_count(query->parent, 1 /* change */);
 
-		err = apfs_attach_child(query->parent, new_node);
-		if (err) {
-			apfs_err(sb, "child attachment failed");
-			apfs_node_free(new_node);
-			goto out;
-		}
+	/*
+	 * No more risk of ancestor splits, now actual changes can be made. The
+	 * first half of the records go into the original node.
+	 */
 
-		/* Point the query back to the original record */
-		if (query->index >= old_rec_count) {
-			/* The record got moved to the new node */
-			apfs_node_free(query->node);
-			query->node = new_node;
-			query->index -= old_rec_count;
-		} else {
-			apfs_node_free(new_node);
-		}
+	old_node->records = 0;
+	old_node->key_free_list_len = 0;
+	old_node->val_free_list_len = 0;
+	err = apfs_copy_record_range(old_node, tmp_node, 0, old_rec_count);
+	if (err) {
+		apfs_err(sb, "record copy failed");
+		goto out;
+	}
+	apfs_update_node(old_node);
+
+	/* Point the query back to the original record */
+	if (query->index >= old_rec_count) {
+		/* The record got moved to the new node */
+		apfs_node_free(query->node);
+		query->node = new_node;
+		new_node = NULL;
+		query->index -= old_rec_count;
 	}
+
+	/*
+	 * This could be avoided in most cases, and queries could get refreshed
+	 * only when really orphaned. But refreshing queries is probably not a
+	 * bottleneck, and trying to be clever with this stuff has caused me a
+	 * lot of trouble already.
+	 */
 	apfs_free_query(query->parent);
 	query->parent = NULL; /* The caller only gets the leaf */
 
-	/* Updating these fields isn't really necessary, but it's cleaner */
-	query->len = apfs_node_locate_data(query->node, query->index,
-					   &query->off);
-	query->key_len = apfs_node_locate_key(query->node, query->index,
-					      &query->key_off);
-
 out:
+	apfs_node_free(new_node);
 	apfs_node_free(tmp_node);
 	return err;
 }
@@ -1459,7 +1544,7 @@ static void apfs_node_free_list_unlink(struct apfs_nloc *prev, struct apfs_nloc
  * @value:	true to allocate in the value area, false for the key area
  *
  * Returns the offset in the node on success, or a negative error code in case
- * of failure.
+ * of failure, which may be -ENOSPC if the node seems full.
  */
 static int apfs_node_free_list_alloc(struct apfs_node *node, u16 len, bool value)
 {
@@ -1525,7 +1610,7 @@ static int apfs_node_free_list_alloc(struct apfs_node *node, u16 len, bool value
  * @len:	wanted key length
  *
  * Returns the offset in the node on success, or a negative error code in case
- * of failure.
+ * of failure, which may be -ENOSPC if the node seems full.
  */
 static int apfs_node_alloc_key(struct apfs_node *node, u16 len)
 {
@@ -1545,7 +1630,7 @@ static int apfs_node_alloc_key(struct apfs_node *node, u16 len)
  * @len:	wanted value length
  *
  * Returns the offset in the node on success, or a negative error code in case
- * of failure.
+ * of failure, which may be -ENOSPC if the node seems full.
  */
 static int apfs_node_alloc_val(struct apfs_node *node, u16 len)
 {
@@ -1560,7 +1645,107 @@ static int apfs_node_alloc_val(struct apfs_node *node, u16 len)
 }
 
 /**
- * apfs_node_replace - Replace a record in a node
+ * apfs_node_total_room - Total free space in a node
+ * @node: the node
+ */
+static int apfs_node_total_room(struct apfs_node *node)
+{
+	return node->data - node->free + node->key_free_list_len + node->val_free_list_len;
+}
+
+/**
+ * apfs_node_has_room - Check if a node has room for insertion or replacement
+ * @node:	node to check
+ * @length:	length of the needed space (may be negative on replace)
+ * @replace:	are we replacing a record?
+ */
+bool apfs_node_has_room(struct apfs_node *node, int length, bool replace)
+{
+	struct apfs_btree_node_phys *node_raw = (void *)node->object.data;
+	int toc_entry_size, needed_room;
+
+	if (apfs_node_has_fixed_kv_size(node))
+		toc_entry_size = sizeof(struct apfs_kvoff);
+	else
+		toc_entry_size = sizeof(struct apfs_kvloc);
+
+	needed_room = length;
+	if (!replace) {
+		if (sizeof(*node_raw) + (node->records + 1) * toc_entry_size > node->key)
+			needed_room += APFS_BTREE_TOC_ENTRY_INCREMENT * toc_entry_size;
+	}
+
+	return apfs_node_total_room(node) >= needed_room;
+}
+
+/**
+ * apfs_defragment_node - Make all free space in a node contiguous
+ * @node: node to defragment
+ *
+ * Returns 0 on success or a negative error code in case of failure.
+ */
+static int apfs_defragment_node(struct apfs_node *node)
+{
+	struct super_block *sb = node->object.sb;
+	struct apfs_btree_node_phys *node_raw = (void *)node->object.data;
+	struct apfs_node *tmp_node = NULL;
+	int record_count, err;
+
+	apfs_assert_in_transaction(sb, &node_raw->btn_o);
+
+	/* Put all records in a temporary in-memory node and deal them out */
+	err = apfs_node_temp_dup(node, &tmp_node);
+	if (err)
+		return err;
+	record_count = node->records;
+	node->records = 0;
+	node->key_free_list_len = 0;
+	node->val_free_list_len = 0;
+	err = apfs_copy_record_range(node, tmp_node, 0, record_count);
+	if (err) {
+		apfs_err(sb, "record copy failed");
+		goto fail;
+	}
+	apfs_update_node(node);
+fail:
+	apfs_node_free(tmp_node);
+	return err;
+}
+
+/**
+ * apfs_node_update_toc_entry - Update a table of contents entry in place
+ * @query: query pointing to the toc entry
+ *
+ * The toc entry gets updated with the length and offset for the key/value
+ * provided by @query. Don't call this function for nodes with fixed length
+ * key/values, those never need to update their toc entries.
+ */
+static void apfs_node_update_toc_entry(struct apfs_query *query)
+{
+	struct super_block *sb = NULL;
+	struct apfs_node *node = NULL;
+	struct apfs_btree_node_phys *node_raw = NULL;
+	struct apfs_kvloc *kvloc = NULL;
+	int value_end;
+
+	node = query->node;
+	ASSERT(!apfs_node_has_fixed_kv_size(node));
+	sb = node->object.sb;
+	node_raw = (void *)node->object.data;
+
+	value_end = sb->s_blocksize;
+	if (apfs_node_is_root(node))
+		value_end -= sizeof(struct apfs_btree_info);
+
+	kvloc = (struct apfs_kvloc *)node_raw->btn_data + query->index;
+	kvloc->v.off = cpu_to_le16(value_end - query->off);
+	kvloc->v.len = cpu_to_le16(query->len);
+	kvloc->k.off = cpu_to_le16(query->key_off - node->key);
+	kvloc->k.len = cpu_to_le16(query->key_len);
+}
+
+/**
+ * apfs_node_replace - Replace a record in a node that has enough room
  * @query:	exact query that found the record
  * @key:	new on-disk record key (NULL if unchanged)
  * @key_len:	length of @key
@@ -1568,21 +1753,30 @@ static int apfs_node_alloc_val(struct apfs_node *node, u16 len)
  * @val_len:	length of @val
  *
  * Returns 0 on success, and @query is left pointing to the same record. Returns
- * a negative error code in case of failure, which may be -ENOSPC if the node
- * seems full.
+ * a negative error code in case of failure.
  */
 int apfs_node_replace(struct apfs_query *query, void *key, int key_len, void *val, int val_len)
 {
 	struct apfs_node *node = query->node;
 	struct super_block *sb = node->object.sb;
 	struct apfs_btree_node_phys *node_raw = (void *)node->object.data;
-	int old_free = node->free, old_data = node->data;
-	int old_key_free_len = node->key_free_list_len;
-	int old_val_free_len = node->val_free_list_len;
 	int key_off = 0, val_off = 0, err = 0;
+	bool defragged = false;
+	int qtree = query->flags & APFS_QUERY_TREE_MASK;
 
 	apfs_assert_in_transaction(sb, &node_raw->btn_o);
 
+	/*
+	 * Free queues are weird because their tables of contents don't report
+	 * record lengths, as if they were fixed, but some of the leaf values
+	 * are actually "ghosts", that is, zero-length. Supporting replace of
+	 * such records would require some changes, and so far I've had no need
+	 * for it.
+	 */
+	(void)qtree;
+	ASSERT(!(qtree == APFS_QUERY_FREE_QUEUE && apfs_node_is_leaf(node)));
+
+retry:
 	if (key) {
 		if (key_len <= query->key_len) {
 			u16 end = query->key_off + key_len;
@@ -1594,8 +1788,9 @@ int apfs_node_replace(struct apfs_query *query, void *key, int key_len, void *va
 			apfs_node_free_range(node, query->key_off, query->key_len);
 			key_off = apfs_node_alloc_key(node, key_len);
 			if (key_off < 0) {
-				err = key_off;
-				goto fail;
+				if (key_off == -ENOSPC)
+					goto defrag;
+				return key_off;
 			}
 		}
 	}
@@ -1611,8 +1806,9 @@ int apfs_node_replace(struct apfs_query *query, void *key, int key_len, void *va
 			apfs_node_free_range(node, query->off, query->len);
 			val_off = apfs_node_alloc_val(node, val_len);
 			if (val_off < 0) {
-				err = val_off;
-				goto fail;
+				if (val_off == -ENOSPC)
+					goto defrag;
+				return val_off;
 			}
 		}
 	}
@@ -1629,83 +1825,44 @@ int apfs_node_replace(struct apfs_query *query, void *key, int key_len, void *va
 	}
 
 	/* If the key or value were resized, update the table of contents */
-	if (!apfs_node_has_fixed_kv_size(node)) {
-		struct apfs_kvloc *kvloc;
-		int value_end;
-
-		value_end = sb->s_blocksize;
-		if (apfs_node_is_root(node))
-			value_end -= sizeof(struct apfs_btree_info);
-
-		kvloc = (struct apfs_kvloc *)node_raw->btn_data + query->index;
-		kvloc->v.off = cpu_to_le16(value_end - query->off);
-		kvloc->v.len = cpu_to_le16(query->len);
-		kvloc->k.off = cpu_to_le16(query->key_off - node->key);
-		kvloc->k.len = cpu_to_le16(query->key_len);
-	}
+	if (!apfs_node_has_fixed_kv_size(node))
+		apfs_node_update_toc_entry(query);
 
 	apfs_update_node(node);
 	return 0;
 
-fail:
-	/*
-	 * This isn't very tidy, but the transaction may continue on -ENOSPC,
-	 * so we must restore the in-memory node fields that may have been
-	 * modified. The on-disk free lists can be ignored because the node
-	 * should be split soon.
-	 */
-	node->free = old_free;
-	node->data = old_data;
-	node->key_free_list_len = old_key_free_len;
-	node->val_free_list_len = old_val_free_len;
-	return err;
-}
-
-/**
- * apfs_node_total_room - Total free space in a node
- * @node: the node
- */
-static int apfs_node_total_room(struct apfs_node *node)
-{
-	return node->data - node->free + node->key_free_list_len + node->val_free_list_len;
-}
-
-/**
- * apfs_defragment_node - Make all free space in a node contiguous
- * @node: node to defragment
- *
- * Returns 0 on success or a negative error code in case of failure.
- */
-static int apfs_defragment_node(struct apfs_node *node)
-{
-	struct super_block *sb = node->object.sb;
-	struct apfs_btree_node_phys *node_raw = (void *)node->object.data;
-	struct apfs_node *tmp_node = NULL;
-	int record_count, err;
+defrag:
+	if (defragged) {
+		apfs_alert(sb, "no room in defragged node");
+		return -EFSCORRUPTED;
+	}
 
-	apfs_assert_in_transaction(sb, &node_raw->btn_o);
+	/* Crush the replaced entry, so that defragmentation is complete */
+	if (apfs_node_has_fixed_kv_size(node)) {
+		apfs_alert(sb, "failed to replace a fixed size record");
+		return -EFSCORRUPTED;
+	}
+	if (key)
+		query->key_len = 0;
+	if (val)
+		query->len = 0;
+	apfs_node_update_toc_entry(query);
 
-	/* Put all records in a temporary in-memory node and deal them out */
-	err = apfs_node_temp_dup(node, &tmp_node);
-	if (err)
-		return err;
-	record_count = node->records;
-	node->records = 0;
-	node->key_free_list_len = 0;
-	node->val_free_list_len = 0;
-	err = apfs_copy_record_range(node, tmp_node, 0, record_count);
+	err = apfs_defragment_node(node);
 	if (err) {
-		apfs_err(sb, "record copy failed");
-		goto fail;
+		apfs_err(sb, "failed to defragment node");
+		return err;
 	}
-	apfs_update_node(node);
-fail:
-	apfs_node_free(tmp_node);
-	return err;
+	defragged = true;
+
+	/* The record to replace probably moved around */
+	query->len = apfs_node_locate_data(query->node, query->index, &query->off);
+	query->key_len = apfs_node_locate_key(query->node, query->index, &query->key_off);
+	goto retry;
 }
 
 /**
- * apfs_node_insert - Insert a new record in a node
+ * apfs_node_insert - Insert a new record in a node that has enough room
  * @query:	query run to search for the record
  * @key:	on-disk record key
  * @key_len:	length of @key
@@ -1714,8 +1871,7 @@ fail:
  *
  * The new record is placed right after the one found by @query. On success,
  * returns 0 and sets @query to the new record. In case of failure, returns a
- * negative error code and leaves @query pointing to the same record. The error
- * may be -ENOSPC if the node seems full.
+ * negative error code and leaves @query pointing to the same record.
  */
 int apfs_node_insert(struct apfs_query *query, void *key, int key_len, void *val, int val_len)
 {
@@ -1723,25 +1879,19 @@ int apfs_node_insert(struct apfs_query *query, void *key, int key_len, void *val
 	struct super_block *sb = node->object.sb;
 	struct apfs_btree_node_phys *node_raw = (void *)node->object.data;
 	int toc_entry_size;
-	int old_free, old_data, old_key_free_len, old_val_free_len;
 	int key_off, val_off, err;
-	int needed_room;
 	bool defragged = false;
 
 	apfs_assert_in_transaction(sb, &node_raw->btn_o);
 
 retry:
-	needed_room = key_len + val_len;
-	err = 0;
-
 	if (apfs_node_has_fixed_kv_size(node))
 		toc_entry_size = sizeof(struct apfs_kvoff);
 	else
 		toc_entry_size = sizeof(struct apfs_kvloc);
 
 	/* Expand the table of contents if necessary */
-	if (sizeof(*node_raw) +
-	    (node->records + 1) * toc_entry_size > node->key) {
+	if (sizeof(*node_raw) + (node->records + 1) * toc_entry_size > node->key) {
 		int new_key_base = node->key;
 		int new_free_base = node->free;
 		int inc;
@@ -1750,11 +1900,8 @@ retry:
 
 		new_key_base += inc;
 		new_free_base += inc;
-		if (new_free_base > node->data) {
-			needed_room += inc;
-			err = -ENOSPC;
-			goto fail_defrag;
-		}
+		if (new_free_base > node->data)
+			goto defrag;
 		memmove((void *)node_raw + new_key_base,
 			(void *)node_raw + node->key, node->free - node->key);
 
@@ -1763,22 +1910,25 @@ retry:
 		query->key_off += inc;
 	}
 
-	old_free = node->free;
-	old_data = node->data;
-	old_key_free_len = node->key_free_list_len;
-	old_val_free_len = node->val_free_list_len;
-
 	key_off = apfs_node_alloc_key(node, key_len);
 	if (key_off < 0) {
-		err = key_off;
-		goto fail_update;
+		if (key_off == -ENOSPC)
+			goto defrag;
+		return key_off;
 	}
 
 	if (val) {
 		val_off = apfs_node_alloc_val(node, val_len);
 		if (val_off < 0) {
-			err = val_off;
-			goto fail_update;
+			if (val_off == -ENOSPC) {
+				/*
+				 * There is no need for an update of the on-disk
+				 * node before the defrag, since only in-memory
+				 * data should be used there...
+				 */
+				goto defrag;
+			}
+			return val_off;
 		}
 	}
 
@@ -1790,6 +1940,8 @@ retry:
 	if (val) {
 		query->off = val_off;
 		memcpy((void *)node_raw + val_off, val, val_len);
+	} else {
+		query->off = 0;
 	}
 
 	query->index++; /* The query returned the record right before @key */
@@ -1797,39 +1949,21 @@ retry:
 	/* Add the new entry to the table of contents */
 	apfs_create_toc_entry(query);
 
-fail_update:
-	/*
-	 * We must update the on-disk node even on failure, because we did
-	 * expand the table of contents.
-	 */
-	if (err) {
-		node->free = old_free;
-		node->data = old_data;
-		node->key_free_list_len = old_key_free_len;
-		node->val_free_list_len = old_val_free_len;
-	}
 	apfs_update_node(node);
-fail_defrag:
-	if (err == -ENOSPC && !defragged && needed_room <= apfs_node_total_room(node)) {
-		/*
-		 * If we know we should have enough room, defragment the node
-		 * and retry the insertion to avoid a split. This is especially
-		 * important for the ip free queue, because it has a very low
-		 * hard limit in the number of nodes allowed.
-		 */
-		err = apfs_defragment_node(node);
-		if (err) {
-			apfs_err(sb, "failed to defragment node");
-			return err;
-		}
-		defragged = true;
-		goto retry;
-	}
-	if (err == -ENOSPC && defragged) {
+	return 0;
+
+defrag:
+	if (defragged) {
 		apfs_err(sb, "node reports incorrect free space");
-		err = -EFSCORRUPTED;
+		return -EFSCORRUPTED;
 	}
-	return err;
+	err = apfs_defragment_node(node);
+	if (err) {
+		apfs_err(sb, "failed to defragment node");
+		return err;
+	}
+	defragged = true;
+	goto retry;
 }
 
 /**
@@ -1842,17 +1976,20 @@ fail_defrag:
  *
  * The new node is placed right after the one found by @query, which must have
  * a single record. On success, returns 0 and sets @query to the new record;
- * returns a negative error code in case of failure.
+ * returns a negative error code in case of failure, which may be -EAGAIN if a
+ * node split has happened and the caller must refresh and retry.
  */
 int apfs_create_single_rec_node(struct apfs_query *query, void *key, int key_len, void *val, int val_len)
 {
-	struct apfs_node *prev_node = query->node;
-	struct super_block *sb = prev_node->object.sb;
-	struct apfs_node *new_node = NULL;
+	struct super_block *sb = NULL;
+	struct apfs_node *new_node = NULL, *prev_node = NULL;
 	struct apfs_btree_node_phys *prev_raw = NULL;
 	struct apfs_btree_node_phys *new_raw = NULL;
 	int err;
 
+	prev_node = query->node;
+	sb = prev_node->object.sb;
+
 	ASSERT(query->parent);
 	ASSERT(prev_node->records == 1);
 	ASSERT(val && val_len);
@@ -1863,7 +2000,15 @@ int apfs_create_single_rec_node(struct apfs_query *query, void *key, int key_len
 		return -EFSCORRUPTED;
 	}
 
-	apfs_btree_change_node_count(query->parent, 1 /* change */);
+	/*
+	 * This will only be called for leaf nodes because it's the values that
+	 * can get huge, not the keys. It will also never be called for root,
+	 * because the catalog always has more than a single record.
+	 */
+	if (apfs_node_is_root(prev_node) || !apfs_node_is_leaf(prev_node)) {
+		apfs_err(sb, "huge record in index node");
+		return -EFSCORRUPTED;
+	}
 
 	new_node = apfs_create_node(sb, apfs_query_storage(query));
 	if (IS_ERR(new_node)) {
@@ -1884,19 +2029,41 @@ int apfs_create_single_rec_node(struct apfs_query *query, void *key, int key_len
 	new_raw->btn_level = prev_raw->btn_level;
 	apfs_update_node(new_node);
 
-	prev_node = NULL;
-	prev_raw = NULL;
-	apfs_node_free(query->node);
-
 	query->node = new_node;
+	new_node = NULL;
 	query->index = -1;
 	err = apfs_node_insert(query, key, key_len, val, val_len);
 	if (err) {
 		apfs_err(sb, "node record insertion failed");
-		return err;
+		goto fail;
 	}
-	err = apfs_attach_child(query->parent, new_node);
-	if (err)
-		apfs_err(sb, "child attachment failed");
+
+	err = apfs_attach_child(query->parent, query->node);
+	if (err) {
+		if (err != -EAGAIN) {
+			apfs_err(sb, "child attachment failed");
+			goto fail;
+		}
+		err = apfs_delete_node(query->node, query->flags & APFS_QUERY_TREE_MASK);
+		if (err) {
+			apfs_err(sb, "node cleanup failed for query retry");
+			goto fail;
+		}
+
+		/*
+		 * The query must remain pointing to the original node for the
+		 * refresh to take place. The index will not matter though.
+		 */
+		new_node = query->node;
+		query->node = prev_node;
+		prev_node = NULL;
+		err = -EAGAIN;
+		goto fail;
+	}
+	apfs_btree_change_node_count(query->parent, 1 /* change */);
+
+fail:
+	apfs_node_free(prev_node);
+	apfs_node_free(new_node);
 	return err;
 }
diff --git a/object.c b/object.c
index cefce0e..9636a9a 100644
--- a/object.c
+++ b/object.c
@@ -37,131 +37,129 @@ static u64 apfs_fletcher64(void *addr, size_t len)
 
 int apfs_obj_verify_csum(struct super_block *sb, struct buffer_head *bh)
 {
-	struct apfs_obj_phys *obj = (struct apfs_obj_phys *)bh->b_data;
-
 	/* The checksum may be stale until the transaction is committed */
 	if (buffer_trans(bh))
 		return 1;
+	return apfs_multiblock_verify_csum(bh->b_data, sb->s_blocksize);
+}
 
-	return  (le64_to_cpu(obj->o_cksum) ==
-		 apfs_fletcher64((char *) obj + APFS_MAX_CKSUM_SIZE,
-				 sb->s_blocksize - APFS_MAX_CKSUM_SIZE));
+/**
+ * apfs_multiblock_verify_csum - Verify an object's checksum
+ * @object:	the object to verify
+ * @size:	size of the object in bytes (may be multiple blocks)
+ *
+ * Returns 1 on success, 0 on failure.
+ */
+int apfs_multiblock_verify_csum(char *object, u32 size)
+{
+	struct apfs_obj_phys *obj = (struct apfs_obj_phys *)object;
+	u64 actual_csum, header_csum;
+
+	header_csum = le64_to_cpu(obj->o_cksum);
+	actual_csum = apfs_fletcher64(object + APFS_MAX_CKSUM_SIZE, size - APFS_MAX_CKSUM_SIZE);
+	return header_csum == actual_csum;
 }
 
 /**
  * apfs_obj_set_csum - Set the fletcher checksum in an object header
  * @sb:		superblock structure
  * @obj:	the object header
+ *
+ * The object must have a length of a single block.
  */
 void apfs_obj_set_csum(struct super_block *sb, struct apfs_obj_phys *obj)
 {
-	u64 cksum = apfs_fletcher64((char *)obj + APFS_MAX_CKSUM_SIZE,
-				    sb->s_blocksize - APFS_MAX_CKSUM_SIZE);
+	apfs_multiblock_set_csum((char *)obj, sb->s_blocksize);
+}
+
+/**
+ * apfs_multiblock_set_csum - Set an object's checksum
+ * @object:	the object to checksum
+ * @size:	size of the object in bytes (may be multiple blocks)
+ */
+void apfs_multiblock_set_csum(char *object, u32 size)
+{
+	struct apfs_obj_phys *obj = (struct apfs_obj_phys *)object;
+	u64 cksum;
 
+	cksum = apfs_fletcher64(object + APFS_MAX_CKSUM_SIZE, size - APFS_MAX_CKSUM_SIZE);
 	obj->o_cksum = cpu_to_le64(cksum);
 }
 
 /**
- * apfs_cpm_lookup_oid - Search a checkpoint-mapping block for a given oid
- * @sb:		superblock structure
- * @cpm:	checkpoint-mapping block (on disk)
- * @oid:	the ephemeral object id to look up
- * @bno:	on return, the block number for the object
+ * apfs_create_cpm_block - Create a new checkpoint-mapping block
+ * @sb:		filesystem superblock
+ * @bno:	block number to use
+ * @bh_p:	on return, the buffer head for the block
  *
- * Returns -EFSCORRUPTED in case of corruption, or -EAGAIN if @oid is not
- * listed in @cpm; returns 0 on success.
+ * Returns 0 on success or a negative error code in case of failure.
  */
-static int apfs_cpm_lookup_oid(struct super_block *sb,
-			       struct apfs_checkpoint_map_phys *cpm,
-			       u64 oid, u64 *bno)
+int apfs_create_cpm_block(struct super_block *sb, u64 bno, struct buffer_head **bh_p)
 {
-	u32 map_count = le32_to_cpu(cpm->cpm_count);
-	int i;
+	struct apfs_nxsb_info *nxi = APFS_NXI(sb);
+	struct apfs_checkpoint_map_phys *cpm = NULL;
+	struct buffer_head *bh = NULL;
+	int err;
 
-	if (map_count > apfs_max_maps_per_block(sb)) {
-		apfs_err(sb, "block has too many maps (%d)", map_count);
-		return -EFSCORRUPTED;
+	bh = apfs_getblk(sb, bno);
+	if (!bh) {
+		apfs_err(sb, "failed to map cpm block");
+		return -EIO;
 	}
+	err = apfs_transaction_join(sb, bh);
+	if (err) {
+		brelse(bh);
+		return err;
+	}
+	set_buffer_csum(bh);
 
-	for (i = 0; i < map_count; ++i) {
-		struct apfs_checkpoint_mapping *map = &cpm->cpm_map[i];
+	cpm = (void *)bh->b_data;
+	memset(cpm, 0, sb->s_blocksize);
+	cpm->cpm_o.o_oid = cpu_to_le64(bno);
+	cpm->cpm_o.o_xid = cpu_to_le64(nxi->nx_xid);
+	cpm->cpm_o.o_type = cpu_to_le32(APFS_OBJ_PHYSICAL | APFS_OBJECT_TYPE_CHECKPOINT_MAP);
+	cpm->cpm_o.o_subtype = cpu_to_le32(APFS_OBJECT_TYPE_INVALID);
 
-		if (le64_to_cpu(map->cpm_oid) == oid) {
-			*bno = le64_to_cpu(map->cpm_paddr);
-			return 0;
-		}
-	}
-	return -EAGAIN; /* The mapping may still be in the next block */
-}
+	/* For now: the caller will have to update these fields */
+	cpm->cpm_flags = cpu_to_le32(APFS_CHECKPOINT_MAP_LAST);
+	cpm->cpm_count = 0;
 
-/**
- * apfs_read_cpm_block - Read the checkpoint mapping block
- * @sb:	super block structure
- *
- * Only a single cpm block is supported for now. Returns the buffer head for
- * the block on success, or NULL in case of failure.
- */
-static struct buffer_head *apfs_read_cpm_block(struct super_block *sb)
-{
-	struct apfs_nx_superblock *raw_sb = APFS_NXI(sb)->nx_raw;
-	u64 desc_base = le64_to_cpu(raw_sb->nx_xp_desc_base);
-	u32 desc_index = le32_to_cpu(raw_sb->nx_xp_desc_index);
-	u32 desc_blks = le32_to_cpu(raw_sb->nx_xp_desc_blocks);
-	u32 desc_len = le32_to_cpu(raw_sb->nx_xp_desc_len);
-	u64 cpm_bno;
-
-	if (!desc_blks || desc_len < 2)
-		return NULL;
-
-	/* Last block in area is superblock; we want the last mapping block */
-	cpm_bno = desc_base + (desc_index + desc_len - 2) % desc_blks;
-	return apfs_sb_bread(sb, cpm_bno);
+	*bh_p = bh;
+	return 0;
 }
 
 /**
- * apfs_create_cpoint_map - Create a checkpoint mapping
+ * apfs_create_cpoint_map - Create a checkpoint mapping for an object
  * @sb:		filesystem superblock
- * @oid:	ephemeral object id
- * @bno:	block number
+ * @cpm:	checkpoint mapping block to use
+ * @obj:	header for the ephemeral object
+ * @bno:	block number for the ephemeral object
+ * @size:	size of the ephemeral object in bytes
  *
- * Only mappings for free queue nodes are supported for now.  Returns 0 on
- * success or a negative error code in case of failure.
+ * Returns 0 on success or a negative error code in case of failure, which may
+ * be -ENOSPC if @cpm is full.
  */
-int apfs_create_cpoint_map(struct super_block *sb, u64 oid, u64 bno)
+int apfs_create_cpoint_map(struct super_block *sb, struct apfs_checkpoint_map_phys *cpm, struct apfs_obj_phys *obj, u64 bno, u32 size)
 {
-	struct buffer_head *bh;
-	struct apfs_checkpoint_map_phys *cpm;
-	struct apfs_checkpoint_mapping *map;
+	struct apfs_checkpoint_mapping *map = NULL;
 	u32 cpm_count;
-	int err = 0;
 
-	bh = apfs_read_cpm_block(sb);
-	if (!bh)
-		return -EIO;
-	cpm = (struct apfs_checkpoint_map_phys *)bh->b_data;
 	apfs_assert_in_transaction(sb, &cpm->cpm_o);
 
 	cpm_count = le32_to_cpu(cpm->cpm_count);
-	if (cpm_count >= apfs_max_maps_per_block(sb)) { /* TODO */
-		apfs_warn(sb, "creation of cpm blocks not yet supported");
-		err = -EOPNOTSUPP;
-		goto fail;
-	}
+	if (cpm_count >= apfs_max_maps_per_block(sb))
+		return -ENOSPC;
 	map = &cpm->cpm_map[cpm_count];
 	le32_add_cpu(&cpm->cpm_count, 1);
 
-	map->cpm_type = cpu_to_le32(APFS_OBJ_EPHEMERAL |
-				    APFS_OBJECT_TYPE_BTREE_NODE);
-	map->cpm_subtype = cpu_to_le32(APFS_OBJECT_TYPE_SPACEMAN_FREE_QUEUE);
-	map->cpm_size = cpu_to_le32(sb->s_blocksize);
+	map->cpm_type = obj->o_type;
+	map->cpm_subtype = obj->o_subtype;
+	map->cpm_size = cpu_to_le32(size);
 	map->cpm_pad = 0;
 	map->cpm_fs_oid = 0;
-	map->cpm_oid = cpu_to_le64(oid);
+	map->cpm_oid = obj->o_oid;
 	map->cpm_paddr = cpu_to_le64(bno);
-
-fail:
-	brelse(bh);
-	return err;
+	return 0;
 }
 
 /**
@@ -197,120 +195,23 @@ u64 apfs_data_index_to_bno(struct super_block *sb, u32 index)
 }
 
 /**
- * apfs_remove_cpoint_map - Remove a checkpoint mapping
- * @sb:		filesystem superblock
- * @bno:	block number to delete
- *
- * Only mappings for free queue nodes are supported for now. Blocks that come
- * after the deleted one are assumed to shift back one place. Returns 0 on
- * success or a negative error code in case of failure.
- */
-int apfs_remove_cpoint_map(struct super_block *sb, u64 bno)
-{
-	struct buffer_head *bh;
-	struct apfs_checkpoint_map_phys *cpm;
-	struct apfs_checkpoint_mapping *map, *maps_start, *maps_end;
-	struct apfs_checkpoint_mapping *bno_map = NULL;
-	u32 cpm_count;
-	u32 bno_off;
-	int err = 0;
-
-	bh = apfs_read_cpm_block(sb);
-	if (!bh) {
-		apfs_err(sb, "failed to read cpm block");
-		return -EIO;
-	}
-	cpm = (struct apfs_checkpoint_map_phys *)bh->b_data;
-	apfs_assert_in_transaction(sb, &cpm->cpm_o);
-
-	/* TODO: multiple cpm blocks? */
-	cpm_count = le32_to_cpu(cpm->cpm_count);
-	if (cpm_count > apfs_max_maps_per_block(sb)) {
-		apfs_err(sb, "block has too many maps (%d)", cpm_count);
-		err = -EFSCORRUPTED;
-		goto fail;
-	}
-	maps_start = &cpm->cpm_map[0];
-	maps_end = &cpm->cpm_map[cpm_count];
-
-	bno_off = apfs_index_in_data_area(sb, bno);
-	for (map = maps_start; map < maps_end; ++map) {
-		u32 curr_off;
-
-		if (le64_to_cpu(map->cpm_paddr) == bno)
-			bno_map = map;
-
-		curr_off = apfs_index_in_data_area(sb, le64_to_cpu(map->cpm_paddr));
-		if (curr_off > bno_off)
-			map->cpm_paddr = cpu_to_le64(apfs_data_index_to_bno(sb, curr_off - 1));
-	}
-	if (!bno_map) {
-		apfs_err(sb, "no mapping for bno 0x%llx", bno);
-		err = -EFSCORRUPTED;
-		goto fail;
-	}
-	memmove(bno_map, bno_map + 1, (maps_end - bno_map - 1) * sizeof(*bno_map));
-	le32_add_cpu(&cpm->cpm_count, -1);
-
-fail:
-	brelse(bh);
-	return err;
-}
-
-/**
- * apfs_read_ephemeral_object - Find and map an ephemeral object
+ * apfs_ephemeral_object_lookup - Find an ephemeral object info in memory
  * @sb:		superblock structure
  * @oid:	ephemeral object id
  *
- * Returns the mapped buffer head for the object, or an error pointer in case
+ * Returns a pointer to the object info on success, or an error pointer in case
  * of failure.
  */
-struct buffer_head *apfs_read_ephemeral_object(struct super_block *sb, u64 oid)
+struct apfs_ephemeral_object_info *apfs_ephemeral_object_lookup(struct super_block *sb, u64 oid)
 {
 	struct apfs_nxsb_info *nxi = APFS_NXI(sb);
-	struct apfs_nx_superblock *raw_sb = nxi->nx_raw;
-	u64 desc_base = le64_to_cpu(raw_sb->nx_xp_desc_base);
-	u32 desc_index = le32_to_cpu(raw_sb->nx_xp_desc_index);
-	u32 desc_blks = le32_to_cpu(raw_sb->nx_xp_desc_blocks);
-	u32 desc_len = le32_to_cpu(raw_sb->nx_xp_desc_len);
-	u32 i;
-
-	if (!desc_blks || !desc_len) {
-		apfs_err(sb, "no blocks in checkpoint descriptor area");
-		return ERR_PTR(-EFSCORRUPTED);
-	}
+	struct apfs_ephemeral_object_info *list = NULL;
+	int i;
 
-	/* Last block in the area is superblock; the rest are mapping blocks */
-	for (i = 0; i < desc_len - 1; ++i) {
-		struct buffer_head *bh;
-		struct apfs_checkpoint_map_phys *cpm;
-		u64 cpm_bno = desc_base + (desc_index + i) % desc_blks;
-		u64 obj_bno;
-		int err;
-
-		bh = apfs_sb_bread(sb, cpm_bno);
-		if (!bh) {
-			apfs_err(sb, "failed to read cpm block");
-			return ERR_PTR(-EIO);
-		}
-		cpm = (struct apfs_checkpoint_map_phys *)bh->b_data;
-
-		err = apfs_cpm_lookup_oid(sb, cpm, oid, &obj_bno);
-		brelse(bh);
-		cpm = NULL;
-		if (err == -EAGAIN) /* Search the next mapping block */
-			continue;
-		if (err) {
-			apfs_err(sb, "cpm lookup failed for oid 0x%llx", oid);
-			return ERR_PTR(err);
-		}
-
-		bh = apfs_sb_bread(sb, obj_bno);
-		if (!bh) {
-			apfs_err(sb, "failed to read ephemeral block");
-			return ERR_PTR(-EIO);
-		}
-		return bh;
+	list = nxi->nx_eph_list;
+	for (i = 0; i < nxi->nx_eph_count; ++i) {
+		if (list[i].oid == oid)
+			return &list[i];
 	}
 	apfs_err(sb, "no mapping for oid 0x%llx", oid);
 	return ERR_PTR(-EFSCORRUPTED);
diff --git a/snapshot.c b/snapshot.c
index 61dbbfa..77f83b4 100644
--- a/snapshot.c
+++ b/snapshot.c
@@ -71,7 +71,6 @@ static int apfs_create_snap_metadata_rec(struct inode *mntpoint, struct apfs_nod
 	struct apfs_sb_info *sbi = APFS_SB(sb);
 	struct apfs_superblock *vsb_raw = sbi->s_vsb_raw;
 	struct apfs_query *query = NULL;
-	struct apfs_key key = {0};
 	struct apfs_snap_metadata_key raw_key;
 	struct apfs_snap_metadata_val *raw_val = NULL;
 	int val_len;
@@ -79,14 +78,12 @@ static int apfs_create_snap_metadata_rec(struct inode *mntpoint, struct apfs_nod
 	u64 xid = APFS_NXI(sb)->nx_xid;
 	int err;
 
-	apfs_init_snap_metadata_key(xid, &key);
-
 	query = apfs_alloc_query(snap_root, NULL /* parent */);
 	if (!query) {
 		err = -ENOMEM;
 		goto fail;
 	}
-	query->key = &key;
+	apfs_init_snap_metadata_key(xid, &query->key);
 	query->flags |= APFS_QUERY_SNAP_META | APFS_QUERY_EXACT;
 
 	err = apfs_btree_query(sb, &query);
@@ -137,20 +134,17 @@ static int apfs_create_snap_name_rec(struct apfs_node *snap_root, const char *na
 {
 	struct super_block *sb = snap_root->object.sb;
 	struct apfs_query *query = NULL;
-	struct apfs_key key = {0};
 	struct apfs_snap_name_key *raw_key = NULL;
 	struct apfs_snap_name_val raw_val;
 	int key_len;
 	int err;
 
-	apfs_init_snap_name_key(name, &key);
-
 	query = apfs_alloc_query(snap_root, NULL /* parent */);
 	if (!query) {
 		err = -ENOMEM;
 		goto fail;
 	}
-	query->key = &key;
+	apfs_init_snap_name_key(name, &query->key);
 	query->flags |= APFS_QUERY_SNAP_META | APFS_QUERY_EXACT;
 
 	err = apfs_btree_query(sb, &query);
@@ -246,7 +240,6 @@ static int apfs_update_omap_snap_tree(struct super_block *sb, __le64 *oid_p)
 	struct apfs_nxsb_info *nxi = APFS_NXI(sb);
 	struct apfs_node *root = NULL;
 	u64 oid = le64_to_cpup(oid_p);
-	struct apfs_key key = {0};
 	struct apfs_query *query = NULL;
 	__le64 raw_key;
 	struct apfs_omap_snapshot raw_val = {0};
@@ -268,14 +261,12 @@ static int apfs_update_omap_snap_tree(struct super_block *sb, __le64 *oid_p)
 	}
 	oid = 0;
 
-	apfs_init_omap_snap_key(nxi->nx_xid, &key);
-
 	query = apfs_alloc_query(root, NULL /* parent */);
 	if (!query) {
 		err = -ENOMEM;
 		goto fail;
 	}
-	query->key = &key;
+	apfs_init_omap_snap_key(nxi->nx_xid, &query->key);
 	query->flags = APFS_QUERY_OMAP_SNAP | APFS_QUERY_EXACT;
 
 	err = apfs_btree_query(sb, &query);
@@ -499,15 +490,12 @@ static int apfs_snapshot_name_to_xid(struct apfs_node *snap_root, const char *na
 {
 	struct super_block *sb = snap_root->object.sb;
 	struct apfs_query *query = NULL;
-	struct apfs_key key = {0};
 	int err;
 
-	apfs_init_snap_name_key(name, &key);
-
 	query = apfs_alloc_query(snap_root, NULL /* parent */);
 	if (!query)
 		return -ENOMEM;
-	query->key = &key;
+	apfs_init_snap_name_key(name, &query->key);
 	query->flags |= APFS_QUERY_SNAP_META | APFS_QUERY_EXACT;
 
 	err = apfs_btree_query(sb, &query);
@@ -545,15 +533,12 @@ static int apfs_snapshot_xid_to_sblock(struct apfs_node *snap_root, u64 xid, u64
 {
 	struct super_block *sb = snap_root->object.sb;
 	struct apfs_query *query = NULL;
-	struct apfs_key key = {0};
 	int err;
 
-	apfs_init_snap_metadata_key(xid, &key);
-
 	query = apfs_alloc_query(snap_root, NULL /* parent */);
 	if (!query)
 		return -ENOMEM;
-	query->key = &key;
+	apfs_init_snap_metadata_key(xid, &query->key);
 	query->flags |= APFS_QUERY_SNAP_META | APFS_QUERY_EXACT;
 
 	err = apfs_btree_query(sb, &query);
diff --git a/spaceman.c b/spaceman.c
index 2815907..1ac9f76 100644
--- a/spaceman.c
+++ b/spaceman.c
@@ -5,6 +5,7 @@
 
 #include <linux/buffer_head.h>
 #include <linux/fs.h>
+#include <linux/slab.h>
 #include "apfs.h"
 
 /**
@@ -85,9 +86,9 @@ static int apfs_read_spaceman_dev(struct super_block *sb,
 	spaceman->sm_free_count = le64_to_cpu(dev->sm_free_count);
 	spaceman->sm_addr_offset = le32_to_cpu(dev->sm_addr_offset);
 
-	/* Check that all the cib addresses fit in the spaceman block */
+	/* Check that all the cib addresses fit in the spaceman object */
 	if ((long long)spaceman->sm_addr_offset +
-	    (long long)spaceman->sm_cib_count * sizeof(u64) > sb->s_blocksize) {
+	    (long long)spaceman->sm_cib_count * sizeof(u64) > spaceman->sm_size) {
 		apfs_err(sb, "too many cibs (%u)", spaceman->sm_cib_count);
 		return -EFSCORRUPTED;
 	}
@@ -95,6 +96,25 @@ static int apfs_read_spaceman_dev(struct super_block *sb,
 	return 0;
 }
 
+/**
+ * apfs_spaceman_get_16 - Get a 16-bit value from an offset in the spaceman
+ * @sb:		superblock structure
+ * @off:	offset for the value
+ *
+ * Returns a pointer to the value, or NULL if it doesn't fit.
+ */
+static __le16 *apfs_spaceman_get_16(struct super_block *sb, size_t off)
+{
+	struct apfs_spaceman *spaceman = APFS_SM(sb);
+	struct apfs_spaceman_phys *sm_raw = spaceman->sm_raw;
+
+	if (off > spaceman->sm_size)
+		return NULL;
+	if (off + sizeof(__le16) > spaceman->sm_size)
+		return NULL;
+	return (void *)sm_raw + off;
+}
+
 /**
  * apfs_spaceman_get_64 - Get a 64-bit value from an offset in the spaceman
  * @sb:		superblock structure
@@ -107,9 +127,9 @@ static __le64 *apfs_spaceman_get_64(struct super_block *sb, size_t off)
 	struct apfs_spaceman *spaceman = APFS_SM(sb);
 	struct apfs_spaceman_phys *sm_raw = spaceman->sm_raw;
 
-	if (off > sb->s_blocksize)
+	if (off > spaceman->sm_size)
 		return NULL;
-	if (off + sizeof(__le64) > sb->s_blocksize)
+	if (off + sizeof(__le64) > spaceman->sm_size)
 		return NULL;
 	return (void *)sm_raw + off;
 }
@@ -124,7 +144,7 @@ static bool apfs_ip_bm_is_free(struct apfs_spaceman_phys *sm, u16 index)
 	u16 free_head = le16_to_cpu(sm->sm_ip_bm_free_head);
 	u16 free_tail = le16_to_cpu(sm->sm_ip_bm_free_tail);
 	u16 free_len, index_in_free;
-	u16 bmap_count = 16;
+	u16 bmap_count = le32_to_cpu(sm->sm_ip_bm_block_count);
 
 	free_len = (bmap_count + free_tail - free_head) % bmap_count;
 	index_in_free = (bmap_count + index - free_head) % bmap_count;
@@ -144,15 +164,15 @@ static int apfs_update_ip_bm_free_next(struct super_block *sb)
 	struct apfs_spaceman *spaceman = APFS_SM(sb);
 	struct apfs_spaceman_phys *raw = spaceman->sm_raw;
 	u32 free_next_off = le32_to_cpu(raw->sm_ip_bm_free_next_offset);
-	int bmap_count = 16;
+	int bmap_count = le32_to_cpu(raw->sm_ip_bm_block_count); /* TODO: this can overflow! */
 	__le16 *free_next;
 	int i;
 
-	if (free_next_off > sb->s_blocksize) {
+	if (free_next_off > spaceman->sm_size) {
 		apfs_err(sb, "offset out of bounds (%u)", free_next_off);
 		return -EFSCORRUPTED;
 	}
-	if (free_next_off + bmap_count * sizeof(*free_next) > sb->s_blocksize) {
+	if (free_next_off + bmap_count * sizeof(*free_next) > spaceman->sm_size) {
 		apfs_err(sb, "free next out of bounds (%u-%u)", free_next_off, bmap_count * (u32)sizeof(*free_next));
 		return -EFSCORRUPTED;
 	}
@@ -168,65 +188,61 @@ static int apfs_update_ip_bm_free_next(struct super_block *sb)
 }
 
 /**
- * apfs_rotate_ip_bitmaps - Allocate a new ip bitmap from the circular buffer
- * @sb: superblock structure
+ * apfs_rotate_single_ip_bitmap - Reallocate an ip bmap in the circular buffer
+ * @sb:		filesystem superblock
+ * @idx:	index of the ip bitmap to reallocate
  *
  * Returns 0 on success or a negative error code in case of failure.
  */
-static int apfs_rotate_ip_bitmaps(struct super_block *sb)
+static int apfs_rotate_single_ip_bitmap(struct super_block *sb, u32 idx)
 {
 	struct apfs_nxsb_info *nxi = APFS_NXI(sb);
 	struct apfs_spaceman *spaceman = APFS_SM(sb);
 	struct apfs_spaceman_phys *sm_raw = spaceman->sm_raw;
-	u64 bmap_base = le64_to_cpu(sm_raw->sm_ip_bm_base);
-	u32 bmap_length = le32_to_cpu(sm_raw->sm_ip_bm_block_count);
-	u16 free_head, free_tail;
-	__le64 *curr_bmap_off, *xid;
 	struct buffer_head *old_bh = NULL, *new_bh = NULL;
-	int err = 0;
-
-	apfs_assert_in_transaction(sb, &sm_raw->sm_o);
+	u64 ring_base;
+	u32 ring_length;
+	u32 xid_off, ip_bitmap_off;
+	u64 ip_bitmap_bno;
+	u16 free_head;
+	__le64 *xid_p = NULL;
+	__le16 *ip_bitmap_p = NULL;
+	int err;
 
-	if (le32_to_cpu(sm_raw->sm_ip_bm_size_in_blocks) != 1) {
-		apfs_warn(sb, "Multiblock ip bitmaps not supported");
-		return -EOPNOTSUPP;
-	}
+	ring_base = le64_to_cpu(sm_raw->sm_ip_bm_base);
+	ring_length = le32_to_cpu(sm_raw->sm_ip_bm_block_count);
+	free_head = le16_to_cpu(sm_raw->sm_ip_bm_free_head);
 
-	xid = apfs_spaceman_get_64(sb, le32_to_cpu(sm_raw->sm_ip_bm_xid_offset));
-	if (!xid) {
-		apfs_err(sb, "xid out of bounds (%u)", le32_to_cpu(sm_raw->sm_ip_bm_xid_offset));
+	xid_off = le32_to_cpu(sm_raw->sm_ip_bm_xid_offset) + idx * sizeof(*xid_p);
+	xid_p = apfs_spaceman_get_64(sb, xid_off);
+	if (!xid_p) {
+		apfs_err(sb, "xid out of bounds (%u)", xid_off);
 		return -EFSCORRUPTED;
 	}
-	*xid = cpu_to_le64(nxi->nx_xid);
-
-	free_head = le16_to_cpu(sm_raw->sm_ip_bm_free_head);
-	free_tail = le16_to_cpu(sm_raw->sm_ip_bm_free_tail);
+	*xid_p = cpu_to_le64(nxi->nx_xid);
 
-	curr_bmap_off = apfs_spaceman_get_64(sb, le32_to_cpu(sm_raw->sm_ip_bitmap_offset));
-	if (!curr_bmap_off) {
-		apfs_err(sb, "bmap offset out of bounds (%u)", le32_to_cpu(sm_raw->sm_ip_bitmap_offset));
+	ip_bitmap_off = le32_to_cpu(sm_raw->sm_ip_bitmap_offset) + idx * sizeof(*ip_bitmap_p);
+	ip_bitmap_p = apfs_spaceman_get_16(sb, ip_bitmap_off);
+	if (!ip_bitmap_p) {
+		apfs_err(sb, "bmap offset out of bounds (%u)", ip_bitmap_off);
 		return -EFSCORRUPTED;
 	}
-	old_bh = apfs_sb_bread(sb, bmap_base + le64_to_cpup(curr_bmap_off));
+
+	ip_bitmap_bno = ring_base + le16_to_cpup(ip_bitmap_p);
+	old_bh = apfs_sb_bread(sb, ip_bitmap_bno);
 	if (!old_bh) {
-		apfs_err(sb, "failed to read current ip bitmap (0x%llx)", bmap_base + le64_to_cpup(curr_bmap_off));
+		apfs_err(sb, "failed to read current ip bitmap (0x%llx)", ip_bitmap_bno);
 		return -EIO;
 	}
 
-	*curr_bmap_off = cpu_to_le64(free_head);
-	free_head = (free_head + 1) % bmap_length;
-	free_tail = (free_tail + 1) % bmap_length;
+	*ip_bitmap_p = cpu_to_le16(free_head);
+	free_head = (free_head + 1) % ring_length;
 	sm_raw->sm_ip_bm_free_head = cpu_to_le16(free_head);
-	sm_raw->sm_ip_bm_free_tail = cpu_to_le16(free_tail);
-	err = apfs_update_ip_bm_free_next(sb);
-	if (err) {
-		apfs_err(sb, "failed to update bitmap ring");
-		goto out;
-	}
 
-	new_bh = apfs_getblk(sb, bmap_base + le64_to_cpup(curr_bmap_off));
+	ip_bitmap_bno = ring_base + le16_to_cpup(ip_bitmap_p);
+	new_bh = apfs_getblk(sb, ip_bitmap_bno);
 	if (!new_bh) {
-		apfs_err(sb, "failed to map block for CoW (0x%llx)", bmap_base + le64_to_cpup(curr_bmap_off));
+		apfs_err(sb, "failed to map block for CoW (0x%llx)", ip_bitmap_bno);
 		err = -EIO;
 		goto out;
 	}
@@ -234,7 +250,7 @@ static int apfs_rotate_ip_bitmaps(struct super_block *sb)
 	err = apfs_transaction_join(sb, new_bh);
 	if (err)
 		goto out;
-	spaceman->sm_ip = new_bh;
+	spaceman->sm_ip_bmaps[idx] = new_bh;
 
 out:
 	brelse(old_bh);
@@ -243,6 +259,64 @@ out:
 	return err;
 }
 
+/**
+ * apfs_rotate_ip_bitmaps - Allocate new ip bitmaps from the circular buffer
+ * @sb: superblock structure
+ *
+ * Allocates bitmaps for the whole internal pool at once, meaning that each
+ * transaction is forced to allocate one bitmap for every ~1.32 TiB of container
+ * size, even if they won't be needed. This seems very reasonable to me, but the
+ * official implementation avoids it and they may have a good reason.
+ *
+ * Returns 0 on success or a negative error code in case of failure.
+ */
+static int apfs_rotate_ip_bitmaps(struct super_block *sb)
+{
+	struct apfs_spaceman *spaceman = APFS_SM(sb);
+	struct apfs_spaceman_phys *sm_raw = spaceman->sm_raw;
+	u32 ring_length = le32_to_cpu(sm_raw->sm_ip_bm_block_count);
+	u32 bmaps_count = spaceman->sm_ip_bmaps_count;
+	u16 free_head, free_tail, free_len;
+	int err;
+	u32 i;
+
+	apfs_assert_in_transaction(sb, &sm_raw->sm_o);
+
+	free_head = le16_to_cpu(sm_raw->sm_ip_bm_free_head);
+	free_tail = le16_to_cpu(sm_raw->sm_ip_bm_free_tail);
+
+	/*
+	 * Check that we have enough room before doing anything. If we run out
+	 * I may need to compact the ring using the blocks marked as 0xFFFF in
+	 * ip_bm_free_next (TODO).
+	 */
+	free_len = (ring_length + free_tail - free_head) % ring_length;
+	if (free_len < bmaps_count) {
+		apfs_alert(sb, "full ip bitmap ring (%u < %u)", free_len, bmaps_count);
+		return -ENOSPC;
+	}
+
+	for (i = 0; i < bmaps_count; ++i) {
+		err = apfs_rotate_single_ip_bitmap(sb, i);
+		if (err) {
+			apfs_err(sb, "failed to rotate ip bitmap %u", i);
+			return err;
+		}
+	}
+
+	/* All bitmaps have been reallocated, so just free the same number */
+	free_tail = (free_tail + bmaps_count) % ring_length;
+	sm_raw->sm_ip_bm_free_tail = cpu_to_le16(free_tail);
+
+	err = apfs_update_ip_bm_free_next(sb);
+	if (err) {
+		apfs_err(sb, "failed to update bitmap ring");
+		return err;
+	}
+
+	return 0;
+}
+
 /*
  * Free queue record data
  */
@@ -309,10 +383,11 @@ static int apfs_ip_mark_free(struct super_block *sb, u64 bno)
 {
 	struct apfs_spaceman *sm = APFS_SM(sb);
 	struct apfs_spaceman_phys *sm_raw = sm->sm_raw;
-	char *bitmap = sm->sm_ip->b_data;
+	struct buffer_head *bmap_bh = NULL;
 
 	bno -= le64_to_cpu(sm_raw->sm_ip_base);
-	__clear_bit_le(bno, bitmap);
+	bmap_bh = sm->sm_ip_bmaps[bno >> sm->sm_ip_bmaps_shift];
+	__clear_bit_le(bno & sm->sm_ip_bmaps_mask, bmap_bh->b_data);
 
 	return 0;
 }
@@ -337,15 +412,13 @@ static int apfs_flush_fq_rec(struct apfs_node *root, u64 xid, u64 *len)
 	struct apfs_spaceman *sm = APFS_SM(sb);
 	struct apfs_query *query = NULL;
 	struct apfs_fq_rec fqrec = {0};
-	struct apfs_key key;
 	u64 bno;
 	int err;
 
 	query = apfs_alloc_query(root, NULL /* parent */);
 	if (!query)
 		return -ENOMEM;
-	apfs_init_free_queue_key(xid, 0 /* paddr */, &key);
-	query->key = &key;
+	apfs_init_free_queue_key(xid, 0 /* paddr */, &query->key);
 	query->flags |= APFS_QUERY_FREE_QUEUE | APFS_QUERY_ANY_NUMBER | APFS_QUERY_EXACT;
 
 	err = apfs_btree_query(sb, &query);
@@ -392,9 +465,14 @@ static u64 apfs_free_queue_oldest_xid(struct apfs_node *root)
 	char *raw = root->object.data;
 	int len, off;
 
+	if (root->records == 0)
+		return 0;
 	len = apfs_node_locate_key(root, 0, &off);
-	if (len != sizeof(*key)) /* No records in queue (or corruption) */
+	if (len != sizeof(*key)) {
+		/* TODO: abort transaction */
+		apfs_err(root->object.sb, "bad key length (%d)", len);
 		return 0;
+	}
 	key = (struct apfs_spaceman_free_queue_key *)(raw + off);
 	return le64_to_cpu(key->sfqk_xid);
 }
@@ -403,10 +481,11 @@ static u64 apfs_free_queue_oldest_xid(struct apfs_node *root)
  * apfs_flush_free_queue - Free ip blocks queued by old transactions
  * @sb:		superblock structure
  * @qid:	queue to be freed
+ * @force:	flush as much as possible
  *
  * Returns 0 on success or a negative error code in case of failure.
  */
-static int apfs_flush_free_queue(struct super_block *sb, unsigned int qid)
+static int apfs_flush_free_queue(struct super_block *sb, unsigned int qid, bool force)
 {
 	struct apfs_nxsb_info *nxi = APFS_NXI(sb);
 	struct apfs_spaceman *sm = APFS_SM(sb);
@@ -423,10 +502,21 @@ static int apfs_flush_free_queue(struct super_block *sb, unsigned int qid)
 		return PTR_ERR(fq_root);
 	}
 
-	/* Preserve a few transactions */
-	while (oldest + 4 < nxi->nx_xid) {
+	while (oldest) {
 		u64 sfq_count;
 
+		/*
+		 * Try to preserve one transaction here. I don't really know
+		 * what free queues are for so this is probably silly.
+		 */
+		if (force) {
+			if (oldest == nxi->nx_xid)
+				break;
+		} else {
+			if (oldest + 1 >= nxi->nx_xid)
+				break;
+		}
+
 		while (true) {
 			u64 count = 0;
 
@@ -445,6 +535,9 @@ static int apfs_flush_free_queue(struct super_block *sb, unsigned int qid)
 		oldest = apfs_free_queue_oldest_xid(fq_root);
 		fq->sfq_oldest_xid = cpu_to_le64(oldest);
 
+		if (force)
+			continue;
+
 		/*
 		 * Flushing a single transaction may not be enough to avoid
 		 * running out of space in the ip, but it's probably best not
@@ -459,13 +552,47 @@ static int apfs_flush_free_queue(struct super_block *sb, unsigned int qid)
 			break;
 	}
 
-	set_buffer_csum(sm->sm_bh);
-
 fail:
 	apfs_node_free(fq_root);
 	return err;
 }
 
+/**
+ * apfs_allocate_spaceman - Allocate an in-memory spaceman struct, if needed
+ * @sb:		superblock structure
+ * @bmap_cnt:	internal pool bitmap count
+ *
+ * Returns the spaceman and sets it in the superblock info. Also sets the fixed
+ * information about the ip bitmap count. On failure, returns an error pointer.
+ */
+static struct apfs_spaceman *apfs_allocate_spaceman(struct super_block *sb, u32 bmap_cnt)
+{
+	struct apfs_nxsb_info *nxi = APFS_NXI(sb);
+	struct apfs_spaceman *spaceman = NULL;
+	int blk_bitcnt = sb->s_blocksize * 8;
+	size_t sm_size;
+
+	if (nxi->nx_spaceman)
+		return nxi->nx_spaceman;
+
+	/* We don't expect filesystems this big, it would be like 260 TiB */
+	if (bmap_cnt > 200) {
+		apfs_err(sb, "too many ip bitmap blocks (%u)", bmap_cnt);
+		return ERR_PTR(-EFSCORRUPTED);
+	}
+	sm_size = sizeof(*spaceman) + bmap_cnt * sizeof(spaceman->sm_ip_bmaps[0]);
+
+	spaceman = nxi->nx_spaceman = kzalloc(sm_size, GFP_KERNEL);
+	if (!spaceman)
+		return ERR_PTR(-ENOMEM);
+	spaceman->sm_nxi = nxi;
+
+	spaceman->sm_ip_bmaps_count = bmap_cnt;
+	spaceman->sm_ip_bmaps_mask = blk_bitcnt - 1;
+	spaceman->sm_ip_bmaps_shift = order_base_2(blk_bitcnt);
+	return spaceman;
+}
+
 /**
  * apfs_read_spaceman - Find and read the space manager
  * @sb: superblock structure
@@ -478,8 +605,8 @@ int apfs_read_spaceman(struct super_block *sb)
 {
 	struct apfs_nxsb_info *nxi = APFS_NXI(sb);
 	struct apfs_nx_superblock *raw_sb = nxi->nx_raw;
-	struct apfs_spaceman *spaceman = APFS_SM(sb);
-	struct buffer_head *sm_bh;
+	struct apfs_spaceman *spaceman = NULL;
+	struct apfs_ephemeral_object_info *sm_eph_info = NULL;
 	struct apfs_spaceman_phys *sm_raw;
 	u32 sm_flags;
 	u64 oid = le64_to_cpu(raw_sb->nx_spaceman_oid);
@@ -488,14 +615,24 @@ int apfs_read_spaceman(struct super_block *sb)
 	if (sb->s_flags & SB_RDONLY) /* The space manager won't be needed */
 		return 0;
 
-	spaceman->sm_free_cache_base = spaceman->sm_free_cache_blkcnt = 0;
+	sm_eph_info = apfs_ephemeral_object_lookup(sb, oid);
+	if (IS_ERR(sm_eph_info)) {
+		apfs_err(sb, "no spaceman object for oid 0x%llx", oid);
+		return PTR_ERR(sm_eph_info);
+	}
+	sm_raw = (struct apfs_spaceman_phys *)sm_eph_info->object;
+	sm_raw->sm_o.o_xid = cpu_to_le64(nxi->nx_xid);
 
-	sm_bh = apfs_read_ephemeral_object(sb, oid);
-	if (IS_ERR(sm_bh)) {
-		apfs_err(sb, "ephemeral read failed for oid 0x%llx", oid);
-		return PTR_ERR(sm_bh);
+	spaceman = apfs_allocate_spaceman(sb, le32_to_cpu(sm_raw->sm_ip_bm_size_in_blocks));
+	if (IS_ERR(spaceman)) {
+		apfs_err(sb, "failed to allocate spaceman");
+		err = PTR_ERR(spaceman);
+		goto fail;
 	}
-	sm_raw = (struct apfs_spaceman_phys *)sm_bh->b_data;
+	spaceman->sm_raw = sm_raw;
+	spaceman->sm_size = sm_eph_info->size;
+
+	spaceman->sm_free_cache_base = spaceman->sm_free_cache_blkcnt = 0;
 
 	sm_flags = le32_to_cpu(sm_raw->sm_flags);
 	/* Undocumented feature, but it's too common to refuse to mount */
@@ -518,19 +655,17 @@ int apfs_read_spaceman(struct super_block *sb)
 		goto fail;
 	}
 
-	spaceman->sm_bh = sm_bh;
-	spaceman->sm_raw = sm_raw;
 	err = apfs_rotate_ip_bitmaps(sb);
 	if (err) {
 		apfs_err(sb, "failed to rotate ip bitmaps");
 		goto fail;
 	}
-	err = apfs_flush_free_queue(sb, APFS_SFQ_IP);
+	err = apfs_flush_free_queue(sb, APFS_SFQ_IP, false /* force */);
 	if (err) {
 		apfs_err(sb, "failed to flush ip fq");
 		goto fail;
 	}
-	err = apfs_flush_free_queue(sb, APFS_SFQ_MAIN);
+	err = apfs_flush_free_queue(sb, APFS_SFQ_MAIN, false /* force */);
 	if (err) {
 		apfs_err(sb, "failed to flush main fq");
 		goto fail;
@@ -538,8 +673,6 @@ int apfs_read_spaceman(struct super_block *sb)
 	return 0;
 
 fail:
-	brelse(sm_bh);
-	spaceman->sm_bh = sm_bh = NULL;
 	spaceman->sm_raw = NULL;
 	return err;
 }
@@ -557,7 +690,7 @@ static void apfs_write_spaceman(struct apfs_spaceman *sm)
 	struct apfs_spaceman_device *dev_raw = &sm_raw->sm_dev[APFS_SD_MAIN];
 	struct apfs_nxsb_info *nxi;
 
-	nxi = container_of(sm, struct apfs_nxsb_info, nx_spaceman);
+	nxi = sm->sm_nxi;
 	ASSERT(le64_to_cpu(sm_raw->sm_o.o_xid) == nxi->nx_xid);
 
 	dev_raw->sm_free_count = cpu_to_le64(sm->sm_free_count);
@@ -573,18 +706,26 @@ static u64 apfs_ip_find_free(struct super_block *sb)
 {
 	struct apfs_spaceman *sm = APFS_SM(sb);
 	struct apfs_spaceman_phys *sm_raw = sm->sm_raw;
-	u64 bitcount = le64_to_cpu(sm_raw->sm_ip_block_count);
-	char *bitmap = sm->sm_ip->b_data;
-	u64 offset;
+	int blk_bitcnt = sb->s_blocksize * 8;
+	u64 full_bitcnt = le64_to_cpu(sm_raw->sm_ip_block_count);
+	u32 i;
 
-	if (bitcount > sb->s_blocksize * 8)
-		return 0;
-	offset = find_next_zero_bit_le(bitmap, bitcount, 0 /* offset */);
-	if (offset >= bitcount) {
-		apfs_warn(sb, "internal pool seems full");
-		return 0;
+	for (i = 0; i < sm->sm_ip_bmaps_count; ++i) {
+		char *bitmap = sm->sm_ip_bmaps[i]->b_data;
+		u64 off_in_bmap_blk, off_in_ip;
+
+		off_in_bmap_blk = find_next_zero_bit_le(bitmap, blk_bitcnt, 0 /* offset */);
+		if (off_in_bmap_blk >= blk_bitcnt) /* No space in this chunk */
+			continue;
+
+		/* We found something, confirm that it's not outside the ip */
+		off_in_ip = (i << sm->sm_ip_bmaps_shift) + off_in_bmap_blk;
+		if (off_in_ip >= full_bitcnt)
+			break;
+		return le64_to_cpu(sm_raw->sm_ip_base) + off_in_ip;
 	}
-	return le64_to_cpu(sm_raw->sm_ip_base) + offset;
+	apfs_err(sb, "internal pool seems full");
+	return 0;
 }
 
 /**
@@ -615,10 +756,11 @@ static void apfs_ip_mark_used(struct super_block *sb, u64 bno)
 {
 	struct apfs_spaceman *sm = APFS_SM(sb);
 	struct apfs_spaceman_phys *sm_raw = sm->sm_raw;
-	char *bitmap = sm->sm_ip->b_data;
+	struct buffer_head *bmap_bh = NULL;
 
 	bno -= le64_to_cpu(sm_raw->sm_ip_base);
-	__set_bit_le(bno, bitmap);
+	bmap_bh = sm->sm_ip_bmaps[bno >> sm->sm_ip_bmaps_shift];
+	__set_bit_le(bno & sm->sm_ip_bmaps_mask, bmap_bh->b_data);
 }
 
 /**
@@ -650,17 +792,16 @@ static inline int apfs_chunk_mark_free(struct super_block *sb, char *bitmap,
 }
 
 /**
- * apfs_free_queue_insert_nocache - Add a block range to its free queue
+ * apfs_free_queue_try_insert - Try to add a block range to its free queue
  * @sb:		superblock structure
  * @bno:	first block number to free
  * @count:	number of consecutive blocks to free
  *
- * Same as apfs_free_queue_insert(), but writes to the free queue directly,
- * bypassing the cache of the latest freed block range.
- *
- * Returns 0 on success or a negative error code in case of failure.
+ * Same as apfs_free_queue_insert_nocache(), except that this one can also fail
+ * with -EAGAIN if there is no room for the new record, so that the caller can
+ * flush the queue and retry.
  */
-int apfs_free_queue_insert_nocache(struct super_block *sb, u64 bno, u64 count)
+static int apfs_free_queue_try_insert(struct super_block *sb, u64 bno, u64 count)
 {
 	struct apfs_nxsb_info *nxi = APFS_NXI(sb);
 	struct apfs_spaceman *sm = APFS_SM(sb);
@@ -670,8 +811,9 @@ int apfs_free_queue_insert_nocache(struct super_block *sb, u64 bno, u64 count)
 	struct apfs_btree_info *fq_info = NULL;
 	struct apfs_query *query = NULL;
 	struct apfs_spaceman_free_queue_key raw_key;
+	bool ghost = count == 1;
+	int needed_room;
 	__le64 raw_val;
-	struct apfs_key key;
 	u64 node_count;
 	u16 node_limit;
 	int err;
@@ -693,9 +835,7 @@ int apfs_free_queue_insert_nocache(struct super_block *sb, u64 bno, u64 count)
 		err = -ENOMEM;
 		goto fail;
 	}
-
-	apfs_init_free_queue_key(nxi->nx_xid, bno, &key);
-	query->key = &key;
+	apfs_init_free_queue_key(nxi->nx_xid, bno, &query->key);
 	query->flags |= APFS_QUERY_FREE_QUEUE;
 
 	err = apfs_btree_query(sb, &query);
@@ -704,9 +844,20 @@ int apfs_free_queue_insert_nocache(struct super_block *sb, u64 bno, u64 count)
 		goto fail;
 	}
 
+	fq_info = (void *)fq_root->object.data + sb->s_blocksize - sizeof(*fq_info);
+	node_count = le64_to_cpu(fq_info->bt_node_count);
+	node_limit = le16_to_cpu(fq->sfq_tree_node_limit);
+	if (node_count == node_limit) {
+		needed_room = sizeof(raw_key) + (ghost ? 0 : sizeof(raw_val));
+		if (!apfs_node_has_room(query->node, needed_room, false /* replace */)) {
+			err = -EAGAIN;
+			goto fail;
+		}
+	}
+
 	raw_key.sfqk_xid = cpu_to_le64(nxi->nx_xid);
 	raw_key.sfqk_paddr = cpu_to_le64(bno);
-	if (count == 1) {
+	if (ghost) {
 		/* A lack of value (ghost record) means single-block extent */
 		err = apfs_btree_insert(query, &raw_key, sizeof(raw_key), NULL /* val */, 0 /* val_len */);
 	} else {
@@ -718,24 +869,9 @@ int apfs_free_queue_insert_nocache(struct super_block *sb, u64 bno, u64 count)
 		goto fail;
 	}
 
-	fq_info = (void *)fq_root->object.data + sb->s_blocksize - sizeof(*fq_info);
-	node_count = le64_to_cpu(fq_info->bt_node_count);
-	node_limit = le16_to_cpu(fq->sfq_tree_node_limit);
-	if (node_count > node_limit) {
-		/*
-		 * Ideally this should never happen, but at this point I can't
-		 * be certain of that (TODO). If it does happen, it's best to
-		 * abort and avoid corruption.
-		 */
-		apfs_alert(sb, "free queue has too many nodes (%llu > %u)", node_count, node_limit);
-		err = -EFSCORRUPTED;
-		goto fail;
-	}
-
 	if (!fq->sfq_oldest_xid)
 		fq->sfq_oldest_xid = cpu_to_le64(nxi->nx_xid);
 	le64_add_cpu(&fq->sfq_count, count);
-	set_buffer_csum(sm->sm_bh);
 
 fail:
 	apfs_free_query(query);
@@ -743,6 +879,44 @@ fail:
 	return err;
 }
 
+/**
+ * apfs_free_queue_insert_nocache - Add a block range to its free queue
+ * @sb:		superblock structure
+ * @bno:	first block number to free
+ * @count:	number of consecutive blocks to free
+ *
+ * Same as apfs_free_queue_insert(), but writes to the free queue directly,
+ * bypassing the cache of the latest freed block range.
+ *
+ * Returns 0 on success or a negative error code in case of failure.
+ */
+int apfs_free_queue_insert_nocache(struct super_block *sb, u64 bno, u64 count)
+{
+	struct apfs_spaceman *sm = APFS_SM(sb);
+	unsigned int qid;
+	int err;
+
+	err = apfs_free_queue_try_insert(sb, bno, count);
+	if (err == -EAGAIN) {
+		qid = apfs_block_in_ip(sm, bno) ? APFS_SFQ_IP : APFS_SFQ_MAIN;
+		err = apfs_flush_free_queue(sb, qid, true /* force */);
+		if (err) {
+			apfs_err(sb, "failed to flush fq to make room");
+			return err;
+		}
+		err = apfs_free_queue_try_insert(sb, bno, count);
+	}
+	if (err) {
+		if (err == -EAGAIN) {
+			apfs_alert(sb, "failed to make room in fq - bug!");
+			err = -EFSCORRUPTED;
+		}
+		apfs_err(sb, "fq insert failed (0x%llx-0x%llx)", bno, count);
+		return err;
+	}
+	return 0;
+}
+
 /**
  * apfs_free_queue_insert - Add a block range to its free queue
  * @sb:		superblock structure
@@ -1060,7 +1234,6 @@ int apfs_spaceman_allocate_block(struct super_block *sb, u64 *bno, bool backward
 			apfs_spaceman_write_cib_addr(sb, index, cib_bh->b_blocknr);
 			/* The free block count has changed */
 			apfs_write_spaceman(sm);
-			set_buffer_csum(sm->sm_bh);
 		}
 		brelse(cib_bh);
 		if (err == -ENOSPC) /* This cib is full */
@@ -1123,7 +1296,6 @@ static int apfs_main_free(struct super_block *sb, u64 bno)
 		apfs_spaceman_write_cib_addr(sb, cib_idx, cib_bh->b_blocknr);
 		/* The free block count has changed */
 		apfs_write_spaceman(sm);
-		set_buffer_csum(sm->sm_bh);
 	}
 	brelse(cib_bh);
 	if (err)
diff --git a/super.c b/super.c
index 61b2941..381fe5e 100644
--- a/super.c
+++ b/super.c
@@ -14,6 +14,9 @@
 #include <linux/statfs.h>
 #include <linux/seq_file.h>
 #include "apfs.h"
+#include "version.h"
+
+#define APFS_MODULE_ID_STRING	"linux-apfs by eafer (" GIT_COMMIT ")"
 
 #if LINUX_VERSION_CODE >= KERNEL_VERSION(4, 16, 0) /* iversion came in 4.16 */
 #include <linux/iversion.h>
@@ -110,11 +113,8 @@ static struct buffer_head *apfs_read_super_copy(struct super_block *sb)
 		apfs_err(sb, "not an apfs filesystem");
 		goto fail;
 	}
-	if (!apfs_obj_verify_csum(sb, bh)) {
-		apfs_err(sb, "inconsistent container superblock");
-		err = -EFSBADCRC;
-		goto fail;
-	}
+	if (!apfs_obj_verify_csum(sb, bh))
+		apfs_notice(sb, "backup superblock seems corrupted");
 	return bh;
 
 fail:
@@ -152,14 +152,16 @@ out_unlock:
 	mutex_unlock(&nxs_mutex);
 }
 
+static int apfs_check_nx_features(struct super_block *sb);
+
 /**
- * apfs_map_main_super - Find the container superblock and map it into memory
+ * apfs_read_main_super - Find the container superblock and read it into memory
  * @sb:	superblock structure
  *
  * Returns a negative error code in case of failure.  On success, returns 0
- * and sets the nx_raw, nx_object and nx_xid fields of APFS_NXI(@sb).
+ * and sets the nx_raw and nx_xid fields of APFS_NXI(@sb).
  */
-static int apfs_map_main_super(struct super_block *sb)
+static int apfs_read_main_super(struct super_block *sb)
 {
 	struct apfs_nxsb_info *nxi = APFS_NXI(sb);
 	struct buffer_head *bh;
@@ -228,20 +230,20 @@ static int apfs_map_main_super(struct super_block *sb)
 		desc_bh = NULL;
 	}
 
+	nxi->nx_raw = kmalloc(sb->s_blocksize, GFP_KERNEL);
+	if (!nxi->nx_raw) {
+		err = -ENOMEM;
+		goto fail;
+	}
+	memcpy(nxi->nx_raw, bh->b_data, sb->s_blocksize);
+	nxi->nx_bno = bno;
 	nxi->nx_xid = xid;
-	nxi->nx_raw = msb_raw;
-	nxi->nx_object.sb = sb; /* XXX: these "objects" never made any sense */
-	nxi->nx_object.block_nr = bno;
-	nxi->nx_object.oid = le64_to_cpu(msb_raw->nx_o.o_oid);
-	nxi->nx_object.o_bh = bh;
-	nxi->nx_object.data = bh->b_data;
 
 	/* For now we only support blocksize < PAGE_SIZE */
 	nxi->nx_blocksize = sb->s_blocksize;
 	nxi->nx_blocksize_bits = sb->s_blocksize_bits;
 
-	return 0;
-
+	err = apfs_check_nx_features(sb);
 fail:
 	brelse(bh);
 	return err;
@@ -251,9 +253,8 @@ fail:
  * apfs_update_software_info - Write the module info to a modified volume
  * @sb: superblock structure
  *
- * Does nothing if the module information is already present at index zero of
- * the apfs_modified_by array.  Otherwise, writes it there after shifting the
- * rest of the entries to the right.
+ * Writes this module's information to index zero of the apfs_modified_by
+ * array, shifting the rest of the entries to the right.
  */
 static void apfs_update_software_info(struct super_block *sb)
 {
@@ -266,11 +267,7 @@ static void apfs_update_software_info(struct super_block *sb)
 	ASSERT(strlen(APFS_MODULE_ID_STRING) < APFS_MODIFIED_NAMELEN);
 	mod_by = raw->apfs_modified_by;
 
-	/* This check could be optimized away, but does it matter? */
-	if (!strcmp(mod_by->id, APFS_MODULE_ID_STRING))
-		return;
 	memmove(mod_by + 1, mod_by, (APFS_MAX_HIST - 1) * sizeof(*mod_by));
-
 	memset(mod_by->id, 0, sizeof(mod_by->id));
 	strscpy(mod_by->id, APFS_MODULE_ID_STRING, sizeof(mod_by->id));
 	mod_by->timestamp = cpu_to_le64(ktime_get_real_ns());
@@ -280,18 +277,19 @@ static void apfs_update_software_info(struct super_block *sb)
 static struct file_system_type apfs_fs_type;
 
 /**
- * apfs_unmap_main_super - Clean up apfs_map_main_super()
+ * apfs_free_main_super - Clean up apfs_read_main_super()
  * @sbi:	in-memory superblock info
  *
  * It also cleans up after apfs_attach_nxi(), so the name is no longer accurate.
  */
-static inline void apfs_unmap_main_super(struct apfs_sb_info *sbi)
+static inline void apfs_free_main_super(struct apfs_sb_info *sbi)
 {
 	struct apfs_nxsb_info *nxi = sbi->s_nxi;
 #if LINUX_VERSION_CODE < KERNEL_VERSION(6, 5, 0)
 	fmode_t mode = FMODE_READ | FMODE_EXCL;
 #endif
-	struct apfs_object *obj = NULL;
+	struct apfs_ephemeral_object_info *eph_list = NULL;
+	int i;
 
 #if LINUX_VERSION_CODE < KERNEL_VERSION(6, 5, 0)
 	if (nxi->nx_flags & APFS_READWRITE)
@@ -304,19 +302,34 @@ static inline void apfs_unmap_main_super(struct apfs_sb_info *sbi)
 	if (--nxi->nx_refcnt)
 		goto out;
 
-	obj = &nxi->nx_object;
-	obj->data = NULL;
-	brelse(obj->o_bh);
-	obj->o_bh = NULL;
-	obj = NULL;
+	/* Clean up all the ephemeral objects in memory */
+	eph_list = nxi->nx_eph_list;
+	if (eph_list) {
+		for (i = 0; i < nxi->nx_eph_count; ++i) {
+			kfree(eph_list[i].object);
+			eph_list[i].object = NULL;
+		}
+		kfree(eph_list);
+		eph_list = nxi->nx_eph_list = NULL;
+		nxi->nx_eph_count = 0;
+	}
 
-#if LINUX_VERSION_CODE >= KERNEL_VERSION(6, 5, 0)
+	kfree(nxi->nx_raw);
+	nxi->nx_raw = NULL;
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(6, 9, 0)
+	fput(nxi->nx_bdev_file);
+#elif LINUX_VERSION_CODE >= KERNEL_VERSION(6, 8, 0)
+	bdev_release(nxi->nx_bdev_handle);
+#elif LINUX_VERSION_CODE >= KERNEL_VERSION(6, 5, 0)
 	blkdev_put(nxi->nx_bdev, &apfs_fs_type);
 #else
 	blkdev_put(nxi->nx_bdev, mode);
 #endif
 
 	list_del(&nxi->nx_list);
+	kfree(nxi->nx_spaceman);
+	nxi->nx_spaceman = NULL;
 	kfree(nxi);
 out:
 	sbi->s_nxi = NULL;
@@ -459,13 +472,7 @@ int apfs_map_volume_super(struct super_block *sb, bool write)
 	 * Snapshots could get mounted during a transaction, so the fletcher
 	 * checksum doesn't have to be valid.
 	 */
-	err = apfs_map_volume_super_bno(sb, vsb, !write && !sbi->s_snap_name);
-	if (err)
-		return err;
-
-	if (write)
-		apfs_update_software_info(sb);
-	return 0;
+	return apfs_map_volume_super_bno(sb, vsb, !write && !sbi->s_snap_name);
 
 fail:
 	brelse(bh);
@@ -670,7 +677,10 @@ static void apfs_put_super(struct super_block *sb)
 {
 	struct apfs_sb_info *sbi = APFS_SB(sb);
 
-	/* Update the volume's unmount time */
+	/* Cleanups won't reschedule themselves during unmount */
+	flush_work(&sbi->s_orphan_cleanup_work);
+
+	/* Stop flushing orphans and update the volume as needed */
 	if (!(sb->s_flags & SB_RDONLY)) {
 		struct apfs_superblock *vsb_raw;
 		struct buffer_head *vsb_bh;
@@ -684,6 +694,7 @@ static void apfs_put_super(struct super_block *sb)
 		apfs_assert_in_transaction(sb, &vsb_raw->apfs_o);
 		ASSERT(buffer_trans(vsb_bh));
 
+		apfs_update_software_info(sb);
 		vsb_raw->apfs_unmount_time = cpu_to_le64(ktime_get_real_ns());
 		set_buffer_csum(vsb_bh);
 
@@ -711,7 +722,7 @@ fail:
 	mutex_lock(&nxs_mutex);
 	apfs_put_omap(sbi->s_omap);
 	sbi->s_omap = NULL;
-	apfs_unmap_main_super(sbi);
+	apfs_free_main_super(sbi);
 	mutex_unlock(&nxs_mutex);
 
 	sb->s_fs_info = NULL;
@@ -749,6 +760,7 @@ static struct inode *apfs_alloc_inode(struct super_block *sb)
 	dstream->ds_ext_dirty = false;
 	ai->i_nchildren = 0;
 	INIT_LIST_HEAD(&ai->i_list);
+	ai->i_cleaned = false;
 	return &ai->vfs_inode;
 }
 
@@ -773,6 +785,10 @@ static void init_once(void *p)
 	inode_init_once(&ai->vfs_inode);
 }
 
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(6, 9, 0)
+#define SLAB_MEM_SPREAD	0
+#endif
+
 static int __init init_inodecache(void)
 {
 	apfs_inode_cachep = kmem_cache_create("apfs_inode_cache",
@@ -879,10 +895,11 @@ static int apfs_count_used_blocks(struct super_block *sb, u64 *count)
 		vol_id = le64_to_cpu(msb_raw->nx_fs_oid[i]);
 		if (vol_id == 0) /* All volumes have been checked */
 			break;
-		err = apfs_omap_lookup_block(sb, omap, vol_id, &vol_bno,
-					     false /* write */);
-		if (err)
+		err = apfs_omap_lookup_newest_block(sb, omap, vol_id, &vol_bno, false /* write */);
+		if (err) {
+			apfs_err(sb, "omap lookup failed for vol id 0x%llx", vol_id);
 			break;
+		}
 
 		bh = apfs_sb_bread(sb, vol_bno);
 		if (!bh) {
@@ -958,6 +975,8 @@ static int apfs_show_options(struct seq_file *seq, struct dentry *root)
 
 	if (sbi->s_vol_nr != 0)
 		seq_printf(seq, ",vol=%u", sbi->s_vol_nr);
+	if (sbi->s_snap_name)
+		seq_printf(seq, ",snap=%s", sbi->s_snap_name);
 	if (uid_valid(sbi->s_uid))
 		seq_printf(seq, ",uid=%u", from_kuid(&init_user_ns,
 						     sbi->s_uid));
@@ -1190,34 +1209,39 @@ static int parse_options(struct super_block *sb, char *options)
 
 out:
 	apfs_set_nx_flags(sb, nx_flags);
-	if ((nxi->nx_flags & APFS_READWRITE) && !(sb->s_flags & SB_RDONLY))
-		apfs_notice(sb, "experimental write support is enabled");
-	else
-		sb->s_flags |= SB_RDONLY;
+	if (!(sb->s_flags & SB_RDONLY)) {
+		if (nxi->nx_flags & APFS_READWRITE) {
+			apfs_notice(sb, "experimental write support is enabled");
+		} else {
+			apfs_warn(sb, "experimental writes disabled to avoid data loss");
+			apfs_warn(sb, "if you really want them, check the README");
+			sb->s_flags |= SB_RDONLY;
+		}
+	}
 	return 0;
 }
 
 /**
- * apfs_check_features - Check for unsupported features in the filesystem
+ * apfs_check_nx_features - Check for unsupported features in the container
  * @sb: superblock structure
  *
  * Returns -EINVAL if unsupported incompatible features are found, otherwise
  * returns 0.
  */
-static int apfs_check_features(struct super_block *sb)
+static int apfs_check_nx_features(struct super_block *sb)
 {
-	struct apfs_nx_superblock *msb_raw = APFS_NXI(sb)->nx_raw;
-	struct apfs_superblock *vsb_raw = APFS_SB(sb)->s_vsb_raw;
+	struct apfs_nx_superblock *msb_raw = NULL;
 	u64 features;
 
-	ASSERT(msb_raw);
-	ASSERT(vsb_raw);
+	msb_raw = APFS_NXI(sb)->nx_raw;
+	if (!msb_raw) {
+		apfs_alert(sb, "feature checks are misplaced");
+		return -EINVAL;
+	}
 
 	features = le64_to_cpu(msb_raw->nx_incompatible_features);
 	if (features & ~APFS_NX_SUPPORTED_INCOMPAT_MASK) {
-		apfs_warn(sb,
-			  "unknown incompatible container features (0x%llx)",
-			  features);
+		apfs_warn(sb, "unknown incompatible container features (0x%llx)", features);
 		return -EINVAL;
 	}
 	if (features & APFS_NX_INCOMPAT_FUSION) {
@@ -1225,10 +1249,38 @@ static int apfs_check_features(struct super_block *sb)
 		return -EINVAL;
 	}
 
+	features = le64_to_cpu(msb_raw->nx_readonly_compatible_features);
+	if (features & ~APFS_NX_SUPPORTED_ROCOMPAT_MASK) {
+		apfs_warn(sb, "unknown read-only compatible container features (0x%llx)", features);
+		if (!sb_rdonly(sb)) {
+			apfs_warn(sb, "container can't be mounted read-write");
+			return -EINVAL;
+		}
+	}
+	return 0;
+}
+
+/**
+ * apfs_check_vol_features - Check for unsupported features in the volume
+ * @sb: superblock structure
+ *
+ * Returns -EINVAL if unsupported incompatible features are found, otherwise
+ * returns 0.
+ */
+static int apfs_check_vol_features(struct super_block *sb)
+{
+	struct apfs_superblock *vsb_raw = NULL;
+	u64 features;
+
+	vsb_raw = APFS_SB(sb)->s_vsb_raw;
+	if (!vsb_raw) {
+		apfs_alert(sb, "feature checks are misplaced");
+		return -EINVAL;
+	}
+
 	features = le64_to_cpu(vsb_raw->apfs_incompatible_features);
 	if (features & ~APFS_SUPPORTED_INCOMPAT_MASK) {
-		apfs_warn(sb, "unknown incompatible volume features (0x%llx)",
-			  features);
+		apfs_warn(sb, "unknown incompatible volume features (0x%llx)", features);
 		return -EINVAL;
 	}
 	if (features & APFS_INCOMPAT_DATALESS_SNAPS) {
@@ -1260,29 +1312,14 @@ static int apfs_check_features(struct super_block *sb)
 	if (!(features & APFS_FS_UNENCRYPTED))
 		apfs_warn(sb, "volume is encrypted, may not be read correctly");
 
-	features = le64_to_cpu(msb_raw->nx_readonly_compatible_features);
-	if (features & ~APFS_NX_SUPPORTED_ROCOMPAT_MASK) {
-		apfs_warn(sb,
-		     "unknown read-only compatible container features (0x%llx)",
-		     features);
-		if (!sb_rdonly(sb)) {
-			apfs_warn(sb, "container can't be mounted read-write");
-			return -EINVAL;
-		}
-	}
-
 	features = le64_to_cpu(vsb_raw->apfs_readonly_compatible_features);
 	if (features & ~APFS_SUPPORTED_ROCOMPAT_MASK) {
-		apfs_warn(sb,
-			"unknown read-only compatible volume features (0x%llx)",
-			features);
+		apfs_warn(sb, "unknown read-only compatible volume features (0x%llx)", features);
 		if (!sb_rdonly(sb)) {
 			apfs_warn(sb, "volume can't be mounted read-write");
 			return -EINVAL;
 		}
 	}
-
-	/* TODO: add checks for encryption, snapshots? */
 	return 0;
 }
 
@@ -1358,7 +1395,7 @@ static void apfs_set_trans_buffer_limit(struct super_block *sb)
 static int apfs_fill_super(struct super_block *sb, void *data, int silent)
 {
 	struct apfs_sb_info *sbi = APFS_SB(sb);
-	struct inode *root;
+	struct inode *root = NULL, *priv = NULL;
 	int err;
 
 	ASSERT(sbi);
@@ -1380,7 +1417,7 @@ static int apfs_fill_super(struct super_block *sb, void *data, int silent)
 	if (err)
 		return err;
 
-	err = apfs_check_features(sb);
+	err = apfs_check_vol_features(sb);
 	if (err)
 		goto failed_omap;
 
@@ -1422,12 +1459,20 @@ static int apfs_fill_super(struct super_block *sb, void *data, int silent)
 		err = PTR_ERR(root);
 		goto failed_mount;
 	}
+
 	sb->s_root = d_make_root(root);
 	if (!sb->s_root) {
 		apfs_err(sb, "unable to get root dentry");
 		err = -ENOMEM;
 		goto failed_mount;
 	}
+
+	INIT_WORK(&sbi->s_orphan_cleanup_work, apfs_orphan_cleanup_work);
+	if (!(sb->s_flags & SB_RDONLY)) {
+		priv = sbi->s_private_dir;
+		if (APFS_I(priv)->i_nchildren)
+			schedule_work(&sbi->s_orphan_cleanup_work);
+	}
 	return 0;
 
 failed_mount:
@@ -1475,17 +1520,34 @@ static int apfs_test_super(struct super_block *sb, void *data)
 }
 
 /**
- * apfs_set_super - Assign a fake bdev and an info struct to a superblock
+ * apfs_set_super - Assign the device and an info struct to a superblock
  * @sb:		superblock structure to set
  * @data:	superblock info for the volume being mounted
  */
 static int apfs_set_super(struct super_block *sb, void *data)
 {
-	int err = set_anon_super(sb, data);
+	struct apfs_sb_info *sbi = data;
+	struct apfs_nxsb_info *nxi = sbi->s_nxi;
+	int err;
 
-	if (!err)
-		sb->s_fs_info = data;
-	return err;
+	/*
+	 * This fake device number will be unique to this volume-snapshot
+	 * combination. It gets reported by stat(), so that userland tools can
+	 * use it to tell different mountpoints apart.
+	 */
+	err = get_anon_bdev(&sbi->s_anon_dev);
+	if (err)
+		return err;
+
+	/*
+	 * This is the actual device number, shared by all volumes and
+	 * snapshots. It gets reported by the mountinfo file, and it seems that
+	 * udisks uses it to decide if a device is mounted, so it must be set.
+	 */
+	sb->s_dev = nxi->nx_bdev->bd_dev;
+
+	sb->s_fs_info = sbi;
+	return 0;
 }
 
 /*
@@ -1534,13 +1596,34 @@ static int apfs_attach_nxi(struct apfs_sb_info *sbi, const char *dev_name, fmode
 
 	nxi = apfs_nx_find_by_dev(dev);
 	if (!nxi) {
-		struct block_device *bdev;
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(6, 9, 0)
+		struct file *file = NULL;
+#elif LINUX_VERSION_CODE >= KERNEL_VERSION(6, 8, 0)
+		struct bdev_handle *handle = NULL;
+#endif
+		struct block_device *bdev = NULL;
 
 		nxi = kzalloc(sizeof(*nxi), GFP_KERNEL);
 		if (!nxi)
 			return -ENOMEM;
 
-#if LINUX_VERSION_CODE >= KERNEL_VERSION(6, 5, 0)
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(6, 9, 0)
+		file = bdev_file_open_by_path(dev_name, mode, &apfs_fs_type, NULL);
+		if (IS_ERR(file)) {
+			kfree(nxi);
+			return PTR_ERR(file);
+		}
+		nxi->nx_bdev_file = file;
+		bdev = file_bdev(file);
+#elif LINUX_VERSION_CODE >= KERNEL_VERSION(6, 8, 0)
+		handle = bdev_open_by_path(dev_name, mode, &apfs_fs_type, NULL);
+		if (IS_ERR(handle)) {
+			kfree(nxi);
+			return PTR_ERR(handle);
+		}
+		nxi->nx_bdev_handle = handle;
+		bdev = handle->bdev;
+#elif LINUX_VERSION_CODE >= KERNEL_VERSION(6, 5, 0)
 		bdev = blkdev_get_by_path(dev_name, mode, &apfs_fs_type, NULL);
 #else
 		bdev = blkdev_get_by_path(dev_name, mode, &apfs_fs_type);
@@ -1613,13 +1696,13 @@ static struct dentry *apfs_mount(struct file_system_type *fs_type, int flags,
 			goto out_deactivate_super;
 		}
 		/* Only one superblock per volume */
-		apfs_unmap_main_super(sbi);
+		apfs_free_main_super(sbi);
 		kfree(sbi->s_snap_name);
 		sbi->s_snap_name = NULL;
 		kfree(sbi);
 		sbi = NULL;
 	} else {
-		error = apfs_map_main_super(sb);
+		error = apfs_read_main_super(sb);
 		if (error)
 			goto out_deactivate_super;
 #if LINUX_VERSION_CODE < KERNEL_VERSION(6, 5, 0)
@@ -1638,7 +1721,7 @@ static struct dentry *apfs_mount(struct file_system_type *fs_type, int flags,
 out_deactivate_super:
 	deactivate_locked_super(sb);
 out_unmap_super:
-	apfs_unmap_main_super(sbi);
+	apfs_free_main_super(sbi);
 out_free_sbi:
 	kfree(sbi->s_snap_name);
 	kfree(sbi);
@@ -1647,11 +1730,19 @@ out_unlock:
 	return ERR_PTR(error);
 }
 
+static void apfs_kill_sb(struct super_block *sb)
+{
+	dev_t anon_dev = APFS_SB(sb)->s_anon_dev;
+
+	generic_shutdown_super(sb);
+	free_anon_bdev(anon_dev);
+}
+
 static struct file_system_type apfs_fs_type = {
 	.owner		= THIS_MODULE,
 	.name		= "apfs",
 	.mount		= apfs_mount,
-	.kill_sb	= kill_anon_super,
+	.kill_sb	= apfs_kill_sb,
 	.fs_flags	= FS_REQUIRES_DEV,
 };
 MODULE_ALIAS_FS("apfs");
@@ -1677,6 +1768,7 @@ static void __exit exit_apfs_fs(void)
 
 MODULE_AUTHOR("Ernesto A. FernÃ¡ndez");
 MODULE_DESCRIPTION("Apple File System");
+MODULE_VERSION(GIT_COMMIT);
 MODULE_LICENSE("GPL");
 module_init(init_apfs_fs)
 module_exit(exit_apfs_fs)
diff --git a/transaction.c b/transaction.c
index 55fb76a..a79a6a5 100644
--- a/transaction.c
+++ b/transaction.c
@@ -8,419 +8,258 @@
 #include "apfs.h"
 
 /**
- * apfs_cpoint_init_area - Initialize the new blocks of a checkpoint area
- * @sb:		superblock structure
- * @base:	first block of the area
- * @blks:	block count for the area
- * @next:	first block for the new checkpoint
- * @len:	block count for the new checkpoint
+ * apfs_checkpoint_end - End the new checkpoint
+ * @sb:	filesystem superblock
  *
- * Copies the blocks belonging to the last checkpoint to the area assigned for
- * the new one, updating their xids, oids and checksums.  Returns 0 on success,
- * or a negative error code in case of failure.
+ * Flushes all changes to disk, and commits the new checkpoint by setting the
+ * fletcher checksum on its superblock.  Returns 0 on success, or a negative
+ * error code in case of failure.
  */
-static int apfs_cpoint_init_area(struct super_block *sb, u64 base, u32 blks,
-				 u32 next, u32 len)
+static int apfs_checkpoint_end(struct super_block *sb)
 {
 	struct apfs_nxsb_info *nxi = APFS_NXI(sb);
-	u32 i;
-
-	for (i = 0; i < len; ++i) {
-		struct buffer_head *new_bh, *old_bh;
-		struct apfs_obj_phys *new_obj;
-		u32 new_index = (next + i) % blks;
-		u32 old_index = (blks + new_index - len) % blks;
-		u32 type;
-		int err;
-
-		new_bh = apfs_getblk(sb, base + new_index);
-		old_bh = apfs_sb_bread(sb, base + old_index);
-		if (!new_bh || !old_bh) {
-			apfs_err(sb, "unable to read the checkpoint areas");
-			brelse(new_bh);
-			brelse(old_bh);
-			return -EINVAL;
-		}
-		memcpy(new_bh->b_data, old_bh->b_data, sb->s_blocksize);
-		brelse(old_bh);
+	struct apfs_obj_phys *obj = &nxi->nx_raw->nx_o;
+	struct buffer_head *bh = NULL;
+	struct inode *bdev_inode = nxi->nx_bdev->bd_inode;
+	struct address_space *bdev_map = bdev_inode->i_mapping;
+	int err;
 
-		if (nxi->nx_flags & APFS_CHECK_NODES && !apfs_obj_verify_csum(sb, new_bh)) {
-			apfs_err(sb, "bad checksum for checkpoint area block");
-			brelse(new_bh);
-			return -EFSBADCRC;
-		}
+	ASSERT(!(sb->s_flags & SB_RDONLY));
 
-		new_obj = (struct apfs_obj_phys *)new_bh->b_data;
-		type = le32_to_cpu(new_obj->o_type);
-		if ((type & APFS_OBJ_STORAGETYPE_MASK) == APFS_OBJ_PHYSICAL)
-			new_obj->o_oid = cpu_to_le64(new_bh->b_blocknr);
+	bh = apfs_getblk(sb, nxi->nx_bno);
+	if (!bh) {
+		apfs_err(sb, "failed to map new checkpoint superblock");
+		return -EIO;
+	}
+	obj->o_xid = cpu_to_le64(nxi->nx_xid);
+	apfs_obj_set_csum(sb, obj);
+	memcpy(bh->b_data, obj, sb->s_blocksize);
 
-		ASSERT(nxi->nx_xid == le64_to_cpu(new_obj->o_xid) + 1);
-		new_obj->o_xid = cpu_to_le64(nxi->nx_xid);
-		err = apfs_transaction_join(sb, new_bh);
-		if (err) {
-			brelse(new_bh);
-			return err;
-		}
+	err = filemap_write_and_wait(bdev_map);
+	if (err)
+		goto out;
 
-		/* The transaction isn't over, don't commit the superblock */
-		if ((type & APFS_OBJECT_TYPE_MASK) !=
-		    APFS_OBJECT_TYPE_NX_SUPERBLOCK)
-			set_buffer_csum(new_bh);
+	mark_buffer_dirty(bh);
+	err = sync_dirty_buffer(bh);
+	if (err)
+		goto out;
 
-		new_obj = NULL;
-		brelse(new_bh);
-	}
-	return 0;
+	err = filemap_write_and_wait(bdev_map);
+out:
+	brelse(bh);
+	bh = NULL;
+	return err;
 }
 
 /**
- * apfs_cpoint_init_desc - Initialize the descriptor area for a new checkpoint
- * @sb: superblock structure
- *
- * Copies the latest descriptor and mapping blocks into the new checkpoint;
- * updates both the on-disk and in-memory superblocks to refer to the new
- * transaction.  Returns 0 on success, or a negative error code in case of
- * failure.
+ * apfs_transaction_has_room - Is there enough free space for this transaction?
+ * @sb:		superblock structure
+ * @maxops:	maximum operations expected
  */
-static int apfs_cpoint_init_desc(struct super_block *sb)
+static bool apfs_transaction_has_room(struct super_block *sb, struct apfs_max_ops maxops)
 {
-	struct apfs_nxsb_info *nxi = APFS_NXI(sb);
-	struct apfs_nx_superblock *raw_sb = nxi->nx_raw;
-	struct buffer_head *new_sb_bh = NULL;
-	u64 desc_base = le64_to_cpu(raw_sb->nx_xp_desc_base);
-	u32 desc_next = le32_to_cpu(raw_sb->nx_xp_desc_next);
-	u32 desc_blks = le32_to_cpu(raw_sb->nx_xp_desc_blocks);
-	u32 desc_len = le32_to_cpu(raw_sb->nx_xp_desc_len);
-	u32 new_sb_index;
-	int err;
-
-	if (!desc_blks || !desc_len) {
-		apfs_err(sb, "bad checkpoint descriptor area");
-		return -EFSCORRUPTED;
-	}
-
-	err = apfs_cpoint_init_area(sb, desc_base, desc_blks,
-				    desc_next, desc_len);
-	if (err) {
-		apfs_err(sb, "failed to init area");
-		return err;
-	}
+	u64 max_cat_blks, max_omap_blks, max_extref_blks, max_blks;
+	/* I don't know the actual maximum heights, just guessing */
+	const u64 max_cat_height = 8, max_omap_height = 3, max_extref_height = 3;
 
-	/* Now update the superblock with the new checkpoint */
+	/*
+	 * On the worst possible case (a tree of max_height), each new insertion
+	 * to the catalog may both cow and split every node up to the root. The
+	 * root though, is only cowed once.
+	 */
+	max_cat_blks = 1 + 2 * maxops.cat * max_cat_height;
 
-	new_sb_index = (desc_next + desc_len - 1) % desc_blks;
-	new_sb_bh = apfs_sb_bread(sb, desc_base + new_sb_index);
-	if (!new_sb_bh) {
-		apfs_err(sb, "unable to read the new checkpoint superblock");
-		brelse(new_sb_bh);
-		return -EINVAL;
-	}
+	/*
+	 * Any new catalog node could require a new entry in the object map,
+	 * because the original might belong to a snapshot.
+	 */
+	max_omap_blks = 1 + 2 * max_cat_blks * max_omap_height;
 
-	brelse(nxi->nx_object.o_bh);
-	nxi->nx_object.o_bh = new_sb_bh;
-	nxi->nx_object.data = new_sb_bh->b_data;
-	raw_sb = (struct apfs_nx_superblock *)new_sb_bh->b_data;
-	nxi->nx_raw = raw_sb;
-	nxi->nx_object.block_nr = new_sb_bh->b_blocknr;
+	/* The extent reference tree needs a maximum of one record per block */
+	max_extref_blks = 1 + 2 * maxops.blks * max_extref_height;
 
-	ASSERT(nxi->nx_xid == le64_to_cpu(raw_sb->nx_next_xid));
-	ASSERT(buffer_trans(new_sb_bh));
-	raw_sb->nx_next_xid = cpu_to_le64(nxi->nx_xid + 1);
+	/*
+	 * Ephemeral allocations shouldn't fail, and neither should those in the
+	 * internal pool. So just add the actual file blocks and we are done.
+	 */
+	max_blks = max_cat_blks + max_omap_blks + max_extref_blks + maxops.blks;
 
-	/* Apparently the previous checkpoint gets invalidated right away */
-	raw_sb->nx_xp_desc_index = cpu_to_le32(desc_next);
-	desc_next = (new_sb_index + 1) % desc_blks;
-	raw_sb->nx_xp_desc_next = cpu_to_le32(desc_next);
-	return 0;
+	return max_blks < APFS_SM(sb)->sm_free_count;
 }
 
 /**
- * apfs_cpoint_init_data - Initialize the data area for a new checkpoint
- * @sb: superblock structure
+ * apfs_read_single_ephemeral_object - Read a single ephemeral object to memory
+ * @sb:		filesystem superblock
+ * @map:	checkpoint mapping for the object
  *
- * Copies the latest data blocks into the new checkpoint, updating the fields
- * related to this change of location.  Returns 0 on success, or a negative
- * error code in case of failure.
+ * Returns 0 on success or a negative error code in case of failure.
  */
-static int apfs_cpoint_init_data(struct super_block *sb)
+static int apfs_read_single_ephemeral_object(struct super_block *sb, struct apfs_checkpoint_mapping *map)
 {
 	struct apfs_nxsb_info *nxi = APFS_NXI(sb);
-	struct apfs_nx_superblock *raw_sb = nxi->nx_raw;
-	u64 data_base = le64_to_cpu(raw_sb->nx_xp_data_base);
-	u32 data_next = le32_to_cpu(raw_sb->nx_xp_data_next);
-	u32 data_blks = le32_to_cpu(raw_sb->nx_xp_data_blocks);
-	u32 data_len = le32_to_cpu(raw_sb->nx_xp_data_len);
-	int err;
-
-	if (!data_blks || !data_len) {
-		apfs_err(sb, "bad checkpoint data area");
-		return -EFSCORRUPTED;
+	struct apfs_ephemeral_object_info *list = NULL;
+	struct buffer_head *bh = NULL;
+	char *object = NULL;
+	int count;
+	u32 size;
+	u64 bno, oid;
+	int err, i;
+
+	list = nxi->nx_eph_list;
+	count = nxi->nx_eph_count;
+	if (count >= APFS_EPHEMERAL_LIST_LIMIT) {
+		apfs_err(sb, "too many ephemeral objects?");
+		return -EOPNOTSUPP;
 	}
 
-	err = apfs_cpoint_init_area(sb, data_base, data_blks,
-				    data_next, data_len);
-	if (err) {
-		apfs_err(sb, "failed to init area");
-		return err;
+	bno = le64_to_cpu(map->cpm_paddr);
+	oid = le64_to_cpu(map->cpm_oid);
+	size = le32_to_cpu(map->cpm_size);
+	if (size > sb->s_blocksize << 1) {
+		/*
+		 * No reason not to support bigger objects, but there has to be
+		 * a limit somewhere and this is all I've seen so far.
+		 */
+		apfs_warn(sb, "ephemeral object has more than 2 blocks");
+		return -EOPNOTSUPP;
 	}
+	if (!size || (size & (sb->s_blocksize - 1))) {
+		apfs_err(sb, "invalid object size (0x%x)", size);
+		return -EFSCORRUPTED;
+	}
+	object = kmalloc(size, GFP_KERNEL);
+	if (!object)
+		return -ENOMEM;
 
-	/* Apparently the previous checkpoint gets invalidated right away */
-	apfs_assert_in_transaction(sb, &raw_sb->nx_o);
-	raw_sb->nx_xp_data_index = cpu_to_le32(data_next);
-	data_next = (data_next + data_len) % data_blks;
-	raw_sb->nx_xp_data_next = cpu_to_le32(data_next);
-	return 0;
-}
-
-/**
- * apfs_update_mapping - Update a single checkpoint mapping
- * @sb:		superblock structure
- * @map:	checkpoint mapping to update
- *
- * Remaps @map to point to the address of the same ephemeral object in the next
- * checkpoint data area.
- */
-static void apfs_update_mapping(struct super_block *sb,
-				struct apfs_checkpoint_mapping *map)
-{
-	struct apfs_nxsb_info *nxi = APFS_NXI(sb);
-	struct apfs_nx_superblock *raw_sb = nxi->nx_raw;
-	u64 data_base = le64_to_cpu(raw_sb->nx_xp_data_base);
-	u32 data_blks = le32_to_cpu(raw_sb->nx_xp_data_blocks);
-	u32 data_len = le32_to_cpu(raw_sb->nx_xp_data_len);
-	u64 old_paddr, new_paddr;
-	u32 old_index, new_index;
-
-	old_paddr = le64_to_cpu(map->cpm_paddr);
-	old_index = old_paddr - data_base;
-	new_index = (old_index + data_len) % data_blks;
-	new_paddr = data_base + new_index;
-
-	map->cpm_paddr = cpu_to_le64(new_paddr);
-}
-
-/**
- * apfs_update_mapping_blocks - Update all checkpoint mappings
- * @sb: superblock structure
- *
- * Updates the mappings in the checkpoint descriptor area to point to the
- * address of the ephemeral objects for the new checkpoint.  Returns 0 on
- * success, or a negative error code in case of failure.
- */
-static int apfs_update_mapping_blocks(struct super_block *sb)
-{
-	struct apfs_nxsb_info *nxi = APFS_NXI(sb);
-	struct apfs_nx_superblock *raw_sb = nxi->nx_raw;
-	u64 desc_base = le64_to_cpu(raw_sb->nx_xp_desc_base);
-	u32 desc_index = le32_to_cpu(raw_sb->nx_xp_desc_index);
-	u32 desc_blks = le32_to_cpu(raw_sb->nx_xp_desc_blocks);
-	u32 desc_len = le32_to_cpu(raw_sb->nx_xp_desc_len);
-	u32 i;
-
-	/* Last block in the area is superblock; the rest are mapping blocks */
-	for (i = 0; i < desc_len - 1; ++i) {
-		struct buffer_head *bh;
-		struct apfs_checkpoint_map_phys *cpm;
-		u32 desc_curr = (desc_index + i) % desc_blks;
-		u32 map_count;
-		int j;
-
-		bh = apfs_sb_bread(sb, desc_base + desc_curr);
+	for (i = 0; i < size >> sb->s_blocksize_bits; ++i) {
+		bh = apfs_sb_bread(sb, bno + i);
 		if (!bh) {
-			apfs_err(sb, "failed to read cpm block");
-			return -EINVAL;
-		}
-		ASSERT(buffer_trans(bh));
-		cpm = (struct apfs_checkpoint_map_phys *)bh->b_data;
-		apfs_assert_in_transaction(sb, &cpm->cpm_o);
-
-		map_count = le32_to_cpu(cpm->cpm_count);
-		if (map_count > apfs_max_maps_per_block(sb)) {
-			apfs_err(sb, "block has too many maps (%d)", map_count);
-			brelse(bh);
-			return -EFSCORRUPTED;
+			apfs_err(sb, "failed to read ephemeral block");
+			err = -EIO;
+			goto fail;
 		}
-
-		for (j = 0; j < map_count; ++j)
-			apfs_update_mapping(sb, &cpm->cpm_map[j]);
-		set_buffer_csum(bh);
+		memcpy(object + (i << sb->s_blocksize_bits), bh->b_data, sb->s_blocksize);
 		brelse(bh);
+		bh = NULL;
 	}
-	return 0;
-}
-
-/**
- * apfs_cpoint_data_allocate - Allocate a new block in the checkpoint data area
- * @sb:		superblock structure
- * @bno:	on return, the allocated block number
- */
-void apfs_cpoint_data_allocate(struct super_block *sb, u64 *bno)
-{
-	struct apfs_nxsb_info *nxi = APFS_NXI(sb);
-	struct apfs_nx_superblock *raw_sb = nxi->nx_raw;
-	u64 data_base = le64_to_cpu(raw_sb->nx_xp_data_base);
-	u32 data_next = le32_to_cpu(raw_sb->nx_xp_data_next);
-	u32 data_blks = le32_to_cpu(raw_sb->nx_xp_data_blocks);
-	u32 data_len = le32_to_cpu(raw_sb->nx_xp_data_len);
-
-	*bno = data_base + data_next;
-	data_next = (data_next + 1) % data_blks;
-	data_len++;
-
-	apfs_assert_in_transaction(sb, &raw_sb->nx_o);
-	raw_sb->nx_xp_data_next = cpu_to_le32(data_next);
-	raw_sb->nx_xp_data_len = cpu_to_le32(data_len);
-}
-
-/**
- * apfs_cpoint_data_free - Free a block in the checkpoint data area
- * @sb:		superblock structure
- * @bno:	block number to free
- *
- * Returns 0 on sucess, or a negative error code in case of failure.
- */
-int apfs_cpoint_data_free(struct super_block *sb, u64 bno)
-{
-	struct apfs_nxsb_info *nxi = APFS_NXI(sb);
-	struct apfs_nx_superblock *raw_sb = nxi->nx_raw;
-	u32 data_next = le32_to_cpu(raw_sb->nx_xp_data_next);
-	u32 data_blks = le32_to_cpu(raw_sb->nx_xp_data_blocks);
-	u32 data_len = le32_to_cpu(raw_sb->nx_xp_data_len);
-	u32 i, bno_i;
 
 	/*
-	 * We can't leave a hole in the data area, so we need to shift all
-	 * blocks that come after @bno one position back.
+	 * The official reference requires that we always verify ephemeral
+	 * checksums on mount, so do it even if the user didn't ask. We should
+	 * actually try to mount an older checkpoint when this fails (TODO),
+	 * which I guess means that the official driver writes all checkpoint
+	 * blocks at once, instead of leaving the superblock for last like we
+	 * do.
 	 */
-	bno_i = apfs_index_in_data_area(sb, bno);
-	for (i = bno_i; i < data_len - 1; ++i) {
-		struct buffer_head *old_bh, *new_bh;
-		int err;
-
-		new_bh = apfs_getblk(sb, apfs_data_index_to_bno(sb, i));
-		old_bh = apfs_sb_bread(sb, apfs_data_index_to_bno(sb, i + 1));
-		if (!new_bh || !old_bh) {
-			apfs_err(sb, "failed to map blocks in data area");
-			brelse(new_bh);
-			brelse(old_bh);
-			return -EIO;
-		}
-		/* I could also just remap the buffer heads... */
-		memcpy(new_bh->b_data, old_bh->b_data, sb->s_blocksize);
-
-		brelse(old_bh);
-		err = apfs_transaction_join(sb, new_bh); /* Not really needed */
-		brelse(new_bh);
-		if (err)
-			return err;
+	if (!apfs_multiblock_verify_csum(object, size)) {
+		apfs_err(sb, "bad checksum for ephemeral object 0x%llx", oid);
+		err = -EFSBADCRC;
+		goto fail;
 	}
 
-	data_next = (data_blks + data_next - 1) % data_blks;
-	data_len--;
-
-	apfs_assert_in_transaction(sb, &raw_sb->nx_o);
-	raw_sb->nx_xp_data_next = cpu_to_le32(data_next);
-	raw_sb->nx_xp_data_len = cpu_to_le32(data_len);
+	list[count].oid = oid;
+	list[count].size = size;
+	list[count].object = object;
+	object = NULL;
+	nxi->nx_eph_count = count + 1;
 	return 0;
+
+fail:
+	kfree(object);
+	object = NULL;
+	return err;
 }
 
 /**
- * apfs_checkpoint_start - Start the checkpoint for a new transaction
- * @sb:	superblock structure
+ * apfs_read_single_cpm_block - Read all ephemeral objects in a cpm block
+ * @sb:		filesystem superblock
+ * @cpm_bno:	block number for the cpm block
  *
- * Sets the descriptor and data areas for a new checkpoint.  Returns 0 on
- * success, or a negative error code in case of failure.
+ * Returns 0 on success or a negative error code in case of failure.
  */
-static int apfs_checkpoint_start(struct super_block *sb)
+static int apfs_read_single_cpm_block(struct super_block *sb, u64 cpm_bno)
 {
-	int err;
-
-	ASSERT(!(sb->s_flags & SB_RDONLY));
+	struct buffer_head *bh = NULL;
+	struct apfs_checkpoint_map_phys *cpm = NULL;
+	u32 map_count;
+	int err, i;
+
+	bh = apfs_sb_bread(sb, cpm_bno);
+	if (!bh) {
+		apfs_err(sb, "failed to read cpm block");
+		return -EIO;
+	}
+	if (!apfs_obj_verify_csum(sb, bh)) {
+		/*
+		 * The reference seems to imply that we need to check these on
+		 * mount, and retry an older checkpoint on failure (TODO).
+		 */
+		apfs_err(sb, "bad checksum for cpm block at 0x%llx", cpm_bno);
+		err = -EFSBADCRC;
+		goto out;
+	}
+	cpm = (struct apfs_checkpoint_map_phys *)bh->b_data;
 
-	err = apfs_cpoint_init_desc(sb);
-	if (err) {
-		apfs_err(sb, "failed to init descriptor area");
-		return err;
+	map_count = le32_to_cpu(cpm->cpm_count);
+	if (map_count > apfs_max_maps_per_block(sb)) {
+		apfs_err(sb, "block has too many maps (%d)", map_count);
+		err = -EFSCORRUPTED;
+		goto out;
 	}
-	err = apfs_cpoint_init_data(sb);
-	if (err) {
-		apfs_err(sb, "failed to init data area");
-		return err;
+
+	for (i = 0; i < map_count; ++i) {
+		err = apfs_read_single_ephemeral_object(sb, &cpm->cpm_map[i]);
+		if (err) {
+			apfs_err(sb, "failed to read ephemeral object %u", i);
+			goto out;
+		}
 	}
-	err = apfs_update_mapping_blocks(sb);
-	if (err)
-		apfs_err(sb, "failed to update checkpoint mappings");
 
+out:
+	brelse(bh);
+	cpm = NULL;
 	return err;
 }
 
 /**
- * apfs_checkpoint_end - End the new checkpoint
- * @sb:	filesystem superblock
+ * apfs_read_ephemeral_objects - Read all ephemeral objects to memory
+ * @sb:	superblock structure
  *
- * Flushes all changes to disk, and commits the new checkpoint by setting the
- * fletcher checksum on its superblock.  Returns 0 on success, or a negative
- * error code in case of failure.
+ * Returns 0 on success or a negative error code in case of failure.
  */
-static int apfs_checkpoint_end(struct super_block *sb)
+static int apfs_read_ephemeral_objects(struct super_block *sb)
 {
 	struct apfs_nxsb_info *nxi = APFS_NXI(sb);
-	struct apfs_obj_phys *obj = &nxi->nx_raw->nx_o;
-	struct buffer_head *bh = nxi->nx_object.o_bh;
-	struct inode *bdev_inode = nxi->nx_bdev->bd_inode;
-	struct address_space *bdev_map = bdev_inode->i_mapping;
+	struct apfs_nx_superblock *raw_sb = nxi->nx_raw;
+	u64 desc_base;
+	u32 desc_index, desc_blks, desc_len, i;
 	int err;
 
-	ASSERT(!(sb->s_flags & SB_RDONLY));
-
-	err = filemap_write_and_wait(bdev_map);
-	if (err)
-		return err;
-
-	apfs_obj_set_csum(sb, obj);
-	mark_buffer_dirty(bh);
-	err = sync_dirty_buffer(bh);
-	if (err)
-		return err;
-
-	return filemap_write_and_wait(bdev_map);
-}
-
-/**
- * apfs_transaction_has_room - Is there enough free space for this transaction?
- * @sb:		superblock structure
- * @maxops:	maximum operations expected
- */
-static bool apfs_transaction_has_room(struct super_block *sb, struct apfs_max_ops maxops)
-{
-	u64 max_cat_blks, max_omap_blks, max_extref_blks, max_blks;
-	/* I don't know the actual maximum heights, just guessing */
-	const u64 max_cat_height = 8, max_omap_height = 3, max_extref_height = 3;
-
-	/*
-	 * On the worst possible case (a tree of max_height), each new insertion
-	 * to the catalog may both cow and split every node up to the root. The
-	 * root though, is only cowed once.
-	 */
-	max_cat_blks = 1 + 2 * maxops.cat * max_cat_height;
-
-	/*
-	 * Any new catalog node could require a new entry in the object map,
-	 * because the original might belong to a snapshot.
-	 */
-	max_omap_blks = 1 + 2 * max_cat_blks * max_omap_height;
+	if (nxi->nx_eph_list) {
+		apfs_alert(sb, "attempt to reread ephemeral object list");
+		return -EFSCORRUPTED;
+	}
+	nxi->nx_eph_list = kzalloc(APFS_EPHEMERAL_LIST_SIZE, GFP_KERNEL);
+	if (!nxi->nx_eph_list)
+		return -ENOMEM;
+	nxi->nx_eph_count = 0;
 
-	/* The extent reference tree needs a maximum of one record per block */
-	max_extref_blks = 1 + 2 * maxops.blks * max_extref_height;
+	desc_base = le64_to_cpu(raw_sb->nx_xp_desc_base);
+	desc_index = le32_to_cpu(raw_sb->nx_xp_desc_index);
+	desc_blks = le32_to_cpu(raw_sb->nx_xp_desc_blocks);
+	desc_len = le32_to_cpu(raw_sb->nx_xp_desc_len);
 
-	/*
-	 * Ephemeral allocations shouldn't fail, and neither should those in the
-	 * internal pool. So just add the actual file blocks and we are done.
-	 */
-	max_blks = max_cat_blks + max_omap_blks + max_extref_blks + maxops.blks;
+	/* Last block in the area is superblock; the rest are mapping blocks */
+	for (i = 0; i < desc_len - 1; ++i) {
+		u64 cpm_bno = desc_base + (desc_index + i) % desc_blks;
 
-	return max_blks < APFS_SM(sb)->sm_free_count;
+		err = apfs_read_single_cpm_block(sb, cpm_bno);
+		if (err) {
+			apfs_err(sb, "failed to read cpm block %u", i);
+			return err;
+		}
+	}
+	return 0;
 }
 
 /**
@@ -449,23 +288,26 @@ int apfs_transaction_start(struct super_block *sb, struct apfs_max_ops maxops)
 		return -EROFS;
 	}
 
-	/* TODO: rethink this now that transactions shouldn't fail */
-	if (!nx_trans->t_old_msb) {
-		/* Backup the old superblock buffers in case the transaction fails */
-		nx_trans->t_old_msb = nxi->nx_object.o_bh;
-		get_bh(nx_trans->t_old_msb);
+	/*
+	 * Ephemeral objects are read only once, kept in memory, and committed
+	 * to disk along with each transaction.
+	 */
+	if (!nxi->nx_eph_list) {
+		err = apfs_read_ephemeral_objects(sb);
+		if (err) {
+			mutex_unlock(&nxs_mutex);
+			up_write(&nxi->nx_big_sem);
+			apfs_err(sb, "failed to read the ephemeral objects");
+			return err;
+		}
+	}
 
+	if (nx_trans->t_starts_count == 0) {
 		++nxi->nx_xid;
+		nxi->nx_raw->nx_next_xid = cpu_to_le64(nxi->nx_xid + 1);
+
 		INIT_LIST_HEAD(&nx_trans->t_inodes);
 		INIT_LIST_HEAD(&nx_trans->t_buffers);
-		nx_trans->t_buffers_count = 0;
-		nx_trans->t_starts_count = 0;
-
-		err = apfs_checkpoint_start(sb);
-		if (err) {
-			apfs_err(sb, "failed to start a new checkpoint");
-			goto fail;
-		}
 
 		err = apfs_read_spaceman(sb);
 		if (err) {
@@ -523,41 +365,6 @@ fail:
 	return err;
 }
 
-/**
- * apfs_end_buffer_write_sync - Clean up a buffer head just synced to disk
- * @bh:		the buffer head to clean
- * @uptodate:	has the write succeeded?
- */
-static void apfs_end_buffer_write_sync(struct buffer_head *bh, int uptodate)
-{
-	struct page *page = NULL;
-	bool is_metadata;
-
-	page = bh->b_page;
-	get_page(page);
-
-	is_metadata = buffer_csum(bh);
-	clear_buffer_csum(bh);
-	end_buffer_write_sync(bh, uptodate);
-	bh = NULL;
-
-	/* Future writes to mmapped areas should fault for CoW */
-	lock_page(page);
-	page_mkclean(page);
-
-	/* XXX: otherwise, the page cache fills up and crashes the machine */
-	if (!is_metadata) {
-#if LINUX_VERSION_CODE >= KERNEL_VERSION(5, 19, 0)
-		try_to_free_buffers(page_folio(page));
-#else
-		try_to_free_buffers(page);
-#endif
-	}
-
-	unlock_page(page);
-	put_page(page);
-}
-
 /**
  * apfs_transaction_flush_all_inodes - Flush inode metadata to the buffer heads
  * @sb: superblock structure
@@ -573,7 +380,6 @@ int apfs_transaction_flush_all_inodes(struct super_block *sb)
 	int err = 0, curr_err;
 
 	ASSERT(!(sb->s_flags & SB_RDONLY));
-	ASSERT(nx_trans->t_old_msb);
 
 	while (!list_empty(&nx_trans->t_inodes)) {
 		struct apfs_inode_info *ai = NULL;
@@ -598,16 +404,16 @@ int apfs_transaction_flush_all_inodes(struct super_block *sb)
 		mutex_unlock(&nxs_mutex);
 		up_write(&nxi->nx_big_sem);
 
-		/* Unlocked, so it may call ->evict_inode() */
+		/* Unlocked, so it may call evict() and wait for writeback */
 		iput(inode);
 
 		down_write(&nxi->nx_big_sem);
 		mutex_lock(&nxs_mutex);
 		nx_trans->t_state = 0;
 
-		/* Transaction aborted by ->evict_inode(), error code is lost */
+		/* Transaction aborted during writeback, error code is lost */
 		if (sb->s_flags & SB_RDONLY) {
-			apfs_err(sb, "abort during inode eviction");
+			apfs_err(sb, "abort during inode writeback");
 			return -EROFS;
 		}
 	}
@@ -615,6 +421,173 @@ int apfs_transaction_flush_all_inodes(struct super_block *sb)
 	return err;
 }
 
+/**
+ * apfs_write_single_ephemeral_object - Write a single ephemeral object to bh's
+ * @sb:		filesystem superblock
+ * @obj_raw:	contents of the object
+ * @map:	checkpoint mapping for the object, already updated
+ *
+ * Returns 0 on success or a negative error code in case of failure.
+ */
+static int apfs_write_single_ephemeral_object(struct super_block *sb, struct apfs_obj_phys *obj_raw, const struct apfs_checkpoint_mapping *map)
+{
+	struct apfs_nxsb_info *nxi = APFS_NXI(sb);
+	struct buffer_head *bh = NULL;
+	u64 bno;
+	u32 size;
+	int err, i;
+
+	bno = le64_to_cpu(map->cpm_paddr);
+	size = le32_to_cpu(map->cpm_size);
+	obj_raw->o_xid = cpu_to_le64(nxi->nx_xid);
+	apfs_multiblock_set_csum((char *)obj_raw, size);
+
+	for (i = 0; i < size >> sb->s_blocksize_bits; ++i) {
+		bh = apfs_getblk(sb, bno + i);
+		if (!bh) {
+			apfs_err(sb, "failed to map ephemeral block");
+			return -EIO;
+		}
+		err = apfs_transaction_join(sb, bh);
+		if (err) {
+			brelse(bh);
+			bh = NULL;
+			return err;
+		}
+		memcpy(bh->b_data, (char *)obj_raw + (i << sb->s_blocksize_bits), sb->s_blocksize);
+		brelse(bh);
+		bh = NULL;
+	}
+	return 0;
+}
+
+/**
+ * apfs_write_ephemeral_objects - Write all ephemeral objects to bh's
+ * @sb: filesystem superblock
+ *
+ * Returns 0 on sucess, or a negative error code in case of failure.
+ */
+static int apfs_write_ephemeral_objects(struct super_block *sb)
+{
+	struct apfs_nxsb_info *nxi = APFS_NXI(sb);
+	struct apfs_nx_superblock *raw_sb = nxi->nx_raw;
+	struct apfs_checkpoint_map_phys *cpm = NULL;
+	struct buffer_head *cpm_bh = NULL;
+	struct apfs_ephemeral_object_info *eph_info = NULL;
+	u64 cpm_bno;
+	u64 desc_base, data_base;
+	u32 desc_index, desc_blks, desc_len, desc_next;
+	u32 data_index, data_blks, data_len, data_next;
+	u32 desc_limit, data_limit;
+	u32 obj_blkcnt;
+	int err, i, cpm_start;
+
+	if (!nxi->nx_eph_list) {
+		apfs_alert(sb, "missing ephemeral object list");
+		return -EFSCORRUPTED;
+	}
+
+	desc_next = le32_to_cpu(raw_sb->nx_xp_desc_next);
+	desc_base = le64_to_cpu(raw_sb->nx_xp_desc_base);
+	desc_index = desc_next; /* New checkpoint */
+	desc_blks = le32_to_cpu(raw_sb->nx_xp_desc_blocks);
+	desc_len = 0; /* For now */
+
+	data_next = le32_to_cpu(raw_sb->nx_xp_data_next);
+	data_base = le64_to_cpu(raw_sb->nx_xp_data_base);
+	data_index = data_next; /* New checkpoint */
+	data_blks = le32_to_cpu(raw_sb->nx_xp_data_blocks);
+	data_len = 0; /* For now */
+
+	/*
+	 * The reference doesn't mention anything about this, but I need to
+	 * put some sort of a limit or else the rings could wrap around and
+	 * corrupt themselves.
+	 */
+	desc_limit = desc_blks >> 2;
+	data_limit = data_blks >> 2;
+
+	for (i = 0; i < nxi->nx_eph_count; ++i) {
+		if (data_len == data_limit) {
+			apfs_err(sb, "too many checkpoint data blocks");
+			return -EFSCORRUPTED;
+		}
+
+		if (!cpm) {
+			cpm_start = i;
+			if (desc_len == desc_limit) {
+				apfs_err(sb, "too many checkpoint descriptor blocks");
+				return -EFSCORRUPTED;
+			}
+			cpm_bno = desc_base + (desc_index + desc_len) % desc_blks;
+			err = apfs_create_cpm_block(sb, cpm_bno, &cpm_bh);
+			if (err) {
+				apfs_err(sb, "failed to create cpm block");
+				return err;
+			}
+			cpm = (void *)cpm_bh->b_data;
+			desc_len += 1;
+		}
+
+		eph_info = &nxi->nx_eph_list[i];
+		data_next = (data_index + data_len) % data_blks;
+		obj_blkcnt = eph_info->size >> sb->s_blocksize_bits;
+		if (obj_blkcnt > data_blks - data_next) {
+			/*
+			 * This multiblock object does not fit in what's left
+			 * of the ring buffer, so move it to the beginning and
+			 * leave some empty blocks.
+			 */
+			data_len += data_blks - data_next;
+			data_next = 0;
+		}
+
+		err = apfs_create_cpoint_map(sb, cpm, eph_info->object, data_base + data_next, eph_info->size);
+		if (err) {
+			if (err == -ENOSPC)
+				cpm->cpm_flags = 0; /* No longer the last */
+			brelse(cpm_bh);
+			cpm = NULL;
+			cpm_bh = NULL;
+			if (err == -ENOSPC) {
+				--i;
+				continue;
+			}
+			apfs_err(sb, "failed to create cpm map %d", i);
+			return err;
+		}
+		err = apfs_write_single_ephemeral_object(sb, eph_info->object, &cpm->cpm_map[i - cpm_start]);
+		if (err) {
+			brelse(cpm_bh);
+			cpm = NULL;
+			cpm_bh = NULL;
+			apfs_err(sb, "failed to write ephemeral object %d", i);
+			return err;
+		}
+		data_len += obj_blkcnt;
+	}
+
+	/*
+	 * The checkpoint superblock can't be set until the very end of the
+	 * transaction commit, but allocate its block here already.
+	 */
+	nxi->nx_bno = desc_base + (desc_index + desc_len) % desc_blks;
+	desc_len += 1;
+
+	desc_next = (desc_index + desc_len) % desc_blks;
+	data_next = (data_index + data_len) % data_blks;
+
+	raw_sb->nx_xp_desc_next = cpu_to_le32(desc_next);
+	raw_sb->nx_xp_desc_index = cpu_to_le32(desc_index);
+	raw_sb->nx_xp_desc_len = cpu_to_le32(desc_len);
+
+	raw_sb->nx_xp_data_next = cpu_to_le32(data_next);
+	raw_sb->nx_xp_data_index = cpu_to_le32(data_index);
+	raw_sb->nx_xp_data_len = cpu_to_le32(data_len);
+
+	return 0;
+}
+
 /**
  * apfs_transaction_commit_nx - Definitely commit the current transaction
  * @sb: superblock structure
@@ -627,9 +600,9 @@ static int apfs_transaction_commit_nx(struct super_block *sb)
 	struct apfs_nx_transaction *nx_trans = &nxi->nx_transaction;
 	struct apfs_bh_info *bhi, *tmp;
 	int err = 0;
+	u32 bmap_idx;
 
 	ASSERT(!(sb->s_flags & SB_RDONLY));
-	ASSERT(nx_trans->t_old_msb);
 
 	/* Before committing the bhs, write all inode metadata to them */
 	err = apfs_transaction_flush_all_inodes(sb);
@@ -640,7 +613,8 @@ static int apfs_transaction_commit_nx(struct super_block *sb)
 
 	/*
 	 * Now that nothing else will be freed, flush the last update to the
-	 * free queues so that it can be committed to disk with the other bhs
+	 * free queues so that it can be committed to disk along with all the
+	 * ephemeral objects.
 	 */
 	if (sm->sm_free_cache_base) {
 		err = apfs_free_queue_insert_nocache(sb, sm->sm_free_cache_base, sm->sm_free_cache_blkcnt);
@@ -650,8 +624,11 @@ static int apfs_transaction_commit_nx(struct super_block *sb)
 		}
 		sm->sm_free_cache_base = sm->sm_free_cache_blkcnt = 0;
 	}
+	err = apfs_write_ephemeral_objects(sb);
+	if (err)
+		return err;
 
-	list_for_each_entry_safe(bhi, tmp, &nx_trans->t_buffers, list) {
+	list_for_each_entry(bhi, &nx_trans->t_buffers, list) {
 		struct buffer_head *bh = bhi->bh;
 
 		ASSERT(buffer_trans(bh));
@@ -659,6 +636,25 @@ static int apfs_transaction_commit_nx(struct super_block *sb)
 		if (buffer_csum(bh))
 			apfs_obj_set_csum(sb, (void *)bh->b_data);
 
+		clear_buffer_dirty(bh);
+		get_bh(bh);
+		lock_buffer(bh);
+		bh->b_end_io = end_buffer_write_sync;
+		apfs_submit_bh(REQ_OP_WRITE, REQ_SYNC, bh);
+	}
+	list_for_each_entry_safe(bhi, tmp, &nx_trans->t_buffers, list) {
+		struct buffer_head *bh = bhi->bh;
+		struct page *page = NULL;
+		bool is_metadata;
+
+		ASSERT(buffer_trans(bh));
+
+		wait_on_buffer(bh);
+		if (!buffer_uptodate(bh)) {
+			apfs_err(sb, "failed to write some blocks");
+			return -EIO;
+		}
+
 		list_del(&bhi->list);
 		clear_buffer_trans(bh);
 		nx_trans->t_buffers_count--;
@@ -668,10 +664,27 @@ static int apfs_transaction_commit_nx(struct super_block *sb)
 		kfree(bhi);
 		bhi = NULL;
 
-		clear_buffer_dirty(bh);
-		lock_buffer(bh);
-		bh->b_end_io = apfs_end_buffer_write_sync;
-		apfs_submit_bh(REQ_OP_WRITE, REQ_SYNC, bh);
+		page = bh->b_page;
+		get_page(page);
+
+		is_metadata = buffer_csum(bh);
+		clear_buffer_csum(bh);
+		put_bh(bh);
+		bh = NULL;
+
+		/* Future writes to mmapped areas should fault for CoW */
+		lock_page(page);
+		page_mkclean(page);
+		/* XXX: otherwise, the page cache fills up and crashes the machine */
+		if (!is_metadata) {
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(5, 19, 0)
+			try_to_free_buffers(page_folio(page));
+#else
+			try_to_free_buffers(page);
+#endif
+		}
+		unlock_page(page);
+		put_page(page);
 	}
 	err = apfs_checkpoint_end(sb);
 	if (err) {
@@ -679,10 +692,6 @@ static int apfs_transaction_commit_nx(struct super_block *sb)
 		return err;
 	}
 
-	/* Success: forget the old container and volume superblocks */
-	brelse(nx_trans->t_old_msb);
-	nx_trans->t_old_msb = NULL;
-
 	list_for_each_entry(sbi, &nxi->vol_list, list) {
 		struct apfs_vol_transaction *vol_trans = &sbi->s_transaction;
 
@@ -701,10 +710,14 @@ static int apfs_transaction_commit_nx(struct super_block *sb)
 		vol_trans->t_old_cat_root.object.o_bh = NULL;
 	}
 
-	brelse(APFS_SM(sb)->sm_ip);
-	APFS_SM(sb)->sm_ip = NULL;
-	brelse(APFS_SM(sb)->sm_bh);
-	APFS_SM(sb)->sm_bh = NULL;
+	for (bmap_idx = 0; bmap_idx < APFS_SM(sb)->sm_ip_bmaps_count; ++bmap_idx) {
+		brelse(APFS_SM(sb)->sm_ip_bmaps[bmap_idx]);
+		APFS_SM(sb)->sm_ip_bmaps[bmap_idx] = NULL;
+	}
+	APFS_SM(sb)->sm_raw = NULL;
+
+	nx_trans->t_starts_count = 0;
+	nx_trans->t_buffers_count = 0;
 	return 0;
 }
 
@@ -723,7 +736,7 @@ static bool apfs_transaction_need_commit(struct super_block *sb)
 		return false;
 	}
 
-	/* Avoid nested commits on ->evict_inode() */
+	/* Avoid nested commits on inode writeback */
 	if (nx_trans->t_state & APFS_NX_TRANS_COMMITTING)
 		return false;
 
@@ -810,7 +823,6 @@ void apfs_inode_join_transaction(struct super_block *sb, struct inode *inode)
 	struct apfs_inode_info *ai = APFS_I(inode);
 
 	ASSERT(!(sb->s_flags & SB_RDONLY));
-	ASSERT(nx_trans->t_old_msb);
 	lockdep_assert_held_write(&nxi->nx_big_sem);
 
 	if (!list_empty(&ai->i_list)) /* Already in the transaction */
@@ -832,7 +844,6 @@ int apfs_transaction_join(struct super_block *sb, struct buffer_head *bh)
 	struct apfs_bh_info *bhi;
 
 	ASSERT(!(sb->s_flags & SB_RDONLY));
-	ASSERT(nx_trans->t_old_msb);
 	lockdep_assert_held_write(&nxi->nx_big_sem);
 
 	if (buffer_trans(bh)) /* Already part of the only transaction */
@@ -883,10 +894,11 @@ void apfs_transaction_abort(struct super_block *sb)
 	struct apfs_nx_transaction *nx_trans = &nxi->nx_transaction;
 	struct apfs_bh_info *bhi, *tmp;
 	struct apfs_inode_info *ai, *ai_tmp;
+	struct apfs_spaceman *sm = NULL;
+	u32 bmap_idx;
 
 	if (sb->s_flags & SB_RDONLY) {
 		/* Transaction already aborted, do nothing */
-		ASSERT(!nx_trans->t_old_msb);
 		ASSERT(list_empty(&nx_trans->t_inodes));
 		ASSERT(list_empty(&nx_trans->t_buffers));
 		mutex_unlock(&nxs_mutex);
@@ -894,7 +906,6 @@ void apfs_transaction_abort(struct super_block *sb)
 		return;
 	}
 
-	ASSERT(nx_trans->t_old_msb);
 	nx_trans->t_state = 0;
 	apfs_err(sb, "aborting transaction");
 
@@ -913,14 +924,10 @@ void apfs_transaction_abort(struct super_block *sb)
 		kfree(bhi);
 	}
 
-	/* Restore the old container superblock */
-	brelse(nxi->nx_object.o_bh);
-	nxi->nx_object.o_bh = nx_trans->t_old_msb;
-	nxi->nx_object.data = nxi->nx_object.o_bh->b_data;
-	nxi->nx_object.block_nr = nx_trans->t_old_msb->b_blocknr;
-	nxi->nx_raw = (void *)nx_trans->t_old_msb->b_data;
-	nx_trans->t_old_msb = NULL;
-
+	/*
+	 * TODO: get rid of all this stuff, it makes little sense. Maybe do an
+	 * actual read-only remount?
+	 */
 	list_for_each_entry(sbi, &nxi->vol_list, list) {
 		struct apfs_vol_transaction *vol_trans = &sbi->s_transaction;
 
@@ -946,10 +953,14 @@ void apfs_transaction_abort(struct super_block *sb)
 		vol_trans->t_old_cat_root.object.data = NULL;
 	}
 
-	brelse(APFS_SM(sb)->sm_ip);
-	APFS_SM(sb)->sm_ip = NULL;
-	brelse(APFS_SM(sb)->sm_bh);
-	APFS_SM(sb)->sm_bh = NULL;
+	sm = APFS_SM(sb);
+	if (sm) {
+		for (bmap_idx = 0; bmap_idx < sm->sm_ip_bmaps_count; ++bmap_idx) {
+			brelse(sm->sm_ip_bmaps[bmap_idx]);
+			sm->sm_ip_bmaps[bmap_idx] = NULL;
+		}
+		APFS_SM(sb)->sm_raw = NULL;
+	}
 
 	/*
 	 * It's not possible to undo in-memory changes from old operations in
@@ -960,7 +971,6 @@ void apfs_transaction_abort(struct super_block *sb)
 	mutex_unlock(&nxs_mutex);
 	up_write(&nxi->nx_big_sem);
 
-	/* ->evict_inode() will just fail if it starts a new transaction */
 	list_for_each_entry_safe(ai, ai_tmp, &nx_trans->t_inodes, i_list) {
 		list_del_init(&ai->i_list);
 		iput(&ai->vfs_inode);
diff --git a/xattr.c b/xattr.c
index ecbe0aa..0de1db1 100644
--- a/xattr.c
+++ b/xattr.c
@@ -195,18 +195,16 @@ int apfs_xattr_get_compressed_data(struct inode *inode, const char *name, struct
 {
 	struct super_block *sb = inode->i_sb;
 	struct apfs_sb_info *sbi = APFS_SB(sb);
-	struct apfs_key key;
 	struct apfs_query *query;
 	struct apfs_xattr xattr;
 	u64 cnid = apfs_ino(inode);
 	int ret;
 
-	apfs_init_xattr_key(cnid, name, &key);
 
 	query = apfs_alloc_query(sbi->s_cat_root, NULL /* parent */);
 	if (!query)
 		return -ENOMEM;
-	query->key = &key;
+	apfs_init_xattr_key(cnid, name, &query->key);
 	query->flags |= APFS_QUERY_CAT | APFS_QUERY_EXACT;
 
 	ret = apfs_btree_query(sb, &query);
@@ -330,18 +328,15 @@ int ____apfs_xattr_get(struct inode *inode, const char *name, void *buffer,
 {
 	struct super_block *sb = inode->i_sb;
 	struct apfs_sb_info *sbi = APFS_SB(sb);
-	struct apfs_key key;
 	struct apfs_query *query;
 	struct apfs_xattr xattr;
 	u64 cnid = apfs_ino(inode);
 	int ret;
 
-	apfs_init_xattr_key(cnid, name, &key);
-
 	query = apfs_alloc_query(sbi->s_cat_root, NULL /* parent */);
 	if (!query)
 		return -ENOMEM;
-	query->key = &key;
+	apfs_init_xattr_key(cnid, name, &query->key);
 	query->flags |= APFS_QUERY_CAT | APFS_QUERY_EXACT;
 
 	ret = apfs_btree_query(sb, &query);
@@ -461,16 +456,13 @@ static int apfs_delete_any_xattr(struct inode *inode)
 {
 	struct super_block *sb = inode->i_sb;
 	struct apfs_sb_info *sbi = APFS_SB(sb);
-	struct apfs_key key;
 	struct apfs_query *query;
 	int ret;
 
 	query = apfs_alloc_query(sbi->s_cat_root, NULL /* parent */);
 	if (!query)
 		return -ENOMEM;
-
-	apfs_init_xattr_key(apfs_ino(inode), NULL /* name */, &key);
-	query->key = &key;
+	apfs_init_xattr_key(apfs_ino(inode), NULL /* name */, &query->key);
 	query->flags = APFS_QUERY_CAT | APFS_QUERY_ANY_NAME | APFS_QUERY_EXACT;
 
 	ret = apfs_btree_query(sb, &query);
@@ -715,7 +707,6 @@ int apfs_xattr_set(struct inode *inode, const char *name, const void *value,
 {
 	struct super_block *sb = inode->i_sb;
 	struct apfs_sb_info *sbi = APFS_SB(sb);
-	struct apfs_key key;
 	struct apfs_query *query = NULL;
 	u64 cnid = apfs_ino(inode);
 	int key_len, val_len;
@@ -733,14 +724,12 @@ int apfs_xattr_set(struct inode *inode, const char *name, const void *value,
 		}
 	}
 
-	apfs_init_xattr_key(cnid, name, &key);
-
 	query = apfs_alloc_query(sbi->s_cat_root, NULL /* parent */);
 	if (!query) {
 		ret = -ENOMEM;
 		goto done;
 	}
-	query->key = &key;
+	apfs_init_xattr_key(cnid, name, &query->key);
 	query->flags = APFS_QUERY_CAT | APFS_QUERY_EXACT;
 
 	ret = apfs_btree_query(sb, &query);
@@ -874,7 +863,6 @@ ssize_t apfs_listxattr(struct dentry *dentry, char *buffer, size_t size)
 	struct super_block *sb = inode->i_sb;
 	struct apfs_sb_info *sbi = APFS_SB(sb);
 	struct apfs_nxsb_info *nxi = APFS_NXI(sb);
-	struct apfs_key key;
 	struct apfs_query *query;
 	u64 cnid = apfs_ino(inode);
 	size_t free = size;
@@ -889,8 +877,7 @@ ssize_t apfs_listxattr(struct dentry *dentry, char *buffer, size_t size)
 	}
 
 	/* We want all the xattrs for the cnid, regardless of the name */
-	apfs_init_xattr_key(cnid, NULL /* name */, &key);
-	query->key = &key;
+	apfs_init_xattr_key(cnid, NULL /* name */, &query->key);
 	query->flags = APFS_QUERY_CAT | APFS_QUERY_MULTIPLE | APFS_QUERY_EXACT;
 
 	while (1) {
